# complete_critic_activation.py
"""
–ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏–∫–∞:
1. –ü–∞—Ç—á confidence_level (—Å–Ω–∏–∂–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤)
2. –ü–∞—Ç—á –∫–∞—á–µ—Å—Ç–≤–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç)
3. –¢–µ—Å—Ç —Å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–º –ø–æ—Ä–æ–≥–æ–º
"""

import sys
import asyncio
import tempfile
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, str(Path(__file__).parent / "src"))

def apply_both_patches():
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –æ–±–∞ –ø–∞—Ç—á–∞: confidence + quality"""
    
    try:
        print("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ü–û–õ–ù–û–ì–û —Ä–µ—à–µ–Ω–∏—è...")
        
        # 1. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á confidence
        print("1Ô∏è‚É£ –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á confidence_level...")
        from src.utils.risk_validation_patch import apply_confidence_and_factors_patch
        apply_confidence_and_factors_patch()
        
        # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á quality calculation
        print("2Ô∏è‚É£ –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ç—á —Ä–∞—Å—á–µ—Ç–∞ –∫–∞—á–µ—Å—Ç–≤–∞...")
        from src.workflow.graph_builder import RiskAssessmentWorkflow
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        if not hasattr(RiskAssessmentWorkflow, '_original_quality_check_node'):
            RiskAssessmentWorkflow._original_quality_check_node = RiskAssessmentWorkflow._quality_check_node
        
        async def ultra_low_quality_check_node(self, state):
            """–£–õ–¨–¢–†–ê-–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∫—Ä–∏—Ç–∏–∫–∞"""
            
            assessment_id = state["assessment_id"]
            
            self.graph_logger.log_workflow_step(
                assessment_id, "quality_check_start",
                f"üîß –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï: ultra_low quality_check"
            )

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
            try:
                all_results = state.get_evaluation_results()
                evaluation_results = {}
                
                for risk_type, result in all_results.items():
                    if not result:
                        continue
                        
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
                    status = None
                    if isinstance(result, dict):
                        status = result.get("status")
                    elif hasattr(result, 'status'):
                        status = result.status
                        
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ
                    is_completed = False
                    if hasattr(status, 'value'):
                        is_completed = status.value == "completed"
                    elif str(status) == "ProcessingStatus.COMPLETED":
                        is_completed = True  
                    elif status == "completed":
                        is_completed = True
                    
                    if not is_completed:
                        continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ result_data
                    result_data = None
                    if isinstance(result, dict):
                        result_data = result.get("result_data")
                    elif hasattr(result, 'result_data'):
                        result_data = result.result_data
                        
                    if result_data is None:
                        continue
                    
                    evaluation_results[risk_type] = result
                
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_data",
                    f"üîß –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï: –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫: {len(evaluation_results)}"
                )
                
            except Exception as e:
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_data_error",
                    f"üîß –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}"
                )
                evaluation_results = {}

            # –ï—Å–ª–∏ –Ω–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
            if not evaluation_results:
                state["current_step"] = "error"
                state["error_message"] = "–ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–æ–≤"
                state["retry_needed"] = []
                return state
            
            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            success_rate = len(evaluation_results) / 6
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏–∫–∞
            critic_results = state.get("critic_results", {})
            has_critic_results = bool(critic_results)
            
            if has_critic_results:
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                quality_scores = []
                retry_needed = []
                
                for risk_type, critic_result in critic_results.items():
                    try:
                        if isinstance(critic_result, dict):
                            if (critic_result.get("status") == "completed" and 
                                critic_result.get("result_data") and 
                                "critic_evaluation" in critic_result["result_data"]):
                                
                                critic_eval = critic_result["result_data"]["critic_evaluation"]
                                quality_scores.append(critic_eval.get("quality_score", 7.0))
                                
                                if not critic_eval.get("is_acceptable", True):
                                    retry_count = state.get("retry_count", {})
                                    current_retries = retry_count.get(risk_type, 0)
                                    max_retries = state.get("max_retries", 3)
                                    
                                    if current_retries < max_retries:
                                        retry_needed.append(risk_type)
                            else:
                                quality_scores.append(7.0)
                                
                    except Exception as e:
                        quality_scores.append(7.0)
                
                avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 7.0
                
            else:
                # üîß –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º confidence –∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
                confidence_scores = []
                
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_confidence_analysis",
                    f"üîß –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º confidence –∏–∑ {len(evaluation_results)} –æ—Ü–µ–Ω–æ–∫"
                )
                
                for risk_type, result in evaluation_results.items():
                    try:
                        confidence = None
                        
                        if isinstance(result, dict):
                            result_data = result.get("result_data")
                            if result_data:
                                confidence = result_data.get("confidence_level")
                        elif hasattr(result, 'result_data') and result.result_data:
                            confidence = result.result_data.get("confidence_level")
                        
                        if confidence is not None:
                            confidence_scores.append(confidence)
                            self.graph_logger.log_workflow_step(
                                assessment_id, "confidence_extracted",
                                f"üîß {risk_type}: confidence = {confidence:.3f}"
                            )
                        else:
                            confidence_scores.append(0.7)
                            self.graph_logger.log_workflow_step(
                                assessment_id, "confidence_fallback", 
                                f"üîß {risk_type}: fallback confidence = 0.7"
                            )
                            
                    except Exception as e:
                        confidence_scores.append(0.7)
                
                if confidence_scores:
                    avg_confidence = sum(confidence_scores) / len(confidence_scores)
                    
                    # üîß –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –ù–ò–ó–ö–û–ï –ö–ê–ß–ï–°–¢–í–û –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    confidence_quality = avg_confidence * 6.0   # –°–ù–ò–ñ–ï–ù–û —Å 8.0
                    success_quality = success_rate * 1.0        # –°–ù–ò–ñ–ï–ù–û —Å 2.0
                    avg_quality = confidence_quality + success_quality
                    
                    # üîß –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï —Å–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
                    avg_quality = avg_quality * 0.8  # –ï—â–µ -20%
                    
                    self.graph_logger.log_workflow_step(
                        assessment_id, "quality_check_ultra_low",
                        f"üîß –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï: avg_confidence={avg_confidence:.3f}, "
                        f"final_quality={avg_quality:.1f} (–ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –°–ù–ò–ñ–ï–ù–û)"
                    )
                else:
                    # Extreme fallback - –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                    avg_quality = 3.0
                    self.graph_logger.log_workflow_step(
                        assessment_id, "quality_check_extreme_fallback",
                        f"üîß EXTREME fallback: quality={avg_quality}"
                    )
                
                retry_needed = []
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self.graph_logger.log_quality_check(
                assessment_id, 
                "overall", 
                avg_quality, 
                self.quality_threshold
            )
            
            # –ü—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ
            state["average_quality"] = avg_quality
            
            if retry_needed:
                state["retry_needed"] = retry_needed
                state["current_step"] = "retry_needed"
                
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_retry",
                    f"üîß ‚úÖ RETRY –¥–ª—è: {retry_needed}"
                )
                
            elif avg_quality < self.quality_threshold and not has_critic_results:
                state["current_step"] = "needs_critic"
                state["retry_needed"] = []
                
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_needs_critic",
                    f"üîß ‚úÖ –ö–†–ò–¢–ò–ö –ê–ö–¢–ò–í–ò–†–û–í–ê–ù! (–∫–∞—á–µ—Å—Ç–≤–æ {avg_quality:.1f} < {self.quality_threshold})"
                )
                
            else:
                state["current_step"] = "ready_for_finalization"
                state["retry_needed"] = []
                
                self.graph_logger.log_workflow_step(
                    assessment_id, "quality_check_finalize",
                    f"üîß ‚úÖ –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø (–∫–∞—á–µ—Å—Ç–≤–æ {avg_quality:.1f} >= {self.quality_threshold})"
                )
            
            return state
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —É–ª—å—Ç—Ä–∞-–ø–∞—Ç—á
        RiskAssessmentWorkflow._quality_check_node = ultra_low_quality_check_node
        
        print("‚úÖ –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_with_complete_solution():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–ª–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º"""
    
    try:
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–ª–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
        if not apply_both_patches():
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø–æ–ª–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ")
            return False
            
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        temp_dir = Path(tempfile.mkdtemp())
        test_file = temp_dir / "risky_agent.py"
        test_file.write_text("""
# –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∞–≥–µ–Ω—Ç
class RiskyAgent:
    def __init__(self):
        self.model = "experimental-gpt"  # –ü—Ä–æ–±–ª–µ–º–∞
        
    def handle_data(self, user_data):
        # –ü—Ä–æ–±–ª–µ–º–∞: –Ω–µ—Ç –ø—Ä–æ–≤–µ—Ä–æ–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        return f"Processed: {user_data}"
        """, encoding='utf-8')
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        from src.utils.logger import setup_logging
        setup_logging(log_level="INFO")
        
        # –°–æ–∑–¥–∞–µ–º workflow
        from src.workflow import create_workflow_from_env
        workflow = create_workflow_from_env()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –û–ß–ï–ù–¨ –ù–ò–ó–ö–ò–ô –ø–æ—Ä–æ–≥
        workflow.quality_threshold = 5.0  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π!
        print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –û–ß–ï–ù–¨ –ù–ò–ó–ö–ò–ô –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞: {workflow.quality_threshold}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
        print("\nüèÉ‚Äç‚ôÇÔ∏è –ó–∞–ø—É—Å–∫ —Å –ü–û–õ–ù–´–ú –†–ï–®–ï–ù–ò–ï–ú...")
        
        result = await workflow.run_assessment(
            source_files=[str(temp_dir)],
            agent_name="RiskyAgentForCriticTest"
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–õ–ù–û–ì–û –†–ï–®–ï–ù–ò–Ø:")
        print("=" * 50)
        
        if result.get("success"):
            print("‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
            processing_time = result.get("processing_time", 0)
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.1f}—Å")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø—É—Å–∫–∞–ª—Å—è –ª–∏ –∫—Ä–∏—Ç–∏–∫
            if processing_time > 60:
                print("üéâ –ö–†–ò–¢–ò–ö –ó–ê–ü–£–°–ö–ê–õ–°–Ø! (–≤—Ä–µ–º—è > 60 —Å–µ–∫)")
                print("‚úÖ –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï –†–ê–ë–û–¢–ê–ï–¢!")
            else:
                print("‚ö†Ô∏è –ö—Ä–∏—Ç–∏–∫ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è (–≤—Ä–µ–º—è < 60 —Å–µ–∫)")
                print("üí° –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—Å–µ –µ—â–µ –≤—ã—Å–æ–∫–∏–º, –ø—Ä–æ–≤–µ—Ä–∏–º –ª–æ–≥–∏")
            
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', 'Unknown')}")
            return False
            
    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    print("üöÄ –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï –î–õ–Ø –ê–ö–¢–ò–í–ê–¶–ò–ò –ö–†–ò–¢–ò–ö–ê")
    print("=" * 60)
    print("üéØ –¶–ï–õ–¨: –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫—Ä–∏—Ç–∏–∫–∞")
    print("üîß –ú–ï–¢–û–î: confidence_patch + quality_patch + –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥")
    
    success = await test_with_complete_solution()
    
    print(f"\nüèÅ –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–û–õ–ù–û–ì–û –†–ï–®–ï–ù–ò–Ø:")
    if success:
        print("‚úÖ –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï –†–ê–ë–û–¢–ê–ï–¢!")
        print("\nüí° –î–õ–Ø –ü–û–°–¢–û–Ø–ù–ù–û–ì–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:")
        print("1. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ graph_builder.py")
        print("2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ QUALITY_THRESHOLD=5.0 –≤ .env")
        print("3. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --quality-threshold 5.0 –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ")
    else:
        print("‚ùå –ï–°–¢–¨ –ü–†–û–ë–õ–ï–ú–´ –° –ü–û–õ–ù–´–ú –†–ï–®–ï–ù–ò–ï–ú")
        print("üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")

if __name__ == "__main__":
    asyncio.run(main())