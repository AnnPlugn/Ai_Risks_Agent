# src/agents/evaluator_agents.py
"""
–ê–≥–µ–Ω—Ç—ã-–æ—Ü–µ–Ω—â–∏–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
6 —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤
"""

from typing import Dict, Any, List, Optional, Union
from datetime import datetime

from .base_agent import EvaluationAgent, AgentConfig
from ..models.risk_models import (
    RiskType, RiskEvaluation, AgentTaskResult, ProcessingStatus, WorkflowState
)
from ..utils.logger import LogContext
from ..prompts.call_evaluator_prompts import (call_ethical_prompt, call_social_risk_prompt, call_regulatory_risk_prompt,
                                              call_autonomy_risk_prompt, call_security_risk_prompt, call_stability_risk_prompt)



class EthicalRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
    
    def get_system_prompt(self) -> str:
        try:
            import uuid
            temp_assessment_id = str(uuid.uuid4())[:8]
            bound_logger = self.logger.bind_context(temp_assessment_id, self.name)
            bound_logger.info(f"üìã EthicalRiskEvaluator –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç (–≤–µ—Ä—Å–∏—è —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ 800+ —Å–∏–º–≤–æ–ª–æ–≤)")
        except:
            print("üìã EthicalRiskEvaluator –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç")

        return call_ethical_prompt

    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–û–¢–õ–ê–î–û–ß–ù–ê–Ø –≤–µ—Ä—Å–∏—è –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤ –¥–ª—è GigaChat"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_ethical_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                print(f"üîç DEBUG EthicalRiskEvaluator: –ù–∞—á–∏–Ω–∞–µ–º evaluate_risk...")
                
                # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç LLM
                evaluation_result = await self.evaluate_risk(
                    risk_type="—ç—Ç–∏—á–µ—Å–∫–∏–µ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # ===== –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê THREAT_ASSESSMENTS =====
                print(f"üîç DEBUG EthicalRiskEvaluator: –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM")
                print(f"üîç DEBUG: –ö–ª—é—á–∏ –≤ –æ—Ç–≤–µ—Ç–µ: {list(evaluation_result.keys())}")
                
                if "threat_assessments" not in evaluation_result:
                    print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: threat_assessments –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ –æ—Ç GigaChat!")
                    print("üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç GigaChat:")
                    import json
                    print(json.dumps(evaluation_result, ensure_ascii=False, indent=2))
                    
                    # –°–æ–∑–¥–∞–µ–º fallback threat_assessments
                    print("üîß –°–æ–∑–¥–∞–µ–º fallback threat_assessments...")
                    evaluation_result["threat_assessments"] = {
                        "–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏_–∏_–∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ": {
                            "risk_level": "—Å—Ä–µ–¥–Ω—è—è",
                            "probability_score": 3,
                            "impact_score": 3,
                            "reasoning": "Fallback –æ—Ü–µ–Ω–∫–∞: GigaChat –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª threat_assessments. –ê–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —è–≤–Ω—ã—Ö –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –∫–æ–Ω—Ç—Ä–æ–ª—è RAG –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∞–≥–µ–Ω—Ç–∞."
                        },
                        "–¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è": {
                            "risk_level": "—Å—Ä–µ–¥–Ω—è—è", 
                            "probability_score": 3,
                            "impact_score": 3,
                            "reasoning": "Fallback –æ—Ü–µ–Ω–∫–∞: GigaChat –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª threat_assessments. –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –≥–∞–π–¥–ª–∞–π–Ω–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–∞—Ö."
                        },
                        "—Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å_–∏_–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è": {
                            "risk_level": "—Å—Ä–µ–¥–Ω—è—è",
                            "probability_score": 3, 
                            "impact_score": 3,
                            "reasoning": "Fallback –æ—Ü–µ–Ω–∫–∞: GigaChat –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª threat_assessments. –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ—Ü–µ–¥—É—Ä —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è."
                        }
                    }
                    print("‚úÖ Fallback threat_assessments —Å–æ–∑–¥–∞–Ω")
                else:
                    print("‚úÖ DEBUG EthicalRiskEvaluator: threat_assessments –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ!")
                    threats = evaluation_result["threat_assessments"]
                    print(f"üîç –ù–∞–π–¥–µ–Ω–æ —É–≥—Ä–æ–∑: {len(threats)}")
                    for threat_name, threat_data in threats.items():
                        risk_level = threat_data.get('risk_level', 'unknown')
                        reasoning_length = len(str(threat_data.get('reasoning', '')))
                        print(f"  üéØ {threat_name}: {risk_level} (reasoning: {reasoning_length} —Å–∏–º–≤–æ–ª–æ–≤)")
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.ETHICAL,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å threat_assessments –µ—Å–ª–∏ –µ—Å—Ç—å
                threat_assessments_dict = {}
                if hasattr(risk_evaluation, 'threat_assessments') and risk_evaluation.threat_assessments:
                    for threat_name, threat_obj in risk_evaluation.threat_assessments.items():
                        threat_assessments_dict[threat_name] = {
                            "risk_level": threat_obj.risk_level,
                            "probability_score": threat_obj.probability_score,
                            "impact_score": threat_obj.impact_score,
                            "reasoning": threat_obj.reasoning
                        }
                    print(f"‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º –≤ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ {len(threat_assessments_dict)} —É–≥—Ä–æ–∑")
                
                self.logger.log_risk_evaluation(
                    self.name,
                    assessment_id,
                    "—ç—Ç–∏—á–µ—Å–∫–∏–µ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏",
                    risk_evaluation.total_score,
                    risk_evaluation.risk_level.value,
                    threat_assessments_dict if threat_assessments_dict else None
                )
                
                # –°–æ–∑–¥–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="ethicalriskevaluator",
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation},
                    execution_time_seconds=execution_time,
                    assessment_id=assessment_id
                )
                
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            error_message = f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤: {str(e)}"
            
            print(f"‚ùå –û–®–ò–ë–ö–ê –≤ EthicalRiskEvaluator: {error_message}")
            import traceback
            traceback.print_exc()
            
            return AgentTaskResult(
                task_type="ethicalriskevaluator",
                status=ProcessingStatus.FAILED,
                result_data={},
                execution_time_seconds=execution_time,
                error_message=error_message,
                assessment_id=assessment_id
            )

    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤"""
        # üîç –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–ø–æ—Å–æ–± –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        detailed_summary = agent_profile.get('detailed_summary', {})
        
        # –õ–û–ì–ò–†–£–ï–ú –° –ü–†–ê–í–ò–õ–¨–ù–´–ú assessment_id (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ)
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å assessment_id –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π
            import uuid
            temp_assessment_id = str(uuid.uuid4())[:8]
            bound_logger = self.logger.bind_context(temp_assessment_id, self.name)
            
            if detailed_summary:
                bound_logger.info(f"‚úÖ EthicalRiskEvaluator –ø–æ–ª—É—á–∏–ª –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ —Å {len(detailed_summary)} —Ä–∞–∑–¥–µ–ª–∞–º–∏")
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ä–∞–∑–¥–µ–ª–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ DEBUG —É—Ä–æ–≤–µ–Ω—å)
                total_summary_length = 0
                for section, content in detailed_summary.items():
                    section_length = len(str(content))
                    total_summary_length += section_length
                    bound_logger.debug(f"  üìä {section}: {section_length} —Å–∏–º–≤–æ–ª–æ–≤")
                
                bound_logger.info(f"üìè –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä —Å–∞–º–º–∞—Ä–∏: {total_summary_length} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                bound_logger.warning("‚ö†Ô∏è EthicalRiskEvaluator –ù–ï –ø–æ–ª—É—á–∏–ª –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏")
                
        except Exception as e:
            # Fallback –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
            print(f"üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: detailed_summary –µ—Å—Ç—å: {bool(detailed_summary)}, —Ä–∞–∑–¥–µ–ª–æ–≤: {len(detailed_summary) if detailed_summary else 0}")
        
        

        basic_info = f"""–ü–†–û–§–ò–õ–¨ –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–¢–∏–ø: {agent_profile.get('agent_type', 'unknown')}
–û–ø–∏—Å–∞–Ω–∏–µ: {agent_profile.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {agent_profile.get('autonomy_level', 'unknown')}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–ü–¢–´:
{chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–í–ù–ï–®–ù–ò–ï API: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}"""
        # –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        #detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

class StabilityRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —Ä–∏—Å–∫–æ–≤ –æ—à–∏–±–æ–∫ –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ LLM"""
    
    def get_system_prompt(self) -> str:
        return call_stability_risk_prompt

    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_stability_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                evaluation_result = await self.evaluate_risk(
                    risk_type="—Ä–∏—Å–∫–∏ –æ—à–∏–±–æ–∫ –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ LLM",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.STABILITY,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                self.logger.log_risk_evaluation(
                    self.name, assessment_id, "—Ä–∏—Å–∫–∏ –æ—à–∏–±–æ–∫ –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ LLM",
                    risk_evaluation.total_score, risk_evaluation.risk_level.value
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="stabilityriskevaluator", 
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏: {e}"
            )
            
            fallback_evaluation = RiskEvaluation.create_from_raw_data(
                risk_type=RiskType.STABILITY,
                evaluator_agent=self.name,
                raw_data={"error_message": str(e)}
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="stabilityriskevaluator",
                status=ProcessingStatus.COMPLETED,
                result_data={"risk_evaluation": fallback_evaluation.dict()},
                start_time=start_time,
                end_time=datetime.now(),
                execution_time_seconds=execution_time,
                error_message=f"Fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
            )

    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"""
        basic_info = f"""–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ô –ü–†–û–§–ò–õ–¨ –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
LLM –ú–æ–¥–µ–ª—å: {agent_profile.get('llm_model', 'unknown')}
–¢–∏–ø –∞–≥–µ–Ω—Ç–∞: {agent_profile.get('agent_type', 'unknown')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {agent_profile.get('autonomy_level', 'unknown')}

–°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–ü–¢–´ (–∞–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏):
{chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–í–ù–ï–®–ù–ò–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ò:
APIs: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}

–ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –ö–û–ù–¢–†–û–õ–¨:
–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}"""
# –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

class SecurityRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∏—Å—Ç–µ–º"""
    
    def get_system_prompt(self) -> str:
        return call_security_risk_prompt

    
    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_security_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                evaluation_result = await self.evaluate_risk(
                    risk_type="—Ä–∏—Å–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∏—Å—Ç–µ–º",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.SECURITY,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                self.logger.log_risk_evaluation(
                    self.name, assessment_id, "—Ä–∏—Å–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∏—Å—Ç–µ–º",
                    risk_evaluation.total_score, risk_evaluation.risk_level.value
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="security_risk_evaluation", 
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {e}"
            )
            
            fallback_evaluation = RiskEvaluation.create_from_raw_data(
                risk_type=RiskType.SECURITY,
                evaluator_agent=self.name,
                raw_data={"error_message": str(e)}
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="security_risk_evaluation",
                status=ProcessingStatus.COMPLETED,
                result_data={"risk_evaluation": fallback_evaluation.dict()},
                start_time=start_time,
                end_time=datetime.now(),
                execution_time_seconds=execution_time,
                error_message=f"Fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
            )

    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        basic_info = f"""–ü–†–û–§–ò–õ–¨ –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}
–í–Ω–µ—à–Ω–∏–µ APIs: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}
–£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: {agent_profile.get('autonomy_level', 'unknown')}

–ú–ï–†–´ –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–ü–¢–´ (–∞–Ω–∞–ª–∏–∑ –Ω–∞ —É—è–∑–≤–∏–º–æ—Å—Ç–∏):
{chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢:
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}"""
# –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

class AutonomyRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —Ä–∏—Å–∫–æ–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    
    def get_system_prompt(self) -> str:
        try:
            import uuid
            temp_assessment_id = str(uuid.uuid4())[:8]
            bound_logger = self.logger.bind_context(temp_assessment_id, self.name)
            bound_logger.info(f"üìã AutonomyRiskEvaluator –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç (–≤–µ—Ä—Å–∏—è —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ 1000+ —Å–∏–º–≤–æ–ª–æ–≤)")
        except:
            print("üìã AutonomyRiskEvaluator –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç")

        return call_autonomy_risk_prompt

        
    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_autonomy_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                evaluation_result = await self.evaluate_risk(
                    risk_type="—Ä–∏—Å–∫–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.AUTONOMY,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                self.logger.log_risk_evaluation(
                    self.name, assessment_id, "—Ä–∏—Å–∫–∏ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
                    risk_evaluation.total_score, risk_evaluation.risk_level.value
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="autonomy_risk_evaluation",
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: {e}"
            )
            
            fallback_evaluation = RiskEvaluation.create_from_raw_data(
                risk_type=RiskType.AUTONOMY,
                evaluator_agent=self.name,
                raw_data={"error_message": str(e)}
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="autonomy_risk_evaluation",
                status=ProcessingStatus.COMPLETED,
                result_data={"risk_evaluation": fallback_evaluation.dict()},
                start_time=start_time,
                end_time=datetime.now(),
                execution_time_seconds=execution_time,
                error_message=f"Fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
            )

    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏"""
        basic_info = f"""–ü–†–û–§–ò–õ–¨ –ê–í–¢–û–ù–û–ú–ù–û–°–¢–ò –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: {agent_profile.get('autonomy_level', 'unknown')}
–¢–∏–ø –∞–≥–µ–Ω—Ç–∞: {agent_profile.get('agent_type', 'unknown')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–î–æ—Ö–æ–¥ —Å –æ–ø–µ—Ä–∞—Ü–∏–∏: {agent_profile.get('revenue_per_operation', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')} —Ä—É–±

–û–ë–õ–ê–°–¢–¨ –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–ò:
{agent_profile.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ò –ö–û–ù–¢–†–û–õ–¨:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–°–ò–°–¢–ï–ú–ù–´–ï –ò–ù–°–¢–†–£–ö–¶–ò–ò:
{chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–ò–ù–¢–ï–ì–†–ê–¶–ò–ò:
–í–Ω–µ—à–Ω–∏–µ API: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}"""
# –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

class RegulatoryRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤"""
    
    def get_system_prompt(self) -> str:
        return call_regulatory_risk_prompt

    

    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_regulatory_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                evaluation_result = await self.evaluate_risk(
                    risk_type="—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.REGULATORY,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                self.logger.log_risk_evaluation(
                    self.name, assessment_id, "—Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏",
                    risk_evaluation.total_score, risk_evaluation.risk_level.value
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="regulatory_risk_evaluation",
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤: {e}"
            )
            
            fallback_evaluation = RiskEvaluation.create_from_raw_data(
                risk_type=RiskType.REGULATORY,
                evaluator_agent=self.name,
                raw_data={"error_message": str(e)}
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="regulatory_risk_evaluation",
                status=ProcessingStatus.COMPLETED,
                result_data={"risk_evaluation": fallback_evaluation.dict()},
                start_time=start_time,
                end_time=datetime.now(),
                execution_time_seconds=execution_time,
                error_message=f"Fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
            )

    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        basic_info = f"""–†–ï–ì–£–õ–Ø–¢–û–†–ù–´–ô –ü–†–û–§–ò–õ–¨ –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–¢–∏–ø –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {agent_profile.get('agent_type', 'unknown')}
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}

–û–ë–†–ê–ë–û–¢–ö–ê –ü–ï–†–°–û–ù–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•:
–£—Ä–æ–≤–µ–Ω—å –¥–æ—Å—Ç—É–ø–∞: {', '.join(agent_profile.get('data_access', []))}
–í–Ω–µ—à–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {', '.join(agent_profile.get('external_apis', ['–ù–µ—Ç']))}

–ú–ï–†–´ –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {agent_profile.get('autonomy_level', 'unknown')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–î–æ—Ö–æ–¥ —Å –æ–ø–µ—Ä–∞—Ü–∏–∏: {agent_profile.get('revenue_per_operation', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')} —Ä—É–±

–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:
LLM: {agent_profile.get('llm_model', 'unknown')}
–°–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: {chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}"""
# –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

class SocialRiskEvaluator(EvaluationAgent):
    """–ê–≥–µ–Ω—Ç-–æ—Ü–µ–Ω—â–∏–∫ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –∏ –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
    
    def get_system_prompt(self) -> str:
        return call_social_risk_prompt

    
    async def process(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
        start_time = datetime.now()
        
        try:
            with LogContext("evaluate_social_risk", assessment_id, self.name):
                agent_profile = input_data.get("agent_profile", {})
                agent_data = self._format_agent_data(agent_profile)
                
                evaluation_result = await self.evaluate_risk(
                    risk_type="—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∏ –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã–µ —Ä–∏—Å–∫–∏",
                    agent_data=agent_data,
                    evaluation_criteria=self.get_system_prompt(),
                    assessment_id=assessment_id
                )
                
                # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                risk_evaluation = RiskEvaluation.create_safe(
                    risk_type=RiskType.SOCIAL,
                    evaluator_agent=self.name,
                    raw_data=evaluation_result
                )
                
                self.logger.log_risk_evaluation(
                    self.name, assessment_id, "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ –∏ –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã–µ —Ä–∏—Å–∫–∏",
                    risk_evaluation.total_score, risk_evaluation.risk_level.value
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type="socialriskevaluator",
                    status=ProcessingStatus.COMPLETED,
                    result_data={"risk_evaluation": risk_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time
                )
                
        except Exception as e:
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤: {e}"
            )
            
            fallback_evaluation = RiskEvaluation.create_from_raw_data(
                risk_type=RiskType.SOCIAL,
                evaluator_agent=self.name,
                raw_data={"error_message": str(e)}
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return AgentTaskResult(
                agent_name=self.name,
                task_type="socialriskevaluator",
                status=ProcessingStatus.COMPLETED,
                result_data={"risk_evaluation": fallback_evaluation.dict()},
                start_time=start_time,
                end_time=datetime.now(),
                execution_time_seconds=execution_time,
                error_message=f"Fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
            )
        
    def _format_agent_data(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤"""
        basic_info = f"""–°–û–¶–ò–ê–õ–¨–ù–´–ô –ü–†–û–§–ò–õ–¨ –ê–ì–ï–ù–¢–ê:
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–¢–∏–ø –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {agent_profile.get('agent_type', 'unknown')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–•–ê–†–ê–ö–¢–ï–† –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø:
{agent_profile.get('description', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}

–í–û–ó–ú–û–ñ–ù–û–°–¢–ò –í–õ–ò–Ø–ù–ò–Ø:
–°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã: {chr(10).join(agent_profile.get('system_prompts', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–ó–ê–©–ò–¢–ù–´–ï –ú–ï–†–´:
{chr(10).join(agent_profile.get('guardrails', ['–ù–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–ö–û–ù–¢–ï–ö–°–¢ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}
–ê–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å: {agent_profile.get('autonomy_level', 'unknown')}"""
# –î–û–ë–ê–í–õ–Ø–ï–ú –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò
        detailed_summary = agent_profile.get('detailed_summary', {})
        if detailed_summary:
            summary_section = f"""

=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò ===

–û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary.get('overview', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary.get('technical_architecture', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary.get('operational_model', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary.get('risk_analysis', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary.get('security_recommendations', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–í–´–í–û–î–´:
{detailed_summary.get('conclusions', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}"""
            
            return basic_info + summary_section
        
        return basic_info

# ===============================
# –§–∞–±—Ä–∏–∫–∏ –∏ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
# ===============================



def create_all_evaluator_agents(
    llm_base_url: Optional[str] = None,
    llm_model: Optional[str] = None,
    temperature: Optional[float] = None
) -> Dict[RiskType, EvaluationAgent]:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö 6 –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤
    –û–ë–ù–û–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä
    """
    from .base_agent import create_agent_config
    
    # –ò–ó–ú–ï–ù–ï–ù–û: –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä
    base_config_params = {
        "llm_base_url": llm_base_url,
        "llm_model": llm_model,
        "temperature": temperature,
        "max_retries": 3,
        "timeout_seconds": 120,
        "use_risk_analysis_client": True  # –í—Å–µ –æ—Ü–µ–Ω—â–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
    }
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    configs = {
        RiskType.ETHICAL: create_agent_config(
            name="ethical_risk_evaluator",
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤",
            **base_config_params
        ),
        RiskType.STABILITY: create_agent_config(
            name="stability_risk_evaluator", 
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –æ—à–∏–±–æ–∫ –∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ LLM",
            **base_config_params
        ),
        RiskType.SECURITY: create_agent_config(
            name="security_risk_evaluator",
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∏—Å—Ç–µ–º",
            **base_config_params
        ),
        RiskType.AUTONOMY: create_agent_config(
            name="autonomy_risk_evaluator",
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è",
            **base_config_params
        ),
        RiskType.REGULATORY: create_agent_config(
            name="regulatory_risk_evaluator",
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤",
            **base_config_params
        ),
        RiskType.SOCIAL: create_agent_config(
            name="social_risk_evaluator",
            description="–ê–≥–µ–Ω—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –∏ –º–∞–Ω–∏–ø—É–ª—è—Ç–∏–≤–Ω—ã—Ö —Ä–∏—Å–∫–æ–≤",
            **base_config_params
        )
    }
    
    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ (–í–ê–ñ–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã!)
    evaluators = {
        RiskType.ETHICAL: EthicalRiskEvaluator(configs[RiskType.ETHICAL]),
        RiskType.STABILITY: StabilityRiskEvaluator(configs[RiskType.STABILITY]),
        RiskType.SECURITY: SecurityRiskEvaluator(configs[RiskType.SECURITY]),
        RiskType.AUTONOMY: AutonomyRiskEvaluator(configs[RiskType.AUTONOMY]),
        RiskType.REGULATORY: RegulatoryRiskEvaluator(configs[RiskType.REGULATORY]),
        RiskType.SOCIAL: SocialRiskEvaluator(configs[RiskType.SOCIAL])
    }
    
    return evaluators

def create_safe_evaluator_process_method(risk_type: RiskType, risk_description: str):
        """
        –°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –º–µ—Ç–æ–¥ process –¥–ª—è –ª—é–±–æ–≥–æ –∞–≥–µ–Ω—Ç–∞-–æ—Ü–µ–Ω—â–∏–∫–∞
        
        Args:
            risk_type: –¢–∏–ø —Ä–∏—Å–∫–∞ (RiskType enum)
            risk_description: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–∏–ø–∞ —Ä–∏—Å–∫–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –ú–µ—Ç–æ–¥ process –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        """
        
        async def safe_process(
            self, 
            input_data: Dict[str, Any], 
            assessment_id: str
        ) -> AgentTaskResult:
            """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤"""
            start_time = datetime.now()
            task_type = f"{risk_type.value}riskevaluator"
            
            try:
                with LogContext(f"evaluate_{risk_type.value}_risk", assessment_id, self.name):
                    agent_profile = input_data.get("agent_profile", {})
                    agent_data = self._format_agent_data(agent_profile)
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç LLM
                    evaluation_result = await self.evaluate_risk(
                        risk_type=risk_description,
                        agent_data=agent_data,
                        evaluation_criteria=self.get_system_prompt(),
                        assessment_id=assessment_id
                    )
                    
                    # –ë–ï–ó–û–ü–ê–°–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ RiskEvaluation
                    risk_evaluation = RiskEvaluation.create_safe(
                        risk_type=risk_type,
                        evaluator_agent=self.name,
                        raw_data=evaluation_result
                    )
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    self.logger.log_risk_evaluation(
                        self.name,
                        assessment_id,
                        risk_description,
                        risk_evaluation.total_score,
                        risk_evaluation.risk_level.value
                    )
                    
                    # –°–æ–∑–¥–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    execution_time = (datetime.now() - start_time).total_seconds()
                    
                    return AgentTaskResult(
                        agent_name=self.name,
                        task_type=task_type,
                        status=ProcessingStatus.COMPLETED,
                        result_data={"risk_evaluation": risk_evaluation.dict()},
                        start_time=start_time,
                        end_time=datetime.now(),
                        execution_time_seconds=execution_time
                    )
                    
            except Exception as e:
                # –ü—Ä–∏ –ª—é–±–æ–π –æ—à–∏–±–∫–µ —Å–æ–∑–¥–∞–µ–º fallback –æ—Ü–µ–Ω–∫—É
                self.logger.bind_context(assessment_id, self.name).error(
                    f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ {risk_description}: {e}"
                )
                
                # –°–æ–∑–¥–∞–µ–º fallback RiskEvaluation —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                fallback_evaluation = RiskEvaluation.create_from_raw_data(
                    risk_type=risk_type,
                    evaluator_agent=self.name,
                    raw_data={
                        "probability_score": 3,
                        "impact_score": 3,
                        "probability_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}",
                        "impact_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}",
                        "recommendations": ["–ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM"],
                        "confidence_level": 0.3
                    }
                )
                
                execution_time = (datetime.now() - start_time).total_seconds()
                
                return AgentTaskResult(
                    agent_name=self.name,
                    task_type=task_type,
                    status=ProcessingStatus.COMPLETED,  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–π —Å fallback
                    result_data={"risk_evaluation": fallback_evaluation.dict()},
                    start_time=start_time,
                    end_time=datetime.now(),
                    execution_time_seconds=execution_time,
                    error_message=f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã fallback –¥–∞–Ω–Ω—ã–µ: {str(e)}"
                )
        
        return safe_process




def create_evaluators_from_env() -> Dict[RiskType, EvaluationAgent]:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    –û–ë–ù–û–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä
    """
    # –ò–ó–ú–ï–ù–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä, —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —á—Ç–µ–Ω–∏—è env
    return create_all_evaluator_agents()


# ===============================
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# ===============================

def extract_risk_evaluations_from_results(
    evaluation_results: Dict[RiskType, AgentTaskResult]
) -> Dict[RiskType, RiskEvaluation]:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ RiskEvaluation –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤
    """
    risk_evaluations = {}
    
    for risk_type, task_result in evaluation_results.items():
        try:
            print(f"üîç DEBUG extract_risk_evaluations: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {risk_type}")
            
            if (task_result.status == ProcessingStatus.COMPLETED and 
                task_result.result_data and 
                "risk_evaluation" in task_result.result_data):
                
                eval_data = task_result.result_data["risk_evaluation"]
                print(f"üîç DEBUG: eval_data type = {type(eval_data)}")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –æ–±—ä–µ–∫—Ç RiskEvaluation - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                if isinstance(eval_data, RiskEvaluation):
                    print(f"‚úÖ DEBUG: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π RiskEvaluation –¥–ª—è {risk_type}")
                    risk_evaluations[risk_type] = eval_data
                    
                # –ï—Å–ª–∏ —ç—Ç–æ dict - –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–∑–¥–∞—Ç—å RiskEvaluation
                elif isinstance(eval_data, dict):
                    print(f"üîß DEBUG: –°–æ–∑–¥–∞–µ–º RiskEvaluation –∏–∑ dict –¥–ª—è {risk_type}")
                    print(f"üîß DEBUG: eval_data.keys() = {list(eval_data.keys())}")
                    
                    # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ threat_assessments
                        if 'threat_assessments' in eval_data:
                            print(f"‚úÖ DEBUG: threat_assessments –Ω–∞–π–¥–µ–Ω –¥–ª—è {risk_type}")
                        
                        risk_evaluation = RiskEvaluation(**eval_data)
                        risk_evaluations[risk_type] = risk_evaluation
                        print(f"‚úÖ DEBUG: RiskEvaluation —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ –¥–ª—è {risk_type}")
                        
                    except Exception as create_error:
                        print(f"‚ùå DEBUG: –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è RiskEvaluation –¥–ª—è {risk_type}: {create_error}")
                        print(f"‚ùå DEBUG: –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {eval_data}")
                        
                        # –ù–ï –°–û–ó–î–ê–ï–ú FALLBACK - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É –æ—Ü–µ–Ω–∫—É
                        # –ü—É—Å—Ç—å workflow —Å–∞–º —Ä–µ—à–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å
                        continue
                else:
                    print(f"‚ö†Ô∏è DEBUG: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø eval_data –¥–ª—è {risk_type}: {type(eval_data)}")
                    
        except Exception as e:
            print(f"‚ùå DEBUG: –û–±—â–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {risk_type}: {e}")
            import traceback
            traceback.print_exc()
            # –ù–ï —Å–æ–∑–¥–∞–µ–º fallback - –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    
    print(f"üîç DEBUG extract_risk_evaluations: –ò—Ç–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(risk_evaluations)} –æ—Ü–µ–Ω–æ–∫")
    return risk_evaluations


def calculate_overall_risk_score(
    risk_evaluations: Dict[RiskType, RiskEvaluation]
) -> tuple[int, str]:
    """
    –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞ –∏ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
    
    Args:
        risk_evaluations: –û—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ø–æ —Ç–∏–ø–∞–º
        
    Returns:
        Tuple (–æ–±—â–∏–π –±–∞–ª–ª, —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞)
    """
    if not risk_evaluations:
        return 0, "low"
    
    # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–ª —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤
    max_score = max(evaluation.total_score for evaluation in risk_evaluations.values())
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
    if max_score <= 6:
        risk_level = "low"
    elif max_score <= 14:
        risk_level = "medium"
    else:
        risk_level = "high"
    
    return max_score, risk_level


def get_highest_risk_areas(
    risk_evaluations: Dict[RiskType, RiskEvaluation],
    threshold: int = 10
) -> List[RiskType]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–µ–π –Ω–∞–∏–≤—ã—Å—à–µ–≥–æ —Ä–∏—Å–∫–∞
    
    Args:
        risk_evaluations: –û—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
        threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º–∏ –±–∞–ª–ª–∞–º–∏
    """
    high_risk_areas = []
    
    for risk_type, evaluation in risk_evaluations.items():
        if evaluation.total_score >= threshold:
            high_risk_areas.append(risk_type)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –±–∞–ª–ª–∞
    high_risk_areas.sort(
        key=lambda rt: risk_evaluations[rt].total_score, 
        reverse=True
    )
    
    return high_risk_areas


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π
__all__ = [
    # –ê–≥–µ–Ω—Ç—ã-–æ—Ü–µ–Ω—â–∏–∫–∏
    "EthicalRiskEvaluator",
    "StabilityRiskEvaluator", 
    "SecurityRiskEvaluator",
    "AutonomyRiskEvaluator",
    "RegulatoryRiskEvaluator",
    "SocialRiskEvaluator",
    
   # –§–∞–±—Ä–∏–∫–∏
    "create_all_evaluator_agents",
    "create_evaluator_nodes_for_langgraph_safe",  # ‚Üê –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –°–¢–†–û–ö–£
    "create_critic_node_function_fixed",         # ‚Üê –ò –≠–¢–£
    "create_evaluators_from_env",
    
    # –£—Ç–∏–ª–∏—Ç—ã
    "extract_risk_evaluations_from_results",
    "calculate_overall_risk_score",
    "get_highest_risk_areas"
]

# ===============================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø LANGGRAPH
# ===============================

def create_evaluator_nodes_for_langgraph_safe(evaluators: Dict[RiskType, Any]) -> Dict[str, callable]:
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —É–∑–ª–æ–≤ –¥–ª—è LangGraph –±–µ–∑ concurrent updates"""
    
    def create_safe_evaluator_node(risk_type: RiskType, evaluator):
        async def safe_evaluator_node(state: WorkflowState) -> Dict[str, Any]:
            """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —É–∑–µ–ª –æ—Ü–µ–Ω—â–∏–∫–∞ - –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–≤–æ–µ –ø–æ–ª–µ"""
            
            assessment_id = state.get("assessment_id", "unknown")
            agent_profile = state.get("agent_profile", {})
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            input_data = {"agent_profile": agent_profile}
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫–∞
            result = await evaluator.run(input_data, assessment_id)
            
            # –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∫–∞–∂–¥—ã–π –∞–≥–µ–Ω—Ç –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–≤–æ–µ –ø–æ–ª–µ
            field_mapping = {
                RiskType.ETHICAL: "ethical_evaluation",
                RiskType.STABILITY: "stability_evaluation",
                RiskType.SECURITY: "security_evaluation", 
                RiskType.AUTONOMY: "autonomy_evaluation",
                RiskType.REGULATORY: "regulatory_evaluation",
                RiskType.SOCIAL: "social_evaluation"
            }
            
            field_name = field_mapping[risk_type]
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª—è
            return {field_name: result.dict()}
        
        return safe_evaluator_node
    
    # –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã –¥–ª—è –≤—Å–µ—Ö –æ—Ü–µ–Ω—â–∏–∫–æ–≤
    nodes = {}
    for risk_type, evaluator in evaluators.items():
        node_name = f"{risk_type.value}_evaluator_node"
        nodes[node_name] = create_safe_evaluator_node(risk_type, evaluator)
    
    return nodes

def create_critic_node_function_fixed(critic_agent):
    """–°–æ–∑–¥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —É–∑–ª–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è LangGraph"""
    
    async def critic_node(state: WorkflowState) -> Dict[str, Any]:
        """–£–∑–µ–ª –∫—Ä–∏—Ç–∏–∫–∞ –≤ LangGraph workflow - –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        
        assessment_id = state.get("assessment_id", "unknown")
        agent_profile = state.get("agent_profile", {})
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ –∏–∑ –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        evaluation_results = state.get_evaluation_results()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏
        valid_results = {k: v for k, v in evaluation_results.items() if v is not None}
        
        if not valid_results:
            critic_agent.logger.bind_context(assessment_id, "critic").warning(
                "‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∏"
            )
            return {"critic_results": {}}
        
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∫—Ä–∏—Ç–∏–∫—É –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
            critic_results = await critic_agent.critique_multiple_evaluations(
                evaluation_results=valid_results,
                agent_profile=agent_profile,
                assessment_id=assessment_id
            )
            
            return {"critic_results": critic_results}
            
        except Exception as e:
            critic_agent.logger.bind_context(assessment_id, "critic").error(
                f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —É–∑–ª–µ –∫—Ä–∏—Ç–∏–∫–∞: {e}"
            )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å workflow
            return {"critic_results": {}}
    
    return critic_node
