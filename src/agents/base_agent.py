# src/agents/base_agent.py
"""
–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—â–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤
"""

"""
–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –ò–ò-–∞–≥–µ–Ω—Ç–æ–≤
–ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å DeepSeek –∫–ª–∏–µ–Ω—Ç–∞–º–∏
"""

import asyncio
import json
import re
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
from dataclasses import dataclass

from ..utils.llm_client import LLMClient, LLMConfig, LLMMessage, DeepSeekRiskAnalysisLLMClient, \
    GigaChatRiskAnalysisLLMClient, RiskAnalysisLLMClient, DeepSeekLLMClient, GigaChatLLMClient
from ..utils.llm_config_manager import get_llm_config_manager, LLMProvider
from ..utils.logger import get_logger, log_agent_execution, log_llm_call
from ..models.risk_models import AgentTaskResult, ProcessingStatus


@dataclass
class AgentConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞"""
    name: str
    description: str
    llm_config: LLMConfig
    max_retries: int = 3
    timeout_seconds: int = 180
    temperature: float = 0.1
    use_risk_analysis_client: bool = False


class BaseAgent(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤"""

    def __init__(self, config: AgentConfig):
        self.config = config
        self.logger = get_logger()

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–∞–±—Ä–∏–∫–∞ –¥–ª—è DeepSeek
        self.llm_client = self._create_appropriate_llm_client(config)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≥–µ–Ω—Ç–∞
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_execution_time": 0.0,
            "average_response_time": 0.0
        }

    def _create_appropriate_llm_client(self, config: AgentConfig):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–µ—Ç–æ–¥: –°–æ–∑–¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π LLM –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""

        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–µ
        manager = get_llm_config_manager()
        provider = manager.get_provider()

        print(f"üîç DEBUG BaseAgent: –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider.value}")
        print(f"üîç DEBUG BaseAgent: –ù—É–∂–µ–Ω risk_analysis_client: {config.use_risk_analysis_client}")

        if config.use_risk_analysis_client:
            # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤
            if provider == LLMProvider.DEEPSEEK:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º DeepSeekRiskAnalysisLLMClient")
                return DeepSeekRiskAnalysisLLMClient(config.llm_config)
            elif provider == LLMProvider.GIGACHAT:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º GigaChatRiskAnalysisLLMClient")
                return GigaChatRiskAnalysisLLMClient(config.llm_config)
            else:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º RiskAnalysisLLMClient (fallback)")
                return RiskAnalysisLLMClient(config.llm_config)
        else:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            if provider == LLMProvider.DEEPSEEK:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º DeepSeekLLMClient (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)")
                return DeepSeekLLMClient(config.llm_config)
            elif provider == LLMProvider.GIGACHAT:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º GigaChatLLMClient (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)")
                return GigaChatLLMClient(config.llm_config)
            else:
                print("‚úÖ –°–æ–∑–¥–∞–µ–º LLMClient (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π)")
                return LLMClient(config.llm_config)

    @property
    def name(self) -> str:
        """–ò–º—è –∞–≥–µ–Ω—Ç–∞"""
        return self.config.name

    @property
    def description(self) -> str:
        """–û–ø–∏—Å–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞"""
        return self.config.description

    @abstractmethod
    async def process(
            self,
            input_data: Dict[str, Any],
            assessment_id: str
    ) -> AgentTaskResult:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
        pass

    @abstractmethod
    def get_system_prompt(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–∞"""
        pass
    
    async def run(
        self, 
        input_data: Dict[str, Any], 
        assessment_id: str
    ) -> AgentTaskResult:
        """
        –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        
        Args:
            input_data: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        """
        task_result = AgentTaskResult(
            agent_name=self.name,
            task_type=self._get_task_type(),
            status=ProcessingStatus.IN_PROGRESS,
            start_time=datetime.now()
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã
        self.logger.log_agent_start(self.name, self._get_task_type(), assessment_id)
        
        for attempt in range(self.config.max_retries):
            try:
                # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                result = await asyncio.wait_for(
                    self.process(input_data, assessment_id),
                    timeout=self.config.timeout_seconds
                )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self._update_stats(True, result.execution_time_seconds or 0)
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—Ö
                self.logger.log_agent_success(
                    self.name, 
                    self._get_task_type(), 
                    assessment_id, 
                    result.execution_time_seconds or 0
                )
                
                return result
                
            except asyncio.TimeoutError:
                error_msg = f"–¢–∞–π–º-–∞—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ({self.config.timeout_seconds}—Å)"
                await self._handle_retry(task_result, error_msg, attempt, assessment_id)
                
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {str(e)}"
                await self._handle_retry(task_result, error_msg, attempt, assessment_id)
        
        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        task_result.status = ProcessingStatus.FAILED
        task_result.end_time = datetime.now()
        task_result.execution_time_seconds = (
            task_result.end_time - task_result.start_time
        ).total_seconds()
        
        self._update_stats(False, task_result.execution_time_seconds)
        
        self.logger.log_agent_error(
            self.name, 
            self._get_task_type(), 
            assessment_id, 
            Exception(task_result.error_message or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞")
        )
        
        return task_result
    
    async def call_llm(
        self,
        system_prompt: str,
        user_message: str,
        context: Optional[str] = None,
        assessment_id: str = "unknown",
        temperature: Optional[float] = None
    ) -> str:
        """
        –í—ã–∑–æ–≤ LLM —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        
        Args:
            system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            user_message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç LLM
        """
        messages = [
            LLMMessage(role="system", content=system_prompt)
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if context:
            messages.append(
                LLMMessage(
                    role="user", 
                    content=f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–ó–∞–¥–∞—á–∞:\n{user_message}"
                )
            )
        else:
            messages.append(LLMMessage(role="user", content=user_message))
        
        # –í—ã–∑—ã–≤–∞–µ–º LLM
        response = await self.llm_client.complete_chat(
            messages=messages,
            temperature=temperature or self.config.temperature
        )
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ LLM
        self.logger.log_llm_request(
            self.name,
            assessment_id,
            response.model,
            response.usage.get("total_tokens", 0)
        )
        
        return response.content

    def _create_structured_fallback(self, expected_format: str, error_message: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""

        if expected_format.upper() == "JSON":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –æ—à–∏–±–∫–µ –∏–ª–∏ –∫–ª–∞—Å—Å—É –∞–≥–µ–Ω—Ç–∞
            if "–ø—Ä–æ—Ñ–∏–ª" in error_message.lower() or "profile" in error_message.lower() or self.name == "enhanced_profiler":
                return {
                    "name": "Unknown Agent",
                    "version": "1.0",
                    "description": f"–ò–ò-–∞–≥–µ–Ω—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º. –ü—Ä–∏—á–∏–Ω–∞: {error_message[:100]}",
                    "agent_type": "other",
                    "llm_model": "unknown",
                    "autonomy_level": "supervised",
                    "data_access": ["internal"],
                    "external_apis": [],
                    "target_audience": "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å–∏—Å—Ç–µ–º—ã",
                    "operations_per_hour": None,
                    "revenue_per_operation": None,
                    "system_prompts": [],
                    "guardrails": [],
                    "source_files": [],
                    "detailed_summary": {
                        "overview": f"–ë–∞–∑–æ–≤—ã–π –æ–±–∑–æ—Ä –∞–≥–µ–Ω—Ç–∞. –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_message[:100]}",
                        "technical_architecture": f"–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ LLM: {error_message[:100]}",
                        "operational_model": f"–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ LLM: {error_message[:100]}"
                    }
                }
            elif "—Ä–∏—Å–∫" in error_message.lower() or "risk" in error_message.lower():
                return {
                    "probability_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ LLM: {error_message[:200]}",
                    "impact_reasoning": f"Fallback –æ—Ü–µ–Ω–∫–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ LLM: {error_message[:200]}",
                    "key_factors": ["–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ—Ç LLM"],
                    #"recommendations": ["–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–∞", "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –æ—Ü–µ–Ω–∫—É", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM"],
                    "confidence_level": 0.1
                }
            else:
                # –û–±—â–∏–π fallback
                return {
                    "error": "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM –æ—Ç–≤–µ—Ç–∞",
                    "error_message": error_message,
                    "fallback_response": True,
                    "timestamp": datetime.now().isoformat()
                }

        return {"error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {expected_format}"}

    def _validate_structured_result(self, result: Any, expected_format: str, logger) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ç LLM"""

        if not result:
            logger.warning("‚ùå –ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç LLM")
            return False

        if expected_format.upper() == "JSON":
            if not isinstance(result, dict):
                logger.warning(f"‚ùå –û–∂–∏–¥–∞–ª—Å—è dict, –ø–æ–ª—É—á–µ–Ω {type(result)}")
                return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            if "name" in result:  # –≠—Ç–æ –ø—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞
                required_fields = ["name", "description", "agent_type"]
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    logger.warning(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing_fields}")
                    return False

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
                description = result.get("description", "")
                if len(str(description)) < 100:
                    logger.warning(f"‚ùå –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {len(str(description))} —Å–∏–º–≤–æ–ª–æ–≤")
                    return False

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
            elif "probability_score" in result:  # –≠—Ç–æ –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
                required_fields = ["probability_score", "impact_score", "risk_level"]
                missing_fields = [field for field in required_fields if field not in result]
                if missing_fields:
                    logger.warning(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –æ—Ü–µ–Ω–∫–∏: {missing_fields}")
                    return False

        logger.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        return True

    # 3. –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    def _log_result_statistics(self, result: Dict[str, Any], logger):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""

        if not isinstance(result, dict):
            return

        # –û–±—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å {len(result)} –ø–æ–ª—è–º–∏")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è –∞–≥–µ–Ω—Ç–∞
        if "description" in result:
            desc_len = len(str(result["description"]))
            logger.info(f"üìù –î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {desc_len} —Å–∏–º–≤–æ–ª–æ–≤")

            if desc_len < 200:
                logger.warning(f"‚ö†Ô∏è –ö–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {desc_len} < 200 —Å–∏–º–≤–æ–ª–æ–≤")
            elif desc_len >= 500:
                logger.info(f"üéØ –û—Ç–ª–∏—á–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è: {desc_len} >= 500 —Å–∏–º–≤–æ–ª–æ–≤")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è detailed_summary
        if "detailed_summary" in result and isinstance(result["detailed_summary"], dict):
            summary = result["detailed_summary"]
            for section, content in summary.items():
                content_len = len(str(content))
                logger.info(f"üìã {section}: {content_len} —Å–∏–º–≤–æ–ª–æ–≤")

                if content_len < 100:
                    logger.warning(f"‚ö†Ô∏è –ö–æ—Ä–æ—Ç–∫–∞—è —Å–µ–∫—Ü–∏—è {section}: {content_len} < 100")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Å–ø–∏—Å–∫–æ–≤
        for field in ["system_prompts", "guardrails", "external_apis"]:
            if field in result and isinstance(result[field], list):
                count = len(result[field])
                logger.info(f"üìã {field}: {count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

    async def call_llm_structured(
            self,
            data_to_analyze: str,
            extraction_prompt: str,
            assessment_id: str,
            expected_format: str = "JSON"
    ) -> Dict[str, Any]:
        """–í—ã–∑–æ–≤ LLM –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""

        if not isinstance(self.llm_client, (LLMClient, RiskAnalysisLLMClient)):
            raise ValueError("LLM –∫–ª–∏–µ–Ω—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã")

        # üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞
        prompt_length = len(extraction_prompt)
        data_length = len(data_to_analyze)
        bound_logger = self.logger.bind_context(assessment_id, self.name)

        bound_logger.info(f"üìè –î–ª–∏–Ω–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞: {prompt_length} —Å–∏–º–≤–æ–ª–æ–≤")
        bound_logger.info(f"üìè –î–ª–∏–Ω–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {data_length} —Å–∏–º–≤–æ–ª–æ–≤")
        bound_logger.info(f"üìè –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {prompt_length + data_length} —Å–∏–º–≤–æ–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–∞
        if prompt_length < 3000:
            bound_logger.warning(f"‚ö†Ô∏è –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–º –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π")
        else:
            bound_logger.info(f"‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–ª–∏–Ω–µ –≤ –ø—Ä–æ–º–ø—Ç–µ
        if "–ú–ò–ù–ò–ú–£–ú" in extraction_prompt and ("—Å–∏–º–≤–æ–ª–æ–≤" in extraction_prompt or "—Å–ª–æ–≤" in extraction_prompt):
            bound_logger.info("‚úÖ –í –ø—Ä–æ–º–ø—Ç–µ –Ω–∞–π–¥–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π")
        else:
            bound_logger.warning("‚ö†Ô∏è –í –ø—Ä–æ–º–ø—Ç–µ –ù–ï –Ω–∞–π–¥–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–ª–∏–Ω–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π")

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
        max_attempts = 3
        last_error = None

        for attempt in range(max_attempts):
            try:
                bound_logger.info(f"ü§ñ LLM –∑–∞–ø—Ä–æ—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_attempts})...")

                # –í–∞—Ä–∏–∞—Ü–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
                temperature = 0.05 if attempt == 0 else 0.1 if attempt == 1 else 0.15

                # –î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –¥–æ–±–∞–≤–ª—è–µ–º —É—Å–∏–ª–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç
                enhanced_prompt = extraction_prompt
                if attempt > 0:
                    enhanced_prompt += f"\n\n‚ùó –í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}. –ü—Ä–µ–¥—ã–¥—É—â–∏–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤–µ—Ä–Ω–∏ –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –æ—à–∏–±–æ–∫!"

                result = await self.llm_client.extract_structured_data(
                    data_to_analyze=data_to_analyze,
                    extraction_prompt=enhanced_prompt,
                    expected_format=expected_format
                )

                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if self._validate_structured_result(result, expected_format, bound_logger):
                    bound_logger.info(f"‚úÖ LLM –≤–µ—Ä–Ω—É–ª –≤–∞–ª–∏–¥–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")

                    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    self._log_result_statistics(result, bound_logger)

                    return result
                else:
                    raise ValueError(f"LLM –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")

            except Exception as e:
                last_error = e
                bound_logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: {str(e)[:100]}...")

                if attempt < max_attempts - 1:
                    import asyncio
                    await asyncio.sleep(1 + attempt)  # –ü—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å - —Å–æ–∑–¥–∞–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        bound_logger.error(f"‚ùå –í—Å–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫ LLM –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ —É–¥–∞–ª–∏—Å—å. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_error}")

        fallback_result = self._create_structured_fallback(expected_format, str(last_error))
        bound_logger.warning(f"üîß –°–æ–∑–¥–∞–Ω fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {type(fallback_result)}")

        return fallback_result
    
    def validate_result(self, result_data: Dict[str, Any]) -> bool:
        """
        –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–≥–µ–Ω—Ç–∞
        –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        
        Args:
            result_data: –î–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            
        Returns:
            True –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–µ–Ω
        """
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if not isinstance(result_data, dict):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö)
        required_fields = self._get_required_result_fields()
        for field in required_fields:
            if field not in result_data:
                return False
        
        return True
    
    def _get_task_type(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏ –∞–≥–µ–Ω—Ç–∞"""
        return self.__class__.__name__.lower().replace('agent', '')
    
    def _get_required_result_fields(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö)"""
        return []
    
    async def _handle_retry(
        self, 
        task_result: AgentTaskResult, 
        error_msg: str, 
        attempt: int, 
        assessment_id: str
    ):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏"""
        task_result.error_message = error_msg
        
        if attempt < self.config.max_retries - 1:
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä
            self.logger.log_agent_retry(
                self.name, 
                self._get_task_type(), 
                assessment_id, 
                attempt + 1
            )
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
            await asyncio.sleep(1.0 * (attempt + 1))
        else:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - —Ñ–∏–∫—Å–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
            task_result.status = ProcessingStatus.FAILED
            task_result.end_time = datetime.now()
    
    def _update_stats(self, success: bool, execution_time: float):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–≥–µ–Ω—Ç–∞"""
        self.stats["total_requests"] += 1
        self.stats["total_execution_time"] += execution_time
        
        if success:
            self.stats["successful_requests"] += 1
        else:
            self.stats["failed_requests"] += 1
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
        self.stats["average_response_time"] = (
            self.stats["total_execution_time"] / self.stats["total_requests"]
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞"""
        return {
            **self.stats,
            "success_rate": (
                self.stats["successful_requests"] / max(self.stats["total_requests"], 1)
            ),
            "agent_name": self.name,
            "agent_type": self._get_task_type()
        }
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM
            llm_healthy = await self.llm_client.health_check()
            
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            return llm_healthy
            
        except Exception:
            return False
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –∞–≥–µ–Ω—Ç–∞"""
        try:
            await self.llm_client.close()
        except Exception:
            pass
    
    def __str__(self) -> str:
        return f"{self.__class__.__name__}(name={self.name})"
    
    def __repr__(self) -> str:
        return self.__str__()


class AnalysisAgent(BaseAgent):
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    –†–∞—Å—à–∏—Ä—è–µ—Ç BaseAgent —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    """
    
    def __init__(self, config: AgentConfig):
        super().__init__(config)
    
    async def analyze_data(
        self,
        data: str,
        analysis_type: str,
        criteria: str,
        assessment_id: str,
        examples: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –û–±—â–∏–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞
            criteria: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
            assessment_id: ID –æ—Ü–µ–Ω–∫–∏
            examples: –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        system_prompt = self.get_system_prompt()
        
        if examples:
            system_prompt += f"\n\n–ü–†–ò–ú–ï–†–´:\n{examples}"
        
        user_message = f"""–î–ê–ù–ù–´–ï –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{data}

–¢–ò–ü –ê–ù–ê–õ–ò–ó–ê: {analysis_type}

–ö–†–ò–¢–ï–†–ò–ò:
{criteria}

–í—ã–ø–æ–ª–Ω–∏ –∞–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º."""
        
        response = await self.call_llm(
            system_prompt=system_prompt,
            user_message=user_message,
            assessment_id=assessment_id
        )
        
        return {"analysis_result": response, "analysis_type": analysis_type}


class EvaluationAgent(BaseAgent):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤-–æ—Ü–µ–Ω—â–∏–∫–æ–≤ —Ä–∏—Å–∫–æ–≤"""

    def __init__(self, config: AgentConfig):
        # –ö–†–ò–¢–ò–ß–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –ü–ï–†–ï–î –≤—ã–∑–æ–≤–æ–º super().__init__
        config.use_risk_analysis_client = True
        super().__init__(config)

        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–æ–∑–¥–∞–ª—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø –∫–ª–∏–µ–Ω—Ç–∞
        expected_types = (DeepSeekRiskAnalysisLLMClient, GigaChatRiskAnalysisLLMClient, RiskAnalysisLLMClient)

        if not isinstance(self.llm_client, expected_types):
            raise ValueError(
                f"EvaluationAgent —Ç—Ä–µ–±—É–µ—Ç RiskAnalysisLLMClient –∏–ª–∏ –µ–≥–æ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–æ–≤, "
                f"–ø–æ–ª—É—á–µ–Ω: {type(self.llm_client)}"
            )

        print(f"‚úÖ EvaluationAgent —Å–æ–∑–¥–∞–Ω —Å –∫–ª–∏–µ–Ω—Ç–æ–º: {type(self.llm_client).__name__}")

    # ===== –ù–û–í–´–ï –ù–ê–°–õ–ï–î–£–ï–ú–´–ï –ú–ï–¢–û–î–´ =====

    def _format_enhanced_agent_data(
            self,
            agent_profile: Dict[str, Any],
            llm_analysis_results: Dict[str, Any],
            architecture_graph: str
    ) -> str:
        """–ë–ê–ó–û–í–´–ô –º–µ—Ç–æ–¥ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤"""

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–≥–µ–Ω—Ç–µ
        basic_info = self._format_basic_agent_info(agent_profile)

        # –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å–∞–º–º–∞—Ä–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
        detailed_summary = self._format_detailed_summary(agent_profile.get('detailed_summary', {}))
        if detailed_summary:
            basic_info += detailed_summary

        # LLM –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        llm_analysis = self._format_llm_analysis_results(llm_analysis_results)
        if llm_analysis:
            basic_info += llm_analysis

        # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
        architecture_analysis = self._format_architecture_graph(architecture_graph)
        if architecture_analysis:
            basic_info += architecture_analysis

        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_metrics = self._format_quality_metrics(agent_profile)
        if quality_metrics:
            basic_info += quality_metrics

        return basic_info

    def _format_basic_agent_info(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–≥–µ–Ω—Ç–µ"""
        return f"""=== –ë–ê–ó–û–í–´–ô –ü–†–û–§–ò–õ–¨ –ê–ì–ï–ù–¢–ê ===
–ù–∞–∑–≤–∞–Ω–∏–µ: {agent_profile.get('name', 'Unknown')}
–í–µ—Ä—Å–∏—è: {agent_profile.get('version', '1.0')}
–¢–∏–ø –∞–≥–µ–Ω—Ç–∞: {agent_profile.get('agent_type', 'unknown')}
LLM –ú–æ–¥–µ–ª—å: {agent_profile.get('llm_model', 'unknown')}
–£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏: {agent_profile.get('autonomy_level', 'supervised')}
–î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: {', '.join(agent_profile.get('data_access', []))}
–¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {agent_profile.get('target_audience', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–û–ø–µ—Ä–∞—Ü–∏–π –≤ —á–∞—Å: {agent_profile.get('operations_per_hour', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')}
–î–æ—Ö–æ–¥ —Å –æ–ø–µ—Ä–∞—Ü–∏–∏: {agent_profile.get('revenue_per_operation', '–ù–µ —É–∫–∞–∑–∞–Ω–æ')} —Ä—É–±

–û–ü–ò–°–ê–ù–ò–ï –ê–ì–ï–ù–¢–ê:
{agent_profile.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}

–°–ò–°–¢–ï–ú–ù–´–ï –ü–†–û–ú–ü–¢–´:
{chr(10).join(agent_profile.get('system_prompts', ['–°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò (GUARDRAILS):
{chr(10).join(agent_profile.get('guardrails', ['–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã']))}

–í–ù–ï–®–ù–ò–ï API –ò –ò–ù–¢–ï–ì–†–ê–¶–ò–ò:
{', '.join(agent_profile.get('external_apis', ['–í–Ω–µ—à–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç']))}

–ò–°–•–û–î–ù–´–ï –§–ê–ô–õ–´:
{', '.join(agent_profile.get('source_files', ['–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç']))}"""

    def _format_detailed_summary(self, detailed_summary: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        if not detailed_summary:
            return ""

        summary_sections = ["\n\n=== –î–ï–¢–ê–õ–¨–ù–û–ï –°–ê–ú–ú–ê–†–ò –ü–†–û–§–ê–ô–õ–ï–†–ê ==="]

        # –û–±–∑–æ—Ä –∞–≥–µ–Ω—Ç–∞
        if 'overview' in detailed_summary:
            summary_sections.append(f"""
üìã –û–ë–ó–û–† –ê–ì–ï–ù–¢–ê:
{detailed_summary['overview']}""")

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        if 'technical_architecture' in detailed_summary:
            summary_sections.append(f"""
üèóÔ∏è –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
{detailed_summary['technical_architecture']}""")

        # –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        if 'operational_model' in detailed_summary:
            summary_sections.append(f"""
‚öôÔ∏è –û–ü–ï–†–ê–¶–ò–û–ù–ù–ê–Ø –ú–û–î–ï–õ–¨:
{detailed_summary['operational_model']}""")

        # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if 'risk_analysis' in detailed_summary:
            summary_sections.append(f"""
‚ö†Ô∏è –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ò–°–ö–û–í:
{detailed_summary['risk_analysis']}""")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        if 'security_recommendations' in detailed_summary:
            summary_sections.append(f"""
üîí –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{detailed_summary['security_recommendations']}""")

        # –í—ã–≤–æ–¥—ã –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–∞
        if 'conclusions' in detailed_summary:
            summary_sections.append(f"""
üéØ –í–´–í–û–î–´ –ü–†–û–§–ê–ô–õ–ï–†–ê:
{detailed_summary['conclusions']}""")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
        additional_sections = {
            'business_logic': 'üíº –ë–ò–ó–ù–ï–°-–õ–û–ì–ò–ö–ê',
            'data_flow': 'üìä –ü–û–¢–û–ö–ò –î–ê–ù–ù–´–•',
            'integration_points': 'üîó –¢–û–ß–ö–ò –ò–ù–¢–ï–ì–†–ê–¶–ò–ò',
            'monitoring_capabilities': 'üìà –í–û–ó–ú–û–ñ–ù–û–°–¢–ò –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê',
            'scalability_analysis': 'üìà –ê–ù–ê–õ–ò–ó –ú–ê–°–®–¢–ê–ë–ò–†–£–ï–ú–û–°–¢–ò',
            'compliance_aspects': 'üìã –ê–°–ü–ï–ö–¢–´ –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø'
        }

        for section_key, section_title in additional_sections.items():
            if section_key in detailed_summary:
                summary_sections.append(f"""
{section_title}:
{detailed_summary[section_key]}""")

        return '\n'.join(summary_sections)

    def _format_llm_analysis_results(self, llm_analysis_results: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ LLM –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤"""
        if not llm_analysis_results:
            return ""

        analysis_sections = ["\n\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ LLM –ê–ù–ê–õ–ò–ó–ê –ö–û–ù–¢–ï–ö–°–¢–û–í ==="]

        context_titles = {
            'agent_overview': 'üéØ –û–ë–ó–û–† –ê–ì–ï–ù–¢–ê',
            'technical_architecture': 'üèóÔ∏è –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê',
            'prompts_and_instructions': 'üí¨ –ü–†–û–ú–ü–¢–´ –ò –ò–ù–°–¢–†–£–ö–¶–ò–ò',
            'business_logic': 'üíº –ë–ò–ó–ù–ï–°-–õ–û–ì–ò–ö–ê',
            'configurations': '‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò',
            'supporting_docs': 'üìö –ü–û–î–î–ï–†–ñ–ò–í–ê–Æ–©–ê–Ø –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø'
        }

        for context_type, context_result in llm_analysis_results.items():
            context_title = context_titles.get(context_type, context_type.replace('_', ' ').title())

            if isinstance(context_result, dict) and 'aggregated_analysis' in context_result:
                analysis = context_result['aggregated_analysis']
                formatted_analysis = self._format_analysis_summary(analysis, detailed=True)

                analysis_sections.append(f"""
{context_title}:
{formatted_analysis}

–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞:
- –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context_type}
- –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {context_result.get('metadata', {}).get('total_chunks', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}
- –£—Å–ø–µ—à–Ω—ã—Ö —á–∞–Ω–∫–æ–≤: {context_result.get('metadata', {}).get('successful_chunks', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}""")

            elif isinstance(context_result, dict) and 'error' in context_result:
                analysis_sections.append(f"""
{context_title}:
‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {context_result['error']}""")

        return '\n'.join(analysis_sections)

    def _format_analysis_summary(self, analysis: Any, detailed: bool = False) -> str:
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        if not analysis:
            return "–î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"

        if isinstance(analysis, dict):
            summary_parts = []

            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            priority_fields = [
                'summary', 'description', 'overview', 'key_findings', 'main_points',
                'technical_details', 'security_aspects', 'risk_indicators', 'capabilities', 'limitations', 'dependencies'
            ]

            # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–æ–ª—è
            for field in priority_fields:
                if field in analysis:
                    value = analysis[field]
                    formatted_value = self._format_field_value(field, value, detailed)
                    if formatted_value:
                        summary_parts.append(formatted_value)

            # –ó–∞—Ç–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
            for key, value in analysis.items():
                if key not in priority_fields and value:
                    formatted_value = self._format_field_value(key, value, detailed)
                    if formatted_value:
                        summary_parts.append(formatted_value)

            return '\n'.join(summary_parts) if summary_parts else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"

        # –ï—Å–ª–∏ –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        text_repr = str(analysis)
        if detailed:
            return text_repr[:1000] + ("..." if len(text_repr) > 1000 else "")
        else:
            return text_repr[:300] + ("..." if len(text_repr) > 300 else "")

    def _format_field_value(self, field_name: str, value: Any, detailed: bool) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª—è —Å —É—á–µ—Ç–æ–º –µ–≥–æ —Ç–∏–ø–∞"""
        if not value:
            return ""

        field_title = field_name.replace('_', ' ').title()

        if isinstance(value, str):
            if detailed:
                max_length = 500
            else:
                max_length = 200

            if len(value) > max_length:
                return f"{field_title}: {value[:max_length]}..."
            else:
                return f"{field_title}: {value}"

        elif isinstance(value, list):
            if detailed:
                items = value[:10]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                formatted_items = [str(item)[:100] for item in items]
            else:
                items = value[:5]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ 5 —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                formatted_items = [str(item)[:50] for item in items]

            items_text = ', '.join(formatted_items)
            if len(value) > len(items):
                items_text += f" ... (–≤—Å–µ–≥–æ {len(value)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)"

            return f"{field_title}: {items_text}"

        elif isinstance(value, dict):
            if detailed:
                dict_items = []
                for k, v in list(value.items())[:8]:  # –î–æ 8 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–ª–æ–≤–∞—Ä—è
                    dict_items.append(f"{k}: {str(v)[:80]}")
                return f"{field_title}: {{{', '.join(dict_items)}}}"
            else:
                return f"{field_title}: {str(value)[:150]}..."

        else:
            return f"{field_title}: {str(value)[:100]}"

    def _format_architecture_graph(self, architecture_graph: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã Mermaid"""
        if not architecture_graph or not architecture_graph.strip():
            return ""

        return f"""

=== üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–ê–Ø –î–ò–ê–ì–†–ê–ú–ú–ê ===
{architecture_graph}

–ê–ù–ê–õ–ò–ó –ê–†–•–ò–¢–ï–ö–¢–£–†–´:
{self._analyze_mermaid_architecture(architecture_graph)}"""

    def _analyze_mermaid_architecture(self, mermaid_content: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ä–∏—Å–∫–æ–≤"""
        if not mermaid_content:
            return "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

        analysis_points = []
        lines = mermaid_content.split('\n')

        # –ü–æ–¥—Å—á–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        nodes = [line for line in lines if '-->' in line or '---' in line]
        analysis_points.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(nodes)} —Å–≤—è–∑–µ–π –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ")

        # –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫ —Ä–∏—Å–∫–∞
        risk_indicators = {
            'API': '–í–Ω–µ—à–Ω–∏–µ API –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏',
            'External': '–í–Ω–µ—à–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏',
            'Database': '–î–æ—Å—Ç—É–ø –∫ –±–∞–∑–∞–º –¥–∞–Ω–Ω—ã—Ö',
            'User': '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ',
            'Auth': '–°–∏—Å—Ç–µ–º—ã –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏',
            'Security': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏'
        }

        found_components = []
        for indicator, description in risk_indicators.items():
            if any(indicator.lower() in line.lower() for line in lines):
                found_components.append(f"- {description}")

        if found_components:
            analysis_points.append("–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:")
            analysis_points.extend(found_components)

        # –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if len(nodes) > 10:
            analysis_points.append("‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (>10 —Å–≤—è–∑–µ–π)")
        elif len(nodes) > 5:
            analysis_points.append("‚ö° –£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
        else:
            analysis_points.append("‚úÖ –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞")

        return '\n'.join(analysis_points)

    def _format_profiler_recommendations(self, recommendations: List[str]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–∞"""
        if not recommendations:
            return ""

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categorized_recs = self._categorize_recommendations(recommendations)

        sections = ["\n\n=== üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–†–û–§–ê–ô–õ–ï–†–ê ==="]

        for category, recs in categorized_recs.items():
            if recs:
                sections.append(f"\n{category}:")
                for rec in recs[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                    sections.append(f"  ‚Ä¢ {rec}")

        # –ï—Å–ª–∏ –µ—Å—Ç—å –µ—â–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö –æ—Ç–¥–µ–ª—å–Ω–æ
        total_shown = sum(min(5, len(recs)) for recs in categorized_recs.values())
        if len(recommendations) > total_shown:
            sections.append(f"\n... –∏ –µ—â–µ {len(recommendations) - total_shown} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")

        return '\n'.join(sections)

    def _categorize_recommendations(self, recommendations: List[str]) -> Dict[str, List[str]]:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ç–∏–ø–∞–º"""
        categories = {
            'üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å': [],
            '‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞': [],
            'üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å': [],
            'üìã –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º': [],
            'üéØ –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏': []
        }

        security_keywords = ['–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', 'security', '–∑–∞—â–∏—Ç–∞', '—É—è–∑–≤–∏–º–æ—Å—Ç—å', '—à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ']
        tech_keywords = ['–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞', '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫', '–∫–æ–¥', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è']
        monitoring_keywords = ['–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥', '–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ', '–∫–æ–Ω—Ç—Ä–æ–ª—å', '–∞—É–¥–∏—Ç', '–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ']
        compliance_keywords = ['—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ', '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '—Ä–µ–≥—É–ª—è—Ç–æ—Ä', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç', '–ø–æ–ª–∏—Ç–∏–∫–∞']

        for rec in recommendations:
            rec_lower = rec.lower()

            if any(keyword in rec_lower for keyword in security_keywords):
                categories['üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'].append(rec)
            elif any(keyword in rec_lower for keyword in tech_keywords):
                categories['‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞'].append(rec)
            elif any(keyword in rec_lower for keyword in monitoring_keywords):
                categories['üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å'].append(rec)
            elif any(keyword in rec_lower for keyword in compliance_keywords):
                categories['üìã –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º'].append(rec)
            else:
                categories['üéØ –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'].append(rec)

        # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        return {k: v for k, v in categories.items() if v}

    def _format_quality_metrics(self, agent_profile: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        metrics_info = []

        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
        if 'created_at' in agent_profile:
            metrics_info.append(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è: {agent_profile['created_at']}")

        if 'updated_at' in agent_profile:
            metrics_info.append(f"–î–∞—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {agent_profile['updated_at']}")

        # –ú–µ—Ç—Ä–∏–∫–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        complexity_metrics = []

        system_prompts_count = len(agent_profile.get('system_prompts', []))
        if system_prompts_count > 0:
            complexity_metrics.append(f"–°–∏—Å—Ç–µ–º–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤: {system_prompts_count}")

        guardrails_count = len(agent_profile.get('guardrails', []))
        if guardrails_count > 0:
            complexity_metrics.append(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {guardrails_count}")

        external_apis_count = len(agent_profile.get('external_apis', []))
        if external_apis_count > 0:
            complexity_metrics.append(f"–í–Ω–µ—à–Ω–∏—Ö API: {external_apis_count}")

        data_access_count = len(agent_profile.get('data_access', []))
        if data_access_count > 0:
            complexity_metrics.append(f"–¢–∏–ø–æ–≤ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º: {data_access_count}")

        if metrics_info or complexity_metrics:
            result = ["\n\n=== üìä –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ò –°–õ–û–ñ–ù–û–°–¢–ò ==="]

            if metrics_info:
                result.extend(metrics_info)

            if complexity_metrics:
                result.append("\n–ú–µ—Ç—Ä–∏–∫–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:")
                result.extend([f"  ‚Ä¢ {metric}" for metric in complexity_metrics])

                # –û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
                total_complexity = system_prompts_count + guardrails_count + external_apis_count
                if total_complexity > 15:
                    result.append("  ‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞")
                elif total_complexity > 8:
                    result.append("  ‚ö° –£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞")
                else:
                    result.append("  ‚úÖ –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∞–≥–µ–Ω—Ç–∞")

            return '\n'.join(result)

        return ""

    async def evaluate_risk(
            self,
            risk_type: str,
            agent_data: str,
            evaluation_criteria: str,
            assessment_id: str,
            examples: Optional[str] = None
    ) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞"""

        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–ª–∏–µ–Ω—Ç–∞
            if not hasattr(self.llm_client, 'evaluate_risk'):
                raise ValueError(f"LLM –∫–ª–∏–µ–Ω—Ç {type(self.llm_client)} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç evaluate_risk")

            # –í—ã–∑—ã–≤–∞–µ–º –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞
            result = await self.llm_client.evaluate_risk(
                risk_type=risk_type,
                agent_data=agent_data,
                evaluation_criteria=evaluation_criteria,
                examples=examples
            )

            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            validated_result = self._ensure_required_fields(result)

            # –õ–æ–≥–∏—Ä—É–µ–º –æ—Ü–µ–Ω–∫—É
            self.logger.log_risk_evaluation(
                self.name,
                assessment_id,
                risk_type,
                validated_result["total_score"],
                validated_result["risk_level"]
            )

            return validated_result

        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.logger.bind_context(assessment_id, self.name).error(
                f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞ {risk_type}: {e}"
            )

            return self._get_default_evaluation_data(f"–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞: {str(e)}")
    
    def _get_required_result_fields(self) -> List[str]:
        """–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""
        return [
            "probability_score", "impact_score", "total_score", 
            "risk_level", "probability_reasoning", "impact_reasoning"
        ]
    def _parse_llm_response(self, response_content: str) -> Dict[str, Any]:
        """–ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å—é"""
        
        try:
            # –®–∞–≥ 1: –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            cleaned_content = response_content.strip()
            
            # –£–¥–∞–ª—è–µ–º —Ç–µ–≥–∏ <think>...</think> –µ—Å–ª–∏ –µ—Å—Ç—å
            import re
            cleaned_content = re.sub(r'<think>.*?</think>', '', cleaned_content, flags=re.DOTALL)
            cleaned_content = cleaned_content.strip()
            
            # –£–¥–∞–ª—è–µ–º markdown –±–ª–æ–∫–∏
            if "```json" in cleaned_content:
                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON –±–ª–æ–∫–∏
                json_blocks = re.findall(r'```json\s*(.*?)\s*```', cleaned_content, re.DOTALL)
                if json_blocks:
                    json_content = json_blocks[-1].strip()  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥, –±–µ—Ä–µ–º –≤—Å–µ –ø–æ—Å–ª–µ ```json
                    start = cleaned_content.find("```json") + 7
                    json_content = cleaned_content[start:].strip()
            else:
                # –ò—â–µ–º JSON –ø–æ —Ñ–∏–≥—É—Ä–Ω—ã–º —Å–∫–æ–±–∫–∞–º
                json_match = re.search(r'\{.*\}', cleaned_content, re.DOTALL)
                if json_match:
                    json_content = json_match.group().strip()
                else:
                    json_content = cleaned_content
            
            # –®–∞–≥ 2: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ JSON
            # –£–±–∏—Ä–∞–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ü–µ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –ø–æ—Å–ª–µ }
            if '}' in json_content:
                end_pos = json_content.rfind('}')
                json_content = json_content[:end_pos + 1]
            
            # –®–∞–≥ 3: –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å JSON
            try:
                parsed_data = json.loads(json_content)
            except json.JSONDecodeError:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ—á–∏–Ω–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ JSON
                json_content = self._fix_common_json_errors(json_content)
                parsed_data = json.loads(json_content)
            
            # –®–∞–≥ 4: –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï - –≤—Å–µ–≥–¥–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            parsed_data = self._ensure_required_fields(parsed_data)
            
            return parsed_data
            
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.logger.bind_context("unknown", self.name).warning(
                f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM –æ—Ç–≤–µ—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}"
            )
            self.logger.bind_context("unknown", self.name).debug(
                f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç: {response_content[:200]}..."
            )
            return self._get_default_evaluation_data(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")

    def _fix_common_json_errors(self, json_content: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ JSON –æ—Ç LLM"""
        
        # –£–±–∏—Ä–∞–µ–º trailing commas
        json_content = re.sub(r',\s*}', '}', json_content)
        json_content = re.sub(r',\s*]', ']', json_content)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö
        # –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–æ—Ä–∞–±–æ—Ç–∫–∏
        json_content = re.sub(r'(?<!\\)"(?=[^,}\]]*[,}\]])', '\\"', json_content)
        
        # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ JSON (–µ—Å–ª–∏ –µ—Å—Ç—å)
        json_content = re.sub(r'//.*?\n', '\n', json_content)
        json_content = re.sub(r'/\*.*?\*/', '', json_content, flags=re.DOTALL)
        
        return json_content

    def _ensure_required_fields(self, parsed_data: Dict[str, Any]) -> Dict[str, Any]:
        """–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏"""

        required_fields = {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ LLM",
            "impact_reasoning": "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ LLM",
            "key_factors": [],
            "recommendations": [],
            "confidence_level": 0.7
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
        for field, default_value in required_fields.items():
            if field not in parsed_data or parsed_data[field] is None:
                parsed_data[field] = default_value

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        parsed_data = self._validate_and_fix_field_types(parsed_data)

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
        parsed_data = self._validate_business_logic(parsed_data)

        return parsed_data

    def _validate_numeric_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è probability_score (1-5)
        try:
            data["probability_score"] = int(data["probability_score"])
            if not (1 <= data["probability_score"] <= 5):
                data["probability_score"] = 3
        except (ValueError, TypeError):
            data["probability_score"] = 3
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è impact_score (1-5)
        try:
            data["impact_score"] = int(data["impact_score"])
            if not (1 <= data["impact_score"] <= 5):
                data["impact_score"] = 3
        except (ValueError, TypeError):
            data["impact_score"] = 3
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è confidence_level (0.0-1.0)
        try:
            data["confidence_level"] = float(data["confidence_level"])
            if not (0.0 <= data["confidence_level"] <= 1.0):
                data["confidence_level"] = 0.7
        except (ValueError, TypeError):
            data["confidence_level"] = 0.7
        
        return data

    def _validate_string_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è risk_level
        valid_levels = ["low", "medium", "high"]
        if data.get("risk_level") not in valid_levels:
            data["risk_level"] = "medium"
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è reasoning –ø–æ–ª–µ–π
        if not data.get("probability_reasoning") or len(str(data["probability_reasoning"]).strip()) < 10:
            data["probability_reasoning"] = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
        
        if not data.get("impact_reasoning") or len(str(data["impact_reasoning"]).strip()) < 10:
            data["impact_reasoning"] = "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
        
        return data

    def _validate_list_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–∫–æ–≤—ã–µ –ø–æ–ª—è"""
        
        list_fields = ["key_factors", "recommendations"]
        
        for field in list_fields:
            if not isinstance(data.get(field), list):
                data[field] = []
            
            # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ None
            data[field] = [
                item for item in data[field] 
                if item and isinstance(item, str) and item.strip()
            ]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            data[field] = data[field][:10]
        
        return data

    def _validate_and_fix_field_types(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–∏–ø—ã –ø–æ–ª–µ–π"""

        # –ß–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è (1-5)
        score_fields = ["probability_score", "impact_score"]
        for field in score_fields:
            try:
                value = int(data[field])
                data[field] = max(1, min(5, value))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 1-5
            except (ValueError, TypeError):
                data[field] = 3  # –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª

        # Confidence level (0.0-1.0)
        try:
            value = float(data["confidence_level"])
            data["confidence_level"] = max(0.0, min(1.0, value))
        except (ValueError, TypeError):
            data["confidence_level"] = 0.7

        # Risk level (enum)
        valid_levels = ["low", "medium", "high"]
        if data.get("risk_level") not in valid_levels:
            data["risk_level"] = "medium"

        # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è
        string_fields = ["probability_reasoning", "impact_reasoning"]
        for field in string_fields:
            if not isinstance(data.get(field), str) or len(str(data[field]).strip()) < 5:
                data[field] = f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è {field}"

        # –°–ø–∏—Å–∫–æ–≤—ã–µ –ø–æ–ª—è
        list_fields = ["key_factors", "recommendations"]
        for field in list_fields:
            if not isinstance(data.get(field), list):
                data[field] = []
            else:
                # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ç –ø—É—Å—Ç—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                data[field] = [
                                  str(item).strip() for item in data[field]
                                  if item and str(item).strip()
                              ][:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤

        return data

    def _validate_business_logic(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–∞"""

        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º total_score –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        data["total_score"] = data["probability_score"] * data["impact_score"]

        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º risk_level –Ω–∞ –æ—Å–Ω–æ–≤–µ total_score
        total_score = data["total_score"]
        if total_score <= 6:
            correct_level = "low"
        elif total_score <= 14:
            correct_level = "medium"
        else:
            correct_level = "high"

        if data["risk_level"] != correct_level:
            data["risk_level"] = correct_level

        return data

    def _get_default_evaluation_data(self, error_message: str) -> Dict[str, Any]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏"""
        return {
            "probability_score": 3,
            "impact_score": 3,
            "total_score": 9,
            "risk_level": "medium",
            "probability_reasoning": f"LLM –Ω–µ —Å–º–æ–≥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ. –û—à–∏–±–∫–∞: {error_message}",
            "impact_reasoning": f"LLM –Ω–µ —Å–º–æ–≥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ. –û—à–∏–±–∫–∞: {error_message}",
            "key_factors": ["–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"],
            "recommendations": ["–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"],
            "confidence_level": 0.3
        }

# ===============================
# –§–∞–±—Ä–∏–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
# ===============================

def create_agent_config(
        name: str,
        description: str,
        llm_base_url: Optional[str] = None,
        llm_model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_retries: Optional[int] = None,
        timeout_seconds: Optional[int] = None,
        use_risk_analysis_client: bool = False
) -> AgentConfig:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ —Å —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä–æ–º"""

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä–∞
    manager = get_llm_config_manager()
    base_config = manager.get_config()

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä–∞ –∏–ª–∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º
    actual_base_url = llm_base_url or base_config.base_url
    actual_model = llm_model or base_config.model
    actual_temperature = temperature if temperature is not None else base_config.temperature
    actual_max_retries = max_retries if max_retries is not None else base_config.max_retries
    actual_timeout = timeout_seconds if timeout_seconds is not None else base_config.timeout

    # –°–æ–∑–¥–∞–µ–º LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–æ –í–°–ï–ú–ò –ø–æ–ª—è–º–∏
    llm_config = LLMConfig(
        base_url=actual_base_url,
        model=actual_model,
        temperature=actual_temperature,
        max_tokens=base_config.max_tokens,
        timeout=actual_timeout,
        max_retries=actual_max_retries,
        retry_delay=base_config.retry_delay,
        provider=base_config.provider,
        cert_file=base_config.cert_file,
        key_file=base_config.key_file,
        top_p=base_config.top_p,
        verify_ssl_certs=base_config.verify_ssl_certs,
        profanity_check=base_config.profanity_check,
        streaming=base_config.streaming,
        api_key=base_config.api_key  # –î–û–ë–ê–í–õ–ï–ù–û: API –∫–ª—é—á –¥–ª—è DeepSeek
    )

    return AgentConfig(
        name=name,
        description=description,
        llm_config=llm_config,
        max_retries=actual_max_retries,
        timeout_seconds=actual_timeout,
        temperature=actual_temperature,
        use_risk_analysis_client=use_risk_analysis_client
    )


def create_default_config_from_env() -> AgentConfig:
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä–∞"""
    return create_agent_config(
        name="default_agent",
        description="–ê–≥–µ–Ω—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"
    )


# –≠–∫—Å–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
__all__ = [
    "BaseAgent",
    "AnalysisAgent", 
    "EvaluationAgent",
    "AgentConfig",
    "create_agent_config",
    "create_default_config_from_env"
]
