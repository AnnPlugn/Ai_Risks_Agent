# src/utils/risk_validation_patch.py
"""
üîß –†–ê–ë–û–ß–ò–ô –§–ê–ô–õ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è confidence_level –∏ key_factors
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–æ–π –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π

–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ:
1. confidence_level = 0.7 ‚Üí –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç (0.6-0.9)
2. key_factors = [] ‚Üí –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π

–ù–ï –¢–†–û–ì–ê–ï–¢ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É - —Ç–æ–ª—å–∫–æ —É–ª—É—á—à–∞–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é!
"""

import json
import re
from typing import Dict, Any, List, Optional

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—á–µ–π
_applied_patches = set()

def apply_confidence_and_factors_patch():
    """
    üéØ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–∞—Ç—á –±–µ–∑–æ–ø–∞—Å–Ω–æ
    """
    
    if "confidence_and_factors" in _applied_patches:
        print("‚úÖ –ü–∞—Ç—á –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è confidence_level –∏ key_factors —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω")
        return
    
    try:
        from .llm_client import RiskAnalysisLLMClient
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
        if not hasattr(RiskAnalysisLLMClient, '_original_evaluate_risk'):
            RiskAnalysisLLMClient._original_evaluate_risk = RiskAnalysisLLMClient.evaluate_risk
        
        original_method = RiskAnalysisLLMClient._original_evaluate_risk
        
        # ============================================
        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ú–ï–¢–û–î EVALUATE_RISK
        # ============================================
        
        async def enhanced_evaluate_risk(self, risk_type: str, agent_data: str, evaluation_criteria: str, examples = None) -> Dict[str, Any]:
            """üîß –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞"""
            
            try:
                print(f"üîß –ü–ê–¢–ß: –ù–∞—á–∏–Ω–∞–µ–º evaluate_risk –¥–ª—è {risk_type}")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—ã–∑—ã–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é —Å—Å—ã–ª–∫—É
                result = await original_method(self, risk_type, agent_data, evaluation_criteria, examples)
                
                print(f"üîß –ü–ê–¢–ß: –ü–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π confidence_level
                original_confidence = result.get("confidence_level", 0.7)
                if original_confidence == 0.7:
                    new_confidence = _calculate_intelligent_confidence(result)
                    if new_confidence != original_confidence:
                        result["confidence_level"] = new_confidence
                        print(f"üîß –ü–ê–¢–ß: confidence_level –∏—Å–ø—Ä–∞–≤–ª–µ–Ω {original_confidence} ‚Üí {new_confidence}")
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ key_factors
                current_factors = result.get("key_factors", [])
                if not current_factors:
                    print(f"üîß –ü–ê–¢–ß: –ò–∑–≤–ª–µ–∫–∞–µ–º key_factors –¥–ª—è {risk_type}")
                    result = _extract_missing_key_factors(result, risk_type, agent_data)
                
                print(f"üîß –ü–ê–¢–ß: –ó–∞–≤–µ—Ä—à–∞–µ–º evaluate_risk –¥–ª—è {risk_type}")
                return result
                
            except Exception as e:
                print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –ü–ê–¢–ß–ï: {e}")
                import traceback
                traceback.print_exc()
                
                # FALLBACK: –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                try:
                    return await original_method(self, risk_type, agent_data, evaluation_criteria, examples)
                except Exception as e2:
                    print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ú –ú–ï–¢–û–î–ï: {e2}")
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π fallback
                    return {
                        "probability_score": 3,
                        "impact_score": 3,
                        "total_score": 9,
                        "risk_level": "medium",
                        "probability_reasoning": f"Fallback –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}",
                        "impact_reasoning": f"Fallback –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {str(e)}",
                        "key_factors": [],
                        "recommendations": [],
                        "confidence_level": 0.3
                    }
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ç—á–∞
        RiskAnalysisLLMClient.evaluate_risk = enhanced_evaluate_risk
        
        print("‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ø–∞—Ç—á –¥–ª—è confidence_level –∏ key_factors –ø—Ä–∏–º–µ–Ω–µ–Ω")
        _applied_patches.add("confidence_and_factors")
        
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ç—á–∞: {e}")
        import traceback
        traceback.print_exc()


# ============================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================

def _calculate_intelligent_confidence(data: Dict[str, Any]) -> float:
    """üß† –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
    
    confidence_factors = []
    
    # 1. –ö–∞—á–µ—Å—Ç–≤–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–π
    prob_reasoning = str(data.get("probability_reasoning", ""))
    impact_reasoning = str(data.get("impact_reasoning", ""))
    
    if len(prob_reasoning) > 100 and len(impact_reasoning) > 100:
        confidence_factors.append(0.85)  # –•–æ—Ä–æ—à–∏–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
    elif len(prob_reasoning) > 50 and len(impact_reasoning) > 50:
        confidence_factors.append(0.75)  # –°—Ä–µ–¥–Ω–∏–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
    else:
        confidence_factors.append(0.6)   # –°–ª–∞–±—ã–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è
    
    # 2. –ù–∞–ª–∏—á–∏–µ key_factors
    key_factors = data.get("key_factors", [])
    
    if len(key_factors) >= 3:
        confidence_factors.append(0.85)  # –ú–Ω–æ–≥–æ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    elif len(key_factors) >= 1:
        confidence_factors.append(0.72)  # –ï—Å—Ç—å —Ñ–∞–∫—Ç–æ—Ä—ã
    else:
        confidence_factors.append(0.5)   # –ù–µ—Ç —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    
    # 3. –ù–∞–ª–∏—á–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    recommendations = data.get("recommendations", [])
    
    if len(recommendations) >= 3:
        confidence_factors.append(0.82)  # –ú–Ω–æ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    elif len(recommendations) >= 1:
        confidence_factors.append(0.73)  # –ï—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    else:
        confidence_factors.append(0.6)   # –ú–∞–ª–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    
    # 4. –õ–æ–≥–∏—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–æ–∫
    prob_score = data.get("probability_score", 3)
    impact_score = data.get("impact_score", 3)
    
    if 1 <= prob_score <= 5 and 1 <= impact_score <= 5:
        confidence_factors.append(0.8)   # –í–∞–ª–∏–¥–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
    else:
        confidence_factors.append(0.4)   # –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ
    final_confidence = sum(confidence_factors) / len(confidence_factors)
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ù–ï 0.7
    rounded_confidence = round(final_confidence, 2)
    if rounded_confidence == 0.7:
        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ 0.7, –Ω–µ–º–Ω–æ–≥–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º
        rounded_confidence = 0.71
    
    return rounded_confidence


def _extract_missing_key_factors(data: Dict[str, Any], risk_type: str = "", agent_data: str = "") -> Dict[str, Any]:
    """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ key_factors –∏–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ reasoning –ø–æ–ª–µ–π
    extracted_factors = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º probability_reasoning
    prob_text = str(data.get("probability_reasoning", "")).lower()
    extracted_factors.extend(_extract_factors_from_text(prob_text))
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º impact_reasoning
    impact_text = str(data.get("impact_reasoning", "")).lower()
    extracted_factors.extend(_extract_factors_from_text(impact_text))
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Ç–∏–ø–∞ —Ä–∏—Å–∫–∞ —Ñ–∞–∫—Ç–æ—Ä—ã
    if risk_type:
        extracted_factors.extend(_get_risk_specific_factors(risk_type))
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    if agent_data:
        agent_text = str(agent_data).lower()
        extracted_factors.extend(_extract_factors_from_agent_data(agent_text))
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–µ 5
    unique_factors = []
    seen = set()
    
    for factor in extracted_factors:
        if factor and isinstance(factor, str) and len(factor.strip()) > 3:
            factor_clean = factor.strip()
            if factor_clean.lower() not in seen:
                unique_factors.append(factor_clean)
                seen.add(factor_clean.lower())
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    final_factors = unique_factors[:5]
    
    if final_factors:
        data["key_factors"] = final_factors
        print(f"üîß –ò–∑–≤–ª–µ—á–µ–Ω—ã key_factors: {final_factors}")
    else:
        # Fallback –Ω–∞ –æ—Å–Ω–æ–≤–µ risk_type
        fallback_factors = _get_fallback_factors(risk_type)
        data["key_factors"] = fallback_factors
        print(f"üîß –ü—Ä–∏–º–µ–Ω–µ–Ω—ã fallback key_factors: {fallback_factors}")
    
    return data


def _extract_factors_from_text(text: str) -> List[str]:
    """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    
    factors = []
    
    # –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    risk_patterns = {
        r"–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω.*(?:–∑–∞—â–∏—Ç|–º–µ—Ä|–∫–æ–Ω—Ç—Ä–æ–ª)": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ –º–µ—Ä—ã –∑–∞—â–∏—Ç—ã",
        r"–æ—Ç—Å—É—Ç—Å—Ç–≤.*(?:guardrail|–æ–≥—Ä–∞–Ω–∏—á–µ–Ω)": "–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ guardrails",
        r"–≤—ã—Å–æ–∫.*(?:–∞–≤—Ç–æ–Ω–æ–º|—Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å)": "–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏",
        r"–∏–Ω—Ç–µ–≥—Ä–∞—Ü.*(?:api|–≤–Ω–µ—à–Ω)": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ API",
        r"–ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω.*–¥–∞–Ω–Ω—ã": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        r"—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç.*–º–æ–¥–µ–ª": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
        r"–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω.*–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥",
        r"—Ä–µ–ø—É—Ç–∞—Ü.*—Ä–∏—Å–∫": "–†–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏",
        r"—é—Ä–∏–¥–∏—á–µ—Å–∫.*(?:–ø–æ—Å–ª–µ–¥—Å—Ç–≤|—Ä–∏—Å–∫)": "–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è",
        r"—à—Ç—Ä–∞—Ñ": "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —à—Ç—Ä–∞—Ñ—ã",
        r"—É—Ç–µ—á–∫.*–¥–∞–Ω–Ω—ã": "–†–∏—Å–∫ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö",
        r"–¥–æ–≤–µ—Ä–∏–µ.*–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª": "–ü–æ—Ç–µ—Ä—è –¥–æ–≤–µ—Ä–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
        r"–Ω–∞—Ä—É—à–µ–Ω.*(?:—Ç—Ä–µ–±–æ–≤–∞–Ω|–∑–∞–∫–æ–Ω)": "–ù–∞—Ä—É—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π",
        r"–¥–∏—Å–∫—Ä–∏–º–∏–Ω": "–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è",
        r"–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤": "–ù–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å",
        r"–º–∞–Ω–∏–ø—É–ª—è—Ü": "–ú–∞–Ω–∏–ø—É–ª—è—Ü–∏—è",
        r"–¥–µ–∑–∏–Ω—Ñ–æ—Ä–º": "–î–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
        r"–∫–∏–±–µ—Ä–∞—Ç–∞–∫": "–ö–∏–±–µ—Ä–∞—Ç–∞–∫–∏",
        r"—Ö–∞–ª–ª—é—Ü–∏–Ω": "–•–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏",
        r"—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏.*—Å–±–æ": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–±–æ–∏"
    }
    
    for pattern, factor in risk_patterns.items():
        if re.search(pattern, text):
            factors.append(factor)
    
    return factors


def _extract_factors_from_agent_data(agent_text: str) -> List[str]:
    """üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞"""
    
    factors = []
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    if "–ø–µ—Ä—Å–æ–Ω–∞–ª—å" in agent_text or "personal" in agent_text:
        factors.append("–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    
    if "–∞–≤—Ç–æ–Ω–æ–º" in agent_text or "autonom" in agent_text:
        factors.append("–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏")
    
    if "api" in agent_text or "–∏–Ω—Ç–µ–≥—Ä–∞—Ü" in agent_text:
        factors.append("–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏")
    
    if "—Ñ–∏–Ω–∞–Ω—Å" in agent_text or "–±–∞–Ω–∫" in agent_text:
        factors.append("–†–∞–±–æ—Ç–∞ —Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
    
    if "—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç" in agent_text or "experiment" in agent_text:
        factors.append("–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏")
    
    if "–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥" in agent_text or "monitor" in agent_text:
        factors.append("–í–æ–ø—Ä–æ—Å—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    return factors


def _get_risk_specific_factors(risk_type: str) -> List[str]:
    """üéØ –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–∏–ø–æ–≤ —Ä–∏—Å–∫–æ–≤"""
    
    risk_type_lower = risk_type.lower()
    
    specific_factors = {
        "—ç—Ç–∏—á–µ—Å–∫": ["–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è", "–≠—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è"],
        "—Å–æ—Ü–∏–∞–ª—å–Ω": ["–ú–∞–Ω–∏–ø—É–ª—è—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏", "–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥–µ–∑–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"],
        "–±–µ–∑–æ–ø–∞—Å–Ω": ["–£—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", "–†–∏—Å–∫ —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö"],
        "—Å—Ç–∞–±–∏–ª—å–Ω": ["–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"],
        "–∞–≤—Ç–æ–Ω–æ–º": ["–ù–µ–∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è", "–ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–º–æ—á–∏–π"],
        "—Ä–µ–≥—É–ª—è—Ç–æ—Ä": ["–ù–∞—Ä—É—à–µ–Ω–∏–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π", "–®—Ç—Ä–∞—Ñ–Ω—ã–µ —Å–∞–Ω–∫—Ü–∏–∏"],
        "ethical": ["Potential discrimination", "Ethical violations"],
        "social": ["User manipulation", "Misinformation spread"],
        "security": ["Security vulnerabilities", "Data leak risks"],
        "stability": ["Model instability", "Technical errors"],
        "autonomy": ["Uncontrolled actions", "Authority overreach"],
        "regulatory": ["Regulatory violations", "Penalty sanctions"]
    }
    
    for key, factors in specific_factors.items():
        if key in risk_type_lower:
            return factors[:2]  # –ú–∞–∫—Å–∏–º—É–º 2 —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–∞
    
    return []


def _get_fallback_factors(risk_type: str) -> List[str]:
    """üîÑ Fallback —Ñ–∞–∫—Ç–æ—Ä—ã –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"""
    
    if risk_type:
        return [f"–û–±—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ {risk_type}", "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"]
    else:
        return ["–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞", "–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ"]


# ============================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ü–†–ò–ú–ï–ù–ï–ù–ò–Ø –ò –ü–†–û–í–ï–†–ö–ò
# ============================================

def apply_all_patches():
    """üéØ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –≤—Å–µ –ø—Ä–æ—Å—Ç—ã–µ –ø–∞—Ç—á–∏ (—Ç–æ–ª—å–∫–æ confidence_level –∏ key_factors)"""
    
    apply_confidence_and_factors_patch()


def get_patch_status() -> Dict[str, bool]:
    """üìä –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –ø–∞—Ç—á–µ–π"""
    
    return {
        "confidence_and_factors": "confidence_and_factors" in _applied_patches
    }


def test_patch_working():
    """üß™ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Ä–∞–±–æ—Ç—ã –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""
    
    try:
        # –¢–µ—Å—Ç 1: –†–∞—Å—á–µ—Ç confidence_level
        test_data = {
            "probability_reasoning": "–ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Å –∞–Ω–∞–ª–∏–∑–æ–º —Ä–∏—Å–∫–æ–≤ –∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤",
            "impact_reasoning": "–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π", 
            "key_factors": ["–§–∞–∫—Ç–æ—Ä 1", "–§–∞–∫—Ç–æ—Ä 2", "–§–∞–∫—Ç–æ—Ä 3"],
            "recommendations": ["–†–µ–∫ 1", "–†–µ–∫ 2", "–†–µ–∫ 3"],
            "probability_score": 3,
            "impact_score": 4
        }
        
        confidence = _calculate_intelligent_confidence(test_data)
        
        # –¢–µ—Å—Ç 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ key_factors
        test_data_empty = {
            "key_factors": [],
            "probability_reasoning": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ –º–µ—Ä—ã –∑–∞—â–∏—Ç—ã —Å–æ–∑–¥–∞—é—Ç –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏",
            "impact_reasoning": "–†–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏ –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —à—Ç—Ä–∞—Ñ–∞–º"
        }
        
        result = _extract_missing_key_factors(test_data_empty, "—ç—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∏—Å–∫–∏")
        extracted_factors = result.get("key_factors", [])
        
        return confidence != 0.7 and len(extracted_factors) > 0
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
        return False