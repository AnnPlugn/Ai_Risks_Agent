"""
–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM.
–ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π.
–û–ë–ù–û–í–õ–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ GigaChat –∏ DeepSeek API
"""

import os
from typing import Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

try:
    from dotenv import load_dotenv

    # –ò—â–µ–º .env —Ñ–∞–π–ª –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö
    env_loaded = load_dotenv(verbose=True)  # verbose=True –ø–æ–∫–∞–∂–µ—Ç –∫–∞–∫–æ–π —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω

    if not env_loaded:
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ .env –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
        current_dir = Path.cwd()
        for parent in [current_dir] + list(current_dir.parents):
            env_file = parent / ".env"
            if env_file.exists():
                load_dotenv(env_file, verbose=True)
                print(f"üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω .env —Ñ–∞–π–ª: {env_file}")
                break
        else:
            print("‚ö†Ô∏è  .env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    else:
        print("üìÅ .env —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω")

except ImportError:
    print("‚ö†Ô∏è  python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-dotenv")
except Exception as e:
    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ .env —Ñ–∞–π–ª–∞: {e}")

class LLMProvider(Enum):
    """–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã LLM"""
    LM_STUDIO = "lm_studio"
    GIGACHAT = "gigachat"
    DEEPSEEK = "deepseek"

@dataclass
class LLMConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –∫–ª–∏–µ–Ω—Ç–∞"""
    base_url: str
    model: str
    temperature: float
    max_tokens: int
    timeout: int
    max_retries: int
    retry_delay: float
    provider: LLMProvider = LLMProvider.LM_STUDIO
    api_key: Optional[str] = None  # Added for DeepSeek
    cert_file: Optional[str] = None
    key_file: Optional[str] = None
    top_p: float = 0.2
    verify_ssl_certs: bool = False
    profanity_check: bool = False
    streaming: bool = True

    @classmethod
    def from_manager(cls, **overrides) -> 'LLMConfig':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        global config_manager

        if config_manager is None or config_manager._config is None:
            temp_manager = LLMConfigManager()
            base_config = temp_manager.get_config()
        else:
            base_config = config_manager.get_config()

        return cls(
            base_url=overrides.get('base_url', base_config.base_url),
            model=overrides.get('model', base_config.model),
            temperature=overrides.get('temperature', base_config.temperature),
            max_tokens=overrides.get('max_tokens', base_config.max_tokens),
            timeout=overrides.get('timeout', base_config.timeout),
            max_retries=overrides.get('max_retries', base_config.max_retries),
            retry_delay=overrides.get('retry_delay', base_config.retry_delay),
            provider=overrides.get('provider', base_config.provider),
            api_key=overrides.get('api_key', base_config.api_key),
            cert_file=overrides.get('cert_file', base_config.cert_file),
            key_file=overrides.get('key_file', base_config.key_file),
            top_p=overrides.get('top_p', base_config.top_p),
            verify_ssl_certs=overrides.get('verify_ssl_certs', base_config.verify_ssl_certs),
            profanity_check=overrides.get('profanity_check', base_config.profanity_check),
            streaming=overrides.get('streaming', base_config.streaming)
        )

    @classmethod
    def create_default(cls) -> 'LLMConfig':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (fallback –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        return cls(
            base_url=os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234"),
            model=os.getenv("LLM_MODEL", "qwen3-4b"),
            temperature=float(os.getenv("LLM_TEMPERATURE", "0.1")),
            max_tokens=int(os.getenv("LLM_MAX_TOKENS", "8192")),
            timeout=int(os.getenv("LLM_TIMEOUT", "120")),
            max_retries=int(os.getenv("MAX_RETRY_COUNT", "3")),
            retry_delay=float(os.getenv("LLM_RETRY_DELAY", "1.0")),
            provider=LLMProvider.LM_STUDIO
        )

    @classmethod
    def from_env(cls, **overrides) -> 'LLMConfig':
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        provider_str = os.getenv("LLM_PROVIDER", "lm_studio").lower()
        provider_mapping = {
            "lm_studio": LLMProvider.LM_STUDIO,
            "gigachat": LLMProvider.GIGACHAT,
            "deepseek": LLMProvider.DEEPSEEK
        }
        provider = provider_mapping.get(provider_str, LLMProvider.LM_STUDIO)

        if provider == LLMProvider.GIGACHAT:
            base_url = os.getenv("GIGACHAT_BASE_URL", "https://gigachat-ift.sberdevices.delta.sbrf.ru/v1")
            model = os.getenv("GIGACHAT_MODEL", "GigaChat-Max")
            cert_path = os.getenv("GIGACHAT_CERT_PATH", "lib/llm/client_cert.pem")
            key_path = os.getenv("GIGACHAT_KEY_PATH", "lib/llm/client_key.pem")

            if not os.path.isabs(cert_path):
                cert_path = os.path.join(os.getcwd(), cert_path)
            if not os.path.isabs(key_path):
                key_path = os.path.join(os.getcwd(), key_path)

            cert_file = cert_path
            key_file = key_path
            top_p = float(os.getenv("GIGACHAT_TOP_P", "0.2"))
            verify_ssl_certs = os.getenv("GIGACHAT_VERIFY_SSL", "false").lower() == "true"
            profanity_check = os.getenv("GIGACHAT_PROFANITY_CHECK", "false").lower() == "true"
            streaming = os.getenv("GIGACHAT_STREAMING", "true").lower() == "true"
            api_key = None
        elif provider == LLMProvider.DEEPSEEK:
            base_url = os.getenv("LLM_BASE_URL", "https://api.proxyapi.ru/deepseek")
            model = os.getenv("LLM_MODEL", "deepseek-chat")
            cert_file = None
            key_file = None
            top_p = float(os.getenv("LLM_TOP_P", "0.2"))
            verify_ssl_certs = os.getenv("LLM_VERIFY_SSL", "true").lower() == "true"
            profanity_check = False
            streaming = os.getenv("LLM_STREAMING", "true").lower() == "true"
            api_key = os.getenv("LLM_DeepSeek_API_KEY")
        else:
            base_url = os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234")
            model = os.getenv("LLM_MODEL", "qwen3-4b")
            cert_file = None
            key_file = None
            top_p = float(os.getenv("LLM_TOP_P", "0.2"))
            verify_ssl_certs = False
            profanity_check = False
            streaming = True
            api_key = None

        temperature = float(os.getenv("LLM_TEMPERATURE", "0.1"))
        max_tokens = int(os.getenv("LLM_MAX_TOKENS", "8192"))
        timeout = int(os.getenv("LLM_TIMEOUT", "120"))
        max_retries = int(os.getenv("MAX_RETRY_COUNT", "3"))
        retry_delay = float(os.getenv("LLM_RETRY_DELAY", "1.0"))

        return cls(
            base_url=overrides.get('base_url', base_url),
            model=overrides.get('model', model),
            temperature=overrides.get('temperature', temperature),
            max_tokens=overrides.get('max_tokens', max_tokens),
            timeout=overrides.get('timeout', timeout),
            max_retries=overrides.get('max_retries', max_retries),
            retry_delay=overrides.get('retry_delay', retry_delay),
            provider=overrides.get('provider', provider),
            api_key=overrides.get('api_key', api_key),
            cert_file=overrides.get('cert_file', cert_file),
            key_file=overrides.get('key_file', key_file),
            top_p=overrides.get('top_p', top_p),
            verify_ssl_certs=overrides.get('verify_ssl_certs', verify_ssl_certs),
            profanity_check=overrides.get('profanity_check', profanity_check),
            streaming=overrides.get('streaming', streaming)
        )

class LLMConfigManager:
    """
    Singleton –º–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ LLM.
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ –æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞.
    –û–ë–ù–û–í–õ–ï–ù–û: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤–∫–ª—é—á–∞—è DeepSeek
    """

    _instance: Optional['LLMConfigManager'] = None
    _config: Optional[LLMConfig] = None

    def __new__(cls) -> 'LLMConfigManager':
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if self._config is None:
            self._load_config()

    def _load_config(self) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        provider_str = os.getenv("LLM_PROVIDER", "lm_studio").lower()
        provider = self._parse_provider(provider_str)

        if provider == LLMProvider.GIGACHAT:
            self._config = self._load_gigachat_config()
        elif provider == LLMProvider.DEEPSEEK:
            self._config = self._load_deepseek_config()
        else:
            self._config = self._load_lm_studio_config()

    def _parse_provider(self, provider_str: str) -> LLMProvider:
        """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        provider_mapping = {
            "lm_studio": LLMProvider.LM_STUDIO,
            "gigachat": LLMProvider.GIGACHAT,
            "deepseek": LLMProvider.DEEPSEEK
        }
        return provider_mapping.get(provider_str, LLMProvider.LM_STUDIO)

    def _load_gigachat_config(self) -> LLMConfig:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è GigaChat"""
        base_url = os.getenv("GIGACHAT_BASE_URL", "https://gigachat-ift.sberdevices.delta.sbrf.ru/v1")
        model = os.getenv("GIGACHAT_MODEL", "GigaChat-Max")
        cert_path = os.getenv("GIGACHAT_CERT_PATH", "lib/llm/client_cert.pem")
        key_path = os.getenv("GIGACHAT_KEY_PATH", "lib/llm/client_key.pem")

        if not os.path.isabs(cert_path):
            cert_path = os.path.join(os.getcwd(), cert_path)
        if not os.path.isabs(key_path):
            key_path = os.path.join(os.getcwd(), key_path)

        if not (os.path.exists(cert_path) and os.path.exists(key_path)):
            raise FileNotFoundError(
                f"GigaChat SSL-—Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\n"
                f"Cert: {cert_path}\n"
                f"Key: {key_path}\n"
                f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –≤ .env —Ñ–∞–π–ª–µ"
            )

        temperature = float(os.getenv("LLM_TEMPERATURE", "0.1"))
        max_tokens = int(os.getenv("LLM_MAX_TOKENS", "8192"))
        timeout = int(os.getenv("LLM_TIMEOUT", "120"))
        max_retries = int(os.getenv("MAX_RETRY_COUNT", "3"))
        retry_delay = float(os.getenv("LLM_RETRY_DELAY", "1.0"))

        return LLMConfig(
            base_url=base_url,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=timeout,
            max_retries=max_retries,
            retry_delay=retry_delay,
            provider=LLMProvider.GIGACHAT,
            cert_file=cert_path,
            key_file=key_path,
            top_p=float(os.getenv("GIGACHAT_TOP_P", "0.2")),
            verify_ssl_certs=os.getenv("GIGACHAT_VERIFY_SSL", "false").lower() == "true",
            profanity_check=os.getenv("GIGACHAT_PROFANITY_CHECK", "false").lower() == "true",
            streaming=os.getenv("GIGACHAT_STREAMING", "true").lower() == "true"
        )

    def _load_deepseek_config(self) -> LLMConfig:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è DeepSeek"""
        base_url = os.getenv("LLM_BASE_URL", "https://api.proxyapi.ru/deepseek")
        model = os.getenv("LLM_MODEL", "deepseek-chat")
        api_key = os.getenv("LLM_DeepSeek_API_KEY")

        if not api_key:
            raise ValueError("DeepSeek API key not found in environment variable LLM_DeepSeek_API_KEY")

        temperature = float(os.getenv("LLM_TEMPERATURE", "0.1"))
        max_tokens = int(os.getenv("LLM_MAX_TOKENS", "8192"))
        timeout = int(os.getenv("LLM_TIMEOUT", "120"))
        max_retries = int(os.getenv("MAX_RETRY_COUNT", "3"))
        retry_delay = float(os.getenv("LLM_RETRY_DELAY", "1.0"))

        return LLMConfig(
            base_url=base_url,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=timeout,
            max_retries=max_retries,
            retry_delay=retry_delay,
            provider=LLMProvider.DEEPSEEK,
            api_key=api_key,
            top_p=float(os.getenv("LLM_TOP_P", "0.2")),
            verify_ssl_certs=os.getenv("LLM_VERIFY_SSL", "true").lower() == "true",
            streaming=os.getenv("LLM_STREAMING", "true").lower() == "true"
        )

    def _load_lm_studio_config(self) -> LLMConfig:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è LM Studio"""
        base_url = os.getenv("LLM_BASE_URL", "http://127.0.0.1:1234")
        model = os.getenv("LLM_MODEL", "qwen3-4b")
        temperature = float(os.getenv("LLM_TEMPERATURE", "0.1"))
        max_tokens = int(os.getenv("LLM_MAX_TOKENS", "8192"))
        timeout = int(os.getenv("LLM_TIMEOUT", "120"))
        max_retries = int(os.getenv("MAX_RETRY_COUNT", "3"))
        retry_delay = float(os.getenv("LLM_RETRY_DELAY", "1.0"))

        provider = self._detect_provider(base_url)

        return LLMConfig(
            base_url=base_url,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=timeout,
            max_retries=max_retries,
            retry_delay=retry_delay,
            provider=provider
        )

    def _detect_provider(self, base_url: str) -> LLMProvider:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ URL"""
        if "127.0.0.1" in base_url or "localhost" in base_url:
            return LLMProvider.LM_STUDIO
        elif "gigachat" in base_url.lower() or "sber" in base_url.lower():
            return LLMProvider.GIGACHAT
        elif "deepseek" in base_url.lower() or "proxyapi" in base_url.lower():
            return LLMProvider.DEEPSEEK
        else:
            return LLMProvider.LM_STUDIO

    def get_config(self) -> LLMConfig:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return self._config

    def get_base_url(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ URL –¥–ª—è LLM API"""
        return self._config.base_url

    def get_model(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        return self._config.model

    def get_temperature(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        return self._config.temperature

    def get_max_tokens(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤"""
        return self._config.max_tokens

    def get_timeout(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∞–π–º–∞—É—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        return self._config.timeout

    def get_max_retries(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫"""
        return self._config.max_retries

    def get_retry_delay(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        return self._config.retry_delay

    def get_provider(self) -> LLMProvider:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        return self._config.provider

    def get_api_key(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞"""
        return self._config.api_key

    def get_quality_threshold(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ—Ü–µ–Ω–æ–∫"""
        return float(os.getenv("QUALITY_THRESHOLD", "7.0"))

    def get_cert_file(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞"""
        return self._config.cert_file

    def get_key_file(self) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –∫–ª—é—á–∞"""
        return self._config.key_file

    def get_top_p(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ top_p"""
        return self._config.top_p

    def get_verify_ssl_certs(self) -> bool:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤"""
        return self._config.verify_ssl_certs

    def get_profanity_check(self) -> bool:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏"""
        return self._config.profanity_check

    def get_streaming(self) -> bool:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        return self._config.streaming

    def is_gigachat(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ GigaChat"""
        return self._config.provider == LLMProvider.GIGACHAT

    def is_lm_studio(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ LM Studio"""
        return self._config.provider == LLMProvider.LM_STUDIO

    def is_deepseek(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ DeepSeek"""
        return self._config.provider == LLMProvider.DEEPSEEK

    def create_agent_config_dict(self, **overrides) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        config = {
            "llm_base_url": self.get_base_url(),
            "llm_model": self.get_model(),
            "temperature": self.get_temperature(),
            "max_retries": self.get_max_retries(),
            "timeout_seconds": self.get_timeout(),
            "api_key": self.get_api_key()
        }

        if self.is_gigachat():
            config.update({
                "cert_file": self.get_cert_file(),
                "key_file": self.get_key_file(),
                "top_p": self.get_top_p(),
                "verify_ssl_certs": self.get_verify_ssl_certs(),
                "profanity_check": self.get_profanity_check(),
                "streaming": self.get_streaming()
            })

        config.update(overrides)
        return config

    def create_llm_client_config_dict(self, **overrides) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è LLM –∫–ª–∏–µ–Ω—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        config = {
            "base_url": self.get_base_url(),
            "model": self.get_model(),
            "temperature": self.get_temperature(),
            "api_key": self.get_api_key()
        }

        if self.is_gigachat():
            config.update({
                "cert_file": self.get_cert_file(),
                "key_file": self.get_key_file(),
                "top_p": self.get_top_p(),
                "verify_ssl_certs": self.get_verify_ssl_certs(),
                "profanity_check": self.get_profanity_check(),
                "streaming": self.get_streaming()
            })

        config.update(overrides)
        return config

    def reload_config(self) -> None:
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        self._config = None
        self._load_config()

    def set_provider_config(self, provider: LLMProvider, config_updates: Dict[str, Any]) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        for key, value in config_updates.items():
            os.environ[key] = str(value)

        self.reload_config()

    def get_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        info = {
            "provider": self._config.provider.value,
            "base_url": self._config.base_url,
            "model": self._config.model,
            "temperature": self._config.temperature,
            "max_tokens": self._config.max_tokens,
            "timeout": self._config.timeout,
            "max_retries": self._config.max_retries,
            "quality_threshold": self.get_quality_threshold(),
            "api_key": "******" if self._config.api_key else None
        }

        if self.is_gigachat():
            info.update({
                "cert_file": self._config.cert_file,
                "key_file": self._config.key_file,
                "top_p": self._config.top_p,
                "streaming": self._config.streaming,
                "verify_ssl_certs": self._config.verify_ssl_certs,
                "profanity_check": self._config.profanity_check
            })

        return info

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config_manager = LLMConfigManager()

def get_llm_config_manager() -> LLMConfigManager:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    return config_manager

def get_base_url() -> str:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –±–∞–∑–æ–≤–æ–º—É URL"""
    return config_manager.get_base_url()

def get_model() -> str:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏"""
    return config_manager.get_model()

def get_temperature() -> float:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ"""
    return config_manager.get_temperature()

def get_llm_config() -> LLMConfig:
    """–ë—ã—Å—Ç—Ä—ã–π –¥–æ—Å—Ç—É–ø –∫ –ø–æ–ª–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    return config_manager.get_config()

def is_gigachat() -> bool:
    """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ GigaChat"""
    return config_manager.is_gigachat()

def is_deepseek() -> bool:
    """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ DeepSeek"""
    return config_manager.is_deepseek()

def force_reload_config():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤ –∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤)"""
    global config_manager
    if config_manager._instance is not None:
        config_manager._instance._config = None
        config_manager._instance._load_config()

    try:
        from . import llm_client
        llm_client._global_client = None
    except ImportError:
        pass

def reset_config_manager():
    """–ü–æ–ª–Ω—ã–π —Å–±—Ä–æ—Å –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
    global config_manager
    LLMConfigManager._instance = None
    config_manager = LLMConfigManager()

def print_env_diagnosis():
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    import os

    print("\nüîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–ï–†–ï–ú–ï–ù–ù–´–• –û–ö–†–£–ñ–ï–ù–ò–Ø:")
    required_vars = ["LLM_PROVIDER"]
    gigachat_vars = ["GIGACHAT_CERT_PATH", "GIGACHAT_KEY_PATH", "GIGACHAT_BASE_URL", "GIGACHAT_MODEL"]
    deepseek_vars = ["LLM_DeepSeek_API_KEY"]

    for var in required_vars + gigachat_vars + deepseek_vars:
        value = os.getenv(var)
        status = "‚úÖ" if value else "‚ùå"
        print(f"   {status} {var}: {value if value else '–ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù–ê'}")

    if os.getenv("LLM_PROVIDER", "").lower() == "gigachat":
        cert_path = os.getenv("GIGACHAT_CERT_PATH", "")
        key_path = os.getenv("GIGACHAT_KEY_PATH", "")

        print(f"\nüîí –ü–†–û–í–ï–†–ö–ê –°–ï–†–¢–ò–§–ò–ö–ê–¢–û–í:")
        for name, path in [("CERT", cert_path), ("KEY", key_path)]:
            if path:
                if not os.path.isabs(path):
                    path = os.path.join(os.getcwd(), path)
                exists = os.path.exists(path)
                status = "‚úÖ" if exists else "‚ùå"
                print(f"   {status} {name}: {path} ({'–Ω–∞–π–¥–µ–Ω' if exists else '–ù–ï –ù–ê–ô–î–ï–ù'})")
            else:
                print(f"   ‚ùå {name}: –ø—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω")