# final_workflow_fix.py
"""
–§–∏–Ω–∞–ª—å–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –≤ workflow
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—É —Å —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –≤ WorkflowState
"""

import sys
from pathlib import Path

def apply_critical_fixes():
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π"""
    
    print("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π workflow...")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 1: –û–±–Ω–æ–≤–ª—è–µ–º WorkflowState –≤ risk_models.py
    risk_models_file = Path("src/models/risk_models.py")
    
    if risk_models_file.exists():
        content = risk_models_file.read_text(encoding='utf-8')
        
        # –ù–∞—Ö–æ–¥–∏–º –∏ –∑–∞–º–µ–Ω—è–µ–º WorkflowState
        old_workflow_state = """class WorkflowState(BaseModel):
    \"\"\"–°–æ—Å—Ç–æ—è–Ω–∏–µ workflow –¥–ª—è LangGraph\"\"\"
    
    # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    agent_profile: Optional[AgentProfile] = None
    source_files: List[str] = Field(default_factory=list)
    
    # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    profiling_result: Optional[AgentTaskResult] = None
    evaluation_results: Dict[RiskType, AgentTaskResult] = Field(default_factory=dict)
    critic_results: Dict[RiskType, AgentTaskResult] = Field(default_factory=dict)"""
        
        new_workflow_state = """class WorkflowState(BaseModel):
    \"\"\"–°–æ—Å—Ç–æ—è–Ω–∏–µ workflow –¥–ª—è LangGraph - –ò–°–ü–†–ê–í–õ–ï–ù–û –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\"\"\"
    
    # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
    assessment_id: Optional[str] = Field(None, description="ID –æ—Ü–µ–Ω–∫–∏")
    preliminary_agent_name: Optional[str] = Field(None, description="–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∏–º—è –∞–≥–µ–Ω—Ç–∞")
    
    # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    source_files: List[str] = Field(default_factory=list, description="–§–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    agent_profile: Optional[Dict[str, Any]] = Field(None, description="–ü—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞")
    
    # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∫–∞–∫ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å LangGraph)
    profiling_result: Optional[Dict[str, Any]] = Field(None, description="–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
    evaluation_results: Dict[str, Dict[str, Any]] = Field(default_factory=dict, description="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤")
    critic_results: Dict[str, Dict[str, Any]] = Field(default_factory=dict, description="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")"""
        
        if old_workflow_state in content:
            content = content.replace(old_workflow_state, new_workflow_state)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–æ–¥—ã –¥–ª—è —Å–ª–æ–≤–∞—Ä–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            workflow_state_methods = """
    
    # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–º
    current_step: str = Field("initialization", description="–¢–µ–∫—É—â–∏–π —à–∞–≥")
    retry_count: Dict[str, int] = Field(default_factory=dict, description="–°—á–µ—Ç—á–∏–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤")
    max_retries: int = Field(3, description="–ú–∞–∫—Å–∏–º—É–º –ø–æ–≤—Ç–æ—Ä–æ–≤")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞  
    quality_threshold: float = Field(7.0, description="–ü–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∞")
    require_critic_approval: bool = Field(True, description="–¢—Ä–µ–±–æ–≤–∞—Ç—å –æ–¥–æ–±—Ä–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏–∫–∞")
    
    # –ö–æ–Ω—Ç—Ä–æ–ª—å –æ—à–∏–±–æ–∫
    error_message: Optional[str] = Field(None, description="–°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ")
    retry_needed: List[str] = Field(default_factory=list, description="–†–∏—Å–∫–∏, —Ç—Ä–µ–±—É—é—â–∏–µ –ø–æ–≤—Ç–æ—Ä–∞")
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    start_time: Optional[datetime] = Field(None, description="–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞")
    processing_time: Optional[float] = Field(None, description="–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    average_quality: Optional[float] = Field(None, description="–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    saved_assessment_id: Optional[str] = Field(None, description="ID —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–∏")
    profile_id: Optional[str] = Field(None, description="ID –ø—Ä–æ—Ñ–∏–ª—è –∞–≥–µ–Ω—Ç–∞")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    final_assessment: Optional[Dict[str, Any]] = Field(None, description="–ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞")
    
    class Config:
        \"\"\"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\"\"\"
        extra = "allow"  # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        use_enum_values = True
        arbitrary_types_allowed = True
        
    def __getitem__(self, key: str):
        \"\"\"–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫–∞–∫ –∫ —Å–ª–æ–≤–∞—Ä—é\"\"\"
        return getattr(self, key, None)
    
    def __setitem__(self, key: str, value):
        \"\"\"–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∑–∞–ø–∏—Å–∏ –∫–∞–∫ –≤ —Å–ª–æ–≤–∞—Ä—å\"\"\"
        setattr(self, key, value)
    
    def get(self, key: str, default=None):
        \"\"\"–ú–µ—Ç–æ–¥ get() –∫–∞–∫ —É —Å–ª–æ–≤–∞—Ä—è\"\"\"
        return getattr(self, key, default)
    
    def update(self, updates: Dict[str, Any]):
        \"\"\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –∫–∞–∫ —É —Å–ª–æ–≤–∞—Ä—è\"\"\"
        for key, value in updates.items():
            setattr(self, key, value)
    
    def dict(self, **kwargs) -> Dict[str, Any]:
        \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö –ø–æ–ª–µ–π\"\"\"
        result = super().dict(**kwargs)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        for key, value in self.__dict__.items():
            if key not in result and not key.startswith('_'):
                if isinstance(value, datetime):
                    result[key] = value.isoformat()
                else:
                    result[key] = value
        
        return result"""
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –∫–ª–∞—Å—Å–∞ WorkflowState –∏ –∑–∞–º–µ–Ω—è–µ–º
            import re
            pattern = r"(class WorkflowState\(BaseModel\):.*?)(\n\nclass|\n\n#|\n\ndef|\Z)"
            
            def replace_workflow_state(match):
                return new_workflow_state + workflow_state_methods + match.group(2)
            
            content = re.sub(pattern, replace_workflow_state, content, flags=re.DOTALL)
            
            risk_models_file.write_text(content, encoding='utf-8')
            print("‚úÖ WorkflowState –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –≤ risk_models.py")
        else:
            print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–∞—Ä—ã–π WorkflowState - –≤–æ–∑–º–æ–∂–Ω–æ —É–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 2: –û–±–Ω–æ–≤–ª—è–µ–º profiler_node_function –≤ profiler_agent.py
    profiler_file = Path("src/agents/profiler_agent.py")
    
    if profiler_file.exists():
        content = profiler_file.read_text(encoding='utf-8')
        
        # –ù–∞—Ö–æ–¥–∏–º –∏ –∑–∞–º–µ–Ω—è–µ–º profiler_node_function
        old_profiler_node = """        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        updated_state = state.copy()
        updated_state["profiling_result"] = result
        
        if result.status == ProcessingStatus.COMPLETED:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            agent_profile_data = result.result_data["agent_profile"]
            updated_state["agent_profile"] = agent_profile_data"""
        
        new_profiler_node = """        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ - –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º AgentTaskResult –≤ —Å–ª–æ–≤–∞—Ä—å
        updated_state = state.copy()
        updated_state["profiling_result"] = result.dict()  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
        
        if result.status == ProcessingStatus.COMPLETED:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            agent_profile_data = result.result_data["agent_profile"]
            updated_state["agent_profile"] = agent_profile_data"""
        
        if old_profiler_node in content:
            content = content.replace(old_profiler_node, new_profiler_node)
            profiler_file.write_text(content, encoding='utf-8')
            print("‚úÖ profiler_node_function –∏—Å–ø—Ä–∞–≤–ª–µ–Ω")
        else:
            print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–∞—Ä—ã–π profiler_node - —Ä—É—á–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 3: –°–æ–∑–¥–∞–Ω–∏–µ –±—ã—Å—Ç—Ä–æ–≥–æ –ø–∞—Ç—á–∞ –¥–ª—è evaluator_agents.py
    evaluator_file = Path("src/agents/evaluator_agents.py")
    
    if evaluator_file.exists():
        content = evaluator_file.read_text(encoding='utf-8')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è LangGraph
        patch_content = '''

# ===============================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø LANGGRAPH
# ===============================

def create_evaluator_nodes_for_langgraph_fixed(evaluators: Dict[RiskType, Any]) -> Dict[str, callable]:
    """–°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤ –¥–ª—è LangGraph —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    
    def create_evaluator_node(risk_type: RiskType, evaluator):
        async def evaluator_node(state: Dict[str, Any]) -> Dict[str, Any]:
            """–£–∑–µ–ª –æ—Ü–µ–Ω—â–∏–∫–∞ –≤ LangGraph workflow"""
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            assessment_id = state.get("assessment_id", "unknown")
            agent_profile = state.get("agent_profile", {})
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            input_data = {"agent_profile": agent_profile}
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω—â–∏–∫–∞
            result = await evaluator.run(input_data, assessment_id)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ - –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º AgentTaskResult –≤ —Å–ª–æ–≤–∞—Ä—å
            updated_state = state.copy()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
            if "evaluation_results" not in updated_state:
                updated_state["evaluation_results"] = {}
            
            updated_state["evaluation_results"][risk_type.value] = result.dict()
            
            return updated_state
        
        return evaluator_node
    
    # –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã –¥–ª—è –≤—Å–µ—Ö –æ—Ü–µ–Ω—â–∏–∫–æ–≤
    nodes = {}
    for risk_type, evaluator in evaluators.items():
        node_name = f"{risk_type.value}_evaluator_node"
        nodes[node_name] = create_evaluator_node(risk_type, evaluator)
    
    return nodes


def create_critic_node_function_fixed(critic_agent):
    """–°–æ–∑–¥–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é —É–∑–ª–∞ –∫—Ä–∏—Ç–∏–∫–∞ –¥–ª—è LangGraph"""
    
    async def critic_node(state: Dict[str, Any]) -> Dict[str, Any]:
        """–£–∑–µ–ª –∫—Ä–∏—Ç–∏–∫–∞ –≤ LangGraph workflow"""
        
        assessment_id = state.get("assessment_id", "unknown")
        evaluation_results = state.get("evaluation_results", {})
        agent_profile = state.get("agent_profile", {})
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        updated_state = state.copy()
        
        if "critic_results" not in updated_state:
            updated_state["critic_results"] = {}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–∞
        for risk_type, eval_result in evaluation_results.items():
            if isinstance(eval_result, dict) and eval_result.get("result_data"):
                risk_evaluation = eval_result["result_data"].get("risk_evaluation")
                
                if risk_evaluation:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫—Ä–∏—Ç–∏–∫–∞
                    critic_input = {
                        "risk_type": risk_type,
                        "risk_evaluation": risk_evaluation,
                        "agent_profile": agent_profile,
                        "evaluator_name": eval_result.get("agent_name", "Unknown")
                    }
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫—Ä–∏—Ç–∏–∫–∞
                    critic_result = await critic_agent.run(critic_input, assessment_id)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
                    updated_state["critic_results"][risk_type] = critic_result.dict()
        
        return updated_state
    
    return critic_node
'''
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ç—á –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç
        if "create_evaluator_nodes_for_langgraph_fixed" not in content:
            content += patch_content
            evaluator_file.write_text(content, encoding='utf-8')
            print("‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ evaluator_agents.py")
        else:
            print("‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–∂–µ –µ—Å—Ç—å –≤ evaluator_agents.py")
    
    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 4: –ü–∞—Ç—á –¥–ª—è graph_builder.py
    graph_builder_file = Path("src/workflow/graph_builder.py")
    
    if graph_builder_file.exists():
        content = graph_builder_file.read_text(encoding='utf-8')
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏–º–ø–æ—Ä—Ç—ã
        old_import = """from ..agents.evaluator_agents import (
    create_all_evaluator_agents, create_evaluator_nodes_for_langgraph,
    extract_risk_evaluations_from_results, calculate_overall_risk_score,
    get_highest_risk_areas
)"""
        
        new_import = """from ..agents.evaluator_agents import (
    create_all_evaluator_agents, create_evaluator_nodes_for_langgraph_fixed,
    extract_risk_evaluations_from_results, calculate_overall_risk_score,
    get_highest_risk_areas
)"""
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
        old_usage = "evaluator_nodes = create_evaluator_nodes_for_langgraph(self.evaluators)"
        new_usage = "evaluator_nodes = create_evaluator_nodes_for_langgraph_fixed(self.evaluators)"
        
        content = content.replace(old_import, new_import)
        content = content.replace(old_usage, new_usage)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º critic_agent –∏–º–ø–æ—Ä—Ç
        old_critic_import = """from ..agents.critic_agent import (
    create_critic_agent, create_critic_node_function, create_quality_check_router
)"""
        
        new_critic_import = """from ..agents.critic_agent import (
    create_critic_agent, create_quality_check_router
)
from ..agents.evaluator_agents import create_critic_node_function_fixed"""
        
        content = content.replace(old_critic_import, new_critic_import)
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—Ä–∏—Ç–∏–∫–∞
        old_critic_usage = "critic_node = create_critic_node_function(self.critic)"
        new_critic_usage = "critic_node = create_critic_node_function_fixed(self.critic)"
        
        content = content.replace(old_critic_usage, new_critic_usage)
        
        graph_builder_file.write_text(content, encoding='utf-8')
        print("‚úÖ graph_builder.py –∏—Å–ø—Ä–∞–≤–ª–µ–Ω")
    
    print("\nüéâ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã!")
    print("\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç:")
    print("   python test_complete_workflow.py")

if __name__ == "__main__":
    apply_critical_fixes()