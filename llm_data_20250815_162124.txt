=== ДОКУМЕНТАЦИЯ ===

Файл: main.py
Тип: text_py

[FULL_CODE]
"""
Обновленный main.py с поддержкой Intelligent Orchestrator
Сохраняет всю оригинальную функциональность + добавляет новые возможности
"""
import asyncio
import logging
import argparse
import threading
import os
import sys
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Добавляем корневую директорию в path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Загрузка переменных окружения
load_dotenv()

from config.logging_config import setup_logging
from config.settings_cop2 import (
    DATABASE_URL, 
    TELEGRAM_API_ID, 
    TELEGRAM_API_HASH, 
    TELEGRAM_CHANNELS,
    TELEGRAM_BOT_TOKEN
)
from database.db_manager import DatabaseManager
from utils.telegram_session_manager import TelegramSessionManager
from telegram_bot.bot import TelegramBot
from scheduler.jobs import JobScheduler
from telethon import TelegramClient

# Импорт компонентов workflow
from llm.qwen_model import QwenLLM
from llm.gemma_model import GemmaLLM
from agents.orchestrator i...

[COMMENTS]
# Добавляем корневую директорию в path
# Загрузка переменных окружения
# Импорт компонентов workflow
# Настройка логирования
"""Включает детальное логирование reasoning для агентов"""
# Устанавливаем уровень логирования для агентов
# Создаем специальный форматтер для reasoning логов
# Получаем логгеры агентов
# Проверяем, есть ли уже handlers (чтобы не дублировать)
# Отключаем propagation чтобы избежать дублирования логов
"""Запуск планировщика в отдельном потоке"""
"""Сбор сообщений из канала и сохранение в БД"""
# Определение дат для фильтрации
# Получаем сообщения с пагинацией
# Фильтруем сообщения по дате
# Достигли сообщений старше нужной даты, прекращаем сбор
# Если сообщений меньше лимита, значит достигли конца
# Проверяем, не достигли ли мы старых сообщений
# Сохраняем сообщения в БД
"""Запуск сбора данных из всех каналов"""
"""Запуск анализа сообщений"""
"""Запуск проверки категоризации критиком"""
"""Создание дайджеста"""
"""Запуск полного рабочего процесса (legacy версия)"""...

[FUNCTIONS]

def enable_detailed_reasoning_logs():

def run_scheduler(scheduler):

def _log_execution_results(result: dict):

def run_bot_with_scheduler():

def parse_arguments():

def main():

Файл: agent_registry.py
Тип: text_py

[FULL_CODE]
"""
Обновленный реестр агентов для работы с Intelligent Orchestrator
"""
import logging
from typing import Dict, Any, Optional
from enum import Enum

logger = logging.getLogger(__name__)

class AgentType(Enum):
    """Типы агентов в системе"""
    DATA_COLLECTOR = "data_collector"
    ANALYZER = "analyzer" 
    CRITIC = "critic"
    DIGESTER = "digester"

class AgentRegistry:
    """
    Реестр агентов системы с поддержкой intelligent оркестратора
    """
    
    def __init__(self, db_manager):
        """
        Инициализация реестра агентов
        
        Args:
            db_manager: Менеджер базы данных
        """
        self.db_manager = db_manager
        self.agents = {}
        self._initialize_agents()
        
        logger.info(f"Реестр агентов инициализирован с {len(self.agents)} агентами")
    
    def _initialize_agents(self):
        """Инициализация всех агентов"""
        try:
            # Импортируем агентов
            from agents.data_collector import DataCo...

[COMMENTS]
"""Типы агентов в системе"""
"""Инициализация всех агентов"""
# Импортируем агентов
# Создаем экземпляры агентов
# Поддерживаем как строковые названия, так и enum
# Проверяем базовые атрибуты агента
# Добавляем специфичную информацию если доступна
# Проверяем наличие основных методов
# Базовая проверка инициализации
# Проверка подключения к БД
# Специфичные проверки для каждого типа агента
# Проверяем Telegram сессию если доступно
# Проверяем LLM конфигурацию
# Проверяем learning manager
# Проверяем шаблоны дайджестов
# Определяем общий статус

[FUNCTIONS]
    
    def __init__(self, db_manager):
    
    def _initialize_agents(self):
    
    def get_agent(self, agent_name: str):

[CLASSES]

class AgentType(Enum):

class AgentRegistry:

Файл: analyzer.py
Тип: text_py

[FULL_CODE]
"""
Агент для анализа и классификации сообщений
"""
import logging
import json
import os
from langchain.tools import Tool
from crewai import Agent, Task
from concurrent.futures import ThreadPoolExecutor, as_completed
from config.settings_cop2 import CATEGORIES
import datetime
from datetime import datetime as dt
import time
from utils.learning_manager import LearningExamplesManager
logger = logging.getLogger(__name__)


class AnalyzerAgent:
    def __init__(self, db_manager, llm_model=None):
        """Инициализация агента"""
        self.db_manager = db_manager
        
        # Импорт здесь, чтобы избежать циклических импортов
        from llm.qwen_model import QwenLLM
        self.llm_model = llm_model or QwenLLM()
        
        # Флаг для быстрой проверки критиком сообщений с низкой уверенностью
        self.fast_check = False
        
        # Инициализируем менеджер обучающих примеров
        self.learning_manager = LearningExamplesManager()
        
        # Создаем инструм...

[COMMENTS]
"""Инициализация агента"""
# Импорт здесь, чтобы избежать циклических импортов
# Флаг для быстрой проверки критиком сообщений с низкой уверенностью
# Инициализируем менеджер обучающих примеров
# Создаем инструмент для анализа сообщений
# Создаем агента CrewAI
# В agents/analyzer.py - улучшенный метод _classify_message
# Заменить существующий метод на этот
# Получаем примеры через LearningExamplesManager
# УЛУЧШЕННЫЙ ПРОМПТ с более четким форматом
# Используем существующий метод classify с улучшенным промптом
# УЛУЧШЕННЫЙ ПАРСИНГ ответа
# Разбиваем ответ на строки и ищем паттерны
# Ищем строку с категорией
# Извлекаем категорию после двоеточия
# Точное сопоставление с категориями
# Ищем уверенность
# Извлекаем число
# Альтернативный поиск категории в тексте ответа
# Логируем enhanced результат для отладки
# Fallback: если не удалось распарсить enhanced ответ, используем простой анализ
# Простой поиск категорий в ответе (оригинальная логика)
# Определяем базовую уверенность
# Повышаем ув...

[FUNCTIONS]
    def __init__(self, db_manager, llm_model=None):

    def _classify_message(self, message_text):
    def _format_examples_for_reasoning(self, examples):

    def _log_classification_reasoning(self, message_text, category, confidence, response):
        
    def analyze_messages(self, limit=1500, batch_size=20):
            def process_batch(batch_idx, batch):
    def create_task(self):

[CLASSES]


class AnalyzerAgent:

Файл: collaborative_crew.py
Тип: text_py

[FULL_CODE]
# agents/collaborative_crew.py
"""
Система коллаборации агентов через CrewAI
Использует СУЩЕСТВУЮЩИЕ self.agent из analyzer.py, critic.py, digester.py
"""

import logging
from datetime import datetime
from typing import Dict, List, Any
from enum import Enum

from crewai import Task, Crew, Process

logger = logging.getLogger(__name__)

class CollaborativeCrew:
    """
    Система коллаборации агентов через CrewAI
    Использует существующие self.agent из агентов системы
    """
    
    def __init__(self, agent_registry):
        """
        Инициализация системы коллаборации
        
        Args:
            agent_registry: Реестр агентов системы
        """
        self.agent_registry = agent_registry
        self.collaboration_history = []
        
        # Получаем СУЩЕСТВУЮЩИХ CrewAI агентов из наших классов
        self._get_existing_crewai_agents()
        
        logger.info("🤝 CrewAI коллаборация с СУЩЕСТВУЮЩИМИ агентами инициализирована")
    
    def _get_existing_crewai_a...

[COMMENTS]
# agents/collaborative_crew.py
# Получаем СУЩЕСТВУЮЩИХ CrewAI агентов из наших классов
"""Получаем существующие CrewAI агенты из наших классов"""
# Получаем наших агентов из реестра
# Используем ИХ self.agent (CrewAI агенты)
# ИСПРАВЛЕНО: Принудительно используем GemmaLLM для коллаборации
# Поскольку только у неё есть метод generate
# ЗАДАЧА 1: Глубокий анализ СУЩЕСТВУЮЩИМ анализатором
# ЗАДАЧА 2: Экспертная оценка СУЩЕСТВУЮЩИМ критиком
# СОЗДАЕМ CREW С СУЩЕСТВУЮЩИМИ АГЕНТАМИ
# ВЫПОЛНЯЕМ через CrewAI, но с нашей LLM
# Парсим результат
# ЗАДАЧА 1: Анализ качества СУЩЕСТВУЮЩИМ дайджестером
# ЗАДАЧА 2: Критическая оценка СУЩЕСТВУЮЩИМ критиком
# СОЗДАЕМ CREW С СУЩЕСТВУЮЩИМИ АГЕНТАМИ
# ВЫПОЛНЯЕМ через CrewAI
# Парсим результат
# Создаем задачи для всех агентов
# СОЗДАЕМ CREW СО ВСЕМИ АГЕНТАМИ
# ВЫПОЛНЯЕМ
# ИСПРАВЛЕНО: Проверяем доступность LLM
# Проверяем, что у LLM есть метод generate
# Поскольку CrewAI может не работать с нашей LLM напрямую,
# выполняем задачи последовательно через нашу L...

[FUNCTIONS]
    
    def __init__(self, agent_registry):
    
    def _get_existing_crewai_agents(self):
    
    def _log_crewai_collaboration(self, scenario: str, result: Dict[str, Any]):

[CLASSES]

class CollaborativeCrew:

Файл: context_manager.py
Тип: text_py

[FULL_CODE]
"""
Менеджер контекста для управления состоянием системы и обмена данными между агентами
"""
import logging
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class ContextScope(Enum):
    """Область видимости контекста"""
    GLOBAL = "global"           # Глобальный контекст
    SESSION = "session"         # Контекст сессии выполнения
    TASK = "task"              # Контекст отдельной задачи
    AGENT = "agent"            # Контекст агента

@dataclass
class ContextEntry:
    """Запись в контексте"""
    key: str
    value: Any
    scope: ContextScope
    created_at: datetime
    expires_at: Optional[datetime] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class ContextManager:
    """
    Менеджер контекста для управления состоянием и обмена ...

[COMMENTS]
"""Область видимости контекста"""
"""Запись в контексте"""
# Инициализируем глобальный контекст
"""Инициализация глобального контекста"""
# Состояние системы
# Конфигурация
# Кэш для часто используемых данных
"""Завершение текущей сессии"""
# Очистка временных данных сессии
"""Установка значения в глобальном контексте"""
"""Установка значения в контексте сессии"""
"""Установка значения в контексте задачи"""
"""Установка значения в контексте агента"""
"""Получение значения из глобального контекста"""
"""Получение значения из контекста сессии"""
"""Получение значения из контекста задачи"""
"""Получение значения из контекста агента"""
"""Внутренний метод установки значения"""
"""Внутренний метод получения значения"""
# Проверяем срок действия
"""Получение статистики системы с кэшированием"""
# Проверяем кэш (обновляем раз в 5 минут)
# Обновляем статистику
# Информация о последнем дайджесте
# Количество дайджестов за сегодня
# Кэшируем результат
"""Обновление статуса агента"""
"""Получение...

[FUNCTIONS]
    
    def __post_init__(self):
    
    def __init__(self, db_manager):
    
    def _initialize_global_context(self):
    
    def end_session(self):
    
    def set_global(self, key: str, value: Any, expires_in_hours: int = None):
    
    def set_session(self, key: str, value: Any, expires_in_hours: int = None):
    
    def set_task(self, task_id: str, key: str, value: Any, expires_in_minutes: int = 60):
    
    def set_agent(self, agent_type: str, key: str, value: Any, expires_in_hours: int = 24):
    
    def _set_context(self, key: str, value: Any, scope: ContextScope, expires_at: datetime = None):
    
    def update_agent_status(self, agent_type: str, status: str, metadata: Dict[str, Any] = None):
    
    def record_task_metrics(self, task_id: str, metrics: Dict[str, Any]):
    
    def _update_aggregated_metrics(self, metrics: Dict[str, Any]):
    
    def _cleanup_session_context(self):
    
    def cleanup_expired(self):

[CLASSES]

class ContextScope(Enum):
class ContextEntry:

class ContextManager:

Файл: critic.py
Тип: text_py

[FULL_CODE]
"""
Агент-критик для проверки и исправления категоризации сообщений
"""
import logging
import json
import os
from datetime import datetime
from crewai import Agent
from langchain.tools import Tool
from utils.learning_manager import LearningExamplesManager
from config.settings_cop2 import CATEGORIES
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures

logger = logging.getLogger(__name__)

class CriticAgent:
    def __init__(self, db_manager, llm_model=None):
        """
        Инициализация агента
        
        Args:
            db_manager (DatabaseManager): Менеджер БД
            llm_model (GemmaLLM, optional): Модель для обработки текста
        """
        self.db_manager = db_manager
        
        # Импорт здесь, чтобы избежать циклических импортов
        from llm.gemma_model import GemmaLLM # Changed to lazy import
        
        # Инициализируем менеджер обучающих примеров
        self.learning_manager = LearningExamplesManager()
        
       ...

[COMMENTS]
# Импорт здесь, чтобы избежать циклических импортов
# Инициализируем менеджер обучающих примеров
# Создаем инструмент для проверки категоризации
# Создаем агента CrewAI
"""Сохраняет примеры для обучения аналитика"""
# Используем менеджер обучающих примеров
# В agents/critic.py - улучшенный метод review_categorization
# Заменить существующий метод на этот
# В agents/critic.py - улучшенный метод review_categorization
# Заменить существующий метод на этот
# Получаем сообщение из базы данных
# ЭТАП 1: ПРАВОВАЯ ЭКСПЕРТИЗА
# ЭТАП 2: ЛОГИЧЕСКАЯ КОНСИСТЕНТНОСТЬ
# ЭТАП 3: КОНТЕКСТНЫЙ АНАЛИЗ
# ЭТАП 4: СИНТЕЗ И ФИНАЛЬНОЕ РЕШЕНИЕ
# ЛОГИРОВАНИЕ МНОГОПЕРСПЕКТИВНОГО REASONING
# Применяем решение
"""ЭТАП 1: Проверка правовой точности"""
"""ЭТАП 2: Проверка логической консистентности"""
"""ЭТАП 3: Контекстный анализ"""
"""ЭТАП 4: Синтез всех анализов и принятие решения"""
"""Парсинг ответов промежуточных экспертиз"""
# Определяем рекомендацию на основе ключевых слов
# Ищем уверенность
"""Парсинг финаль...

[FUNCTIONS]
    def __init__(self, db_manager, llm_model=None):
    def _save_learning_example(self, text, category, justification):
        
    def get_message_by_id(self, message_id):

    def review_categorization(self, message_id, original_category):

    def _perform_legal_accuracy_review(self, message_text, current_category):

    def _perform_consistency_review(self, message_text, current_category):

    def _perform_context_review(self, message_text, channel, current_category):

    def _synthesize_multi_perspective_decision(self, message_text, original_category, 
                                            legal_analysis, consistency_analysis, context_analysis):

    def _parse_review_response(self, response, review_type):

    def _parse_final_decision(self, response):

    def _apply_review_decision(self, message_id, message, original_category, decision):
    
    def review_recent_categorizations(self, confidence_threshold=3, limit=30, batch_size=5, max_workers=3, start_date=None, end...

[CLASSES]

class CriticAgent:

Файл: data_collector.py
Тип: text_py

[FULL_CODE]
"""
Улучшенный агент для сбора данных из Telegram-каналов
с поддержкой глубокого исторического сбора
"""
import logging
import asyncio
from datetime import datetime, timedelta
import random
import time
from telethon import TelegramClient
from telethon.tl.functions.messages import GetHistoryRequest
from telethon.errors import FloodWaitError, SlowModeWaitError
from langchain.tools import Tool
from crewai import Agent, Task

from config.settings_cop2 import TELEGRAM_API_ID, TELEGRAM_API_HASH, TELEGRAM_CHANNELS
from utils.telegram_session_manager import TelegramSessionManager

logger = logging.getLogger(__name__) # Исправлен дублированный импорт datetime

class DataCollectorAgent:
    """Улучшенный агент для сбора данных из Telegram-каналов"""
    
    def __init__(self, db_manager, api_id=None, api_hash=None):
        """
        Инициализация агента
        
        Args:
            db_manager (DatabaseManager): Менеджер БД
            api_id (str, optional): Telegram API ID
           ...

[COMMENTS]
"""Улучшенный агент для сбора данных из Telegram-каналов"""
# Создаем инструмент для сбора данных
# Создаем агента CrewAI
"""Инициализация клиента Telegram с использованием менеджера сессий"""
# Используем менеджер сессий для получения клиента
"""Корректное освобождение клиента после использования"""
# Для очень длинных периодов используем стратегию разбиения на подпериоды
# Для периодов средней длины используем оптимизированный подход с смещением дат
# Начинаем с конца периода и двигаемся назад
# Для надежности ограничиваем количество запросов
# Используем GetHistoryRequest для получения сообщений с указанным смещением
# Фильтруем сообщения по датам
# Проверяем, входит ли сообщение в наш диапазон дат
# Если дата сообщения раньше начальной даты, отмечаем это
# Логируем результаты для отладки
# Добавляем отфильтрованные сообщения к общему списку
# Если мы достигли начальной даты или собрали достаточно сообщений, завершаем сбор
# Если получили меньше сообщений, чем запросили, значит дост...

[FUNCTIONS]
    
    def __init__(self, db_manager, api_id=None, api_hash=None):
    
    def create_task(self):

[CLASSES]

class DataCollectorAgent:

Файл: digester.py
Тип: text_py

[FULL_CODE]
"""
Агент для формирования дайджеста
"""
import logging
import re
import json
from datetime import datetime, time, timedelta
from crewai import Agent, Task
from concurrent.futures import ThreadPoolExecutor, as_completed
from config.settings_cop2 import CATEGORIES, BOT_USERNAME
from llm.gemma_model import GemmaLLM
from langchain.tools import Tool
logger = logging.getLogger(__name__)

class DigesterAgent:
    """Агент для формирования дайджеста"""
    
    def __init__(self, db_manager, llm_model=None):
        """
        Инициализация агента
        
        Args:
            db_manager (DatabaseManager): Менеджер БД
            llm_model (GemmaLLM, optional): Модель для генерации текста
        """
        self.db_manager = db_manager
        self.llm_model = llm_model or GemmaLLM()
        
        create_digest_tool = Tool(
            name="create_digest",
            func=self.create_digest,
            description="Формирует дайджест правовых новостей"
        )

        # Создае...

[COMMENTS]
"""Агент для формирования дайджеста"""
# Создаем агента CrewAI
# Проверка на сообщение из канала думы
# Разделим по строкам и найдем подходящий заголовок
# Пропускаем пустые строки и стандартные заголовки
# Берем первую содержательную строку как заголовок
# Разделим текст на части до и после URL
# Ищем заголовок перед URL
# Проверяем на стандартные шаблонные заголовки
# Ищем более содержательный текст в первых нескольких строках
# Далее стандартная логика
# Если заголовок слишком короткий, ищем в тексте после URL
# Очищаем и форматируем заголовок
# Ограничиваем длину заголовка
# Находим все URL в тексте
# Удаляем дубликаты URL, сохраняя первое вхождение каждого URL
# Находим все позиции этого URL
# Сохраняем только первое вхождение
# Проверяем, не является ли это частью markdown ссылки
# Находим открывающую скобку перед URL
# Это часть markdown ссылки, не удаляем
# Удаляем URL
# Корректируем позиции остальных вхождений
# Заменяем обычные URL на markdown ссылки, если они не являются час...

[FUNCTIONS]
    
    def __init__(self, db_manager, llm_model=None):
    def _extract_title_for_url(self, text, url):
    def _add_category_icon(self, category):

    def _clean_text_with_links(self, text):
    def _extract_links_and_headlines(self, text):
    
    def _generate_brief_section(self, category, messages):

    def _generate_short_annotation(self, text, max_length=150):
    
    def _generate_detailed_section(self, category, messages):

    def _generate_digest_intro(self, date, total_messages, categories_count, is_brief=True, days_back=1):
    
    def _process_categories_parallel(self, categories_to_process, messages_by_category, digest_type):

    def create_digest(self, date=None, days_back=1, digest_type="both", 
                update_existing=True, focus_category=None,
                channels=None, keywords=None, digest_id=None):
    def get_digest_to_update(self, date, digest_type):
    def create_task(self):
    def update_digests_for_date(self, date):
    def save_digest_wi...

[CLASSES]

class DigesterAgent:

Файл: orchestrator.py
Тип: text_py

[FULL_CODE]
"""
Orchestrator Agents - оригинальный и intelligent оркестраторы

Содержит:
Intelligent Orchestrator Agent - планировщик с использованием CrewAI для принятия решений
"""
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from enum import Enum
from dataclasses import dataclass
from crewai import Agent, Task, Crew

logger = logging.getLogger(__name__)

class TaskType(Enum):
    """Типы задач в системе"""
    DATA_COLLECTION = "data_collection"
    MESSAGE_ANALYSIS = "message_analysis"
    CATEGORIZATION_REVIEW = "categorization_review"
    DIGEST_CREATION = "digest_creation"
    DIGEST_UPDATE = "digest_update"

class TaskPriority(Enum):
    """Приоритеты задач"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

class TaskStatus(Enum):
    """Статусы выполнения задач"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class Tas...

[COMMENTS]
"""Типы задач в системе"""
"""Приоритеты задач"""
"""Статусы выполнения задач"""
"""Запрос на выполнение задачи"""
"""Результат выполнения задачи"""
"""Инициализация оркестратора"""
# Создаем CrewAI агента
# Стратегии выполнения для разных сценариев
"""Главный метод планирования и выполнения"""
# Простая логика для оригинального оркестратора
"""Анализ текущего состояния системы (упрощенный)"""
# Упрощенные проверки для оригинального оркестратора
# Проверяем дайджесты за сегодня
"""Создание плана выполнения (упрощенный)"""
"""Стратегия для ежедневного рабочего процесса (упрощенная)"""
# Базовые задачи для daily_workflow
"""Стратегия для срочного обновления"""
"""Стратегия для полного анализа"""
"""Стратегия только для создания дайджеста"""
"""Упрощенное выполнение плана"""
"""Выполнение одной задачи (упрощенное)"""
# Используем синхронный метод в executor
"""Анализ результатов выполнения (упрощенный)"""
"""Создание задачи CrewAI для интеграции"""
"""Инициализация оркестратора"""
# Иници...

[FUNCTIONS]
    
    def __post_init__(self):
    
    def __init__(self, db_manager, agent_registry=None):
    
    def __init__(self, db_manager, agent_registry=None):
            def llm_generate(prompt):

[CLASSES]

class TaskType(Enum):

class TaskPriority(Enum):

class TaskStatus(Enum):
class TaskRequest:
class TaskResult:
class OrchestratorAgent:

class IntelligentOrchestratorAgent:

Файл: logging_config.py
Тип: text_py

[FULL_CODE]
"""
Конфигурация логирования
"""
import os
import logging
from logging.handlers import RotatingFileHandler

# Создаем директорию для логов, если её нет
logs_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'logs')
if not os.path.exists(logs_dir):
    os.makedirs(logs_dir)

# Путь к файлу лога
log_file_path = os.path.join(logs_dir, 'lawdigest.log')

# Базовая конфигурация логгера
def setup_logging():
    # Создаем форматтер
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Настройка для файла
    # Настройка для файла с явным указанием кодировки UTF-8
    file_handler = RotatingFileHandler(
    log_file_path,
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5,
    encoding='utf-8'  # Добавьте эту строку
    )
    file_handler.setFormatter(formatter)
    file_handler.setLevel(logging.INFO)
    
    # Настройка для консоли
    console_handler = logging.StreamHandler()
    ...

[COMMENTS]
# Создаем директорию для логов, если её нет
# Путь к файлу лога
# Базовая конфигурация логгера
# Создаем форматтер
# Настройка для файла
# Настройка для файла с явным указанием кодировки UTF-8
# Настройка для консоли
# Настраиваем корневой логгер
# Отдельные настройки для библиотек
# Установите уровень для других логгеров CrewAI

[FUNCTIONS]
def setup_logging():

Файл: settings.py
Тип: text_py

[FULL_CODE]
"""
Обновление настроек проекта
"""
import os
from dotenv import load_dotenv

# Загрузка переменных окружения из .env файла
load_dotenv()

# Telegram настройки
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_API_ID = os.getenv("TELEGRAM_API_ID")
TELEGRAM_API_HASH = os.getenv("TELEGRAM_API_HASH")
BOT_USERNAME = os.getenv("BOT_USERNAME", "your_bot_username")  # Имя бота для ссылок

# Список каналов для мониторинга
TELEGRAM_CHANNELS = [
    # Высшие органы власти
    "@kremlininfo",      # Президент РФ
    "@governmentru",     # Правительство РФ
    "@dumainfo",         # Государственная Дума
    "@sovfedinfo",       # Совет Федерации
    
    # Министерства
    "@minzdravru",       # Минздрав РФ
    "@rosmintrudru",     # Минтруд РФ
    "@minprosvetrf",     # Минпросвещения РФ
    "@minpromtorgrf",    # Минпромторг РФ
    "@MinEconomyrf",     # Минэкономразвития РФ
    "@mincifry",         # Минцифры РФ
    "@mintransrussia",   # Минтранс РФ
    "@minprirody",       # Минпр...

[COMMENTS]
# Загрузка переменных окружения из .env файла
# Telegram настройки
# Список каналов для мониторинга
# Высшие органы власти
# Министерства
# Федеральные службы и агентства
# Прочие организации
# Настройки БД
# Настройки LLM
# Категории для классификации
# Расписание задач

Файл: base_llm.py
Тип: text_py

[FULL_CODE]
"""
Базовый класс для всех LLM моделей, обеспечивающий общую логику кэширования и обработки запросов.
"""
import logging
import requests
import hashlib
import os
import time

logger = logging.getLogger(__name__)

class BaseLLM:
    """
    Базовый класс для LLM моделей, предоставляющий функциональность кэширования
    и обработки запросов к API.
    """
    def __init__(self, model_name: str, api_url: str, cache_dir: str = 'llm_cache'):
        self.model_name = model_name
        self.api_url = f"{api_url}/v1/chat/completions"
        self.cache_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), cache_dir)
        os.makedirs(self.cache_dir, exist_ok=True)
 
    def _get_cached_response(self, prompt: str, max_tokens: int, temperature: float) -> tuple[str | None, bool]:
        """
        Получение ответа из кэша с учетом типа запроса и TTL.
        """
        # Используем полный промпт для хэша, чтобы обеспечить уникальность
        cache_key = hashlib.md5((prompt + f"_t...

[COMMENTS]
# Используем полный промпт для хэша, чтобы обеспечить уникальность
# Определяем TTL в зависимости от типа запроса
# Для очень длинных запросов (больше 5000 символов) - более короткое кэширование
# Strategy: first retry with fewer tokens, then shorten prompt
# If all retries fail due to timeout, return a default error message

[FUNCTIONS]
    def __init__(self, model_name: str, api_url: str, cache_dir: str = 'llm_cache'):

[CLASSES]

class BaseLLM:

Файл: gemma_model.py
Тип: text_py

[FULL_CODE]
"""
Интерфейс для работы с моделью Gemma 3 через LLM Studio
"""
import logging
import requests
import hashlib
import os
import time
from .base_llm import BaseLLM # Added import for BaseLLM

logger = logging.getLogger(__name__)

class GemmaLLM(BaseLLM):
    """Класс для работы с моделью Gemma 3"""
    
    def __init__(self, model_name="gemma-3-12b-it", api_url="http://127.0.0.1:1234"):
        """
        Инициализация модели
        
        Args:
            model_name (str): Название модели
            api_url (str): Базовый URL для API запросов
        """ 
        super().__init__(model_name, api_url) # Call the base class constructor

    def generate(self, prompt, max_tokens=1500, temperature=0.7):
        """
        Генерация текста на основе запроса
        
        Args:
            prompt (str): Запрос к модели
            max_tokens (int): Максимальное количество токенов в ответе
            temperature (float): Температура генерации (0.0-1.0)
            
        Returns:...

[COMMENTS]
"""Класс для работы с моделью Gemma 3"""
# Use the caching logic from the base class
# If no cache, generate response
# Save to cache

[FUNCTIONS]
    
    def __init__(self, model_name="gemma-3-12b-it", api_url="http://127.0.0.1:1234"):

    def generate(self, prompt, max_tokens=1500, temperature=0.7):
    
    def summarize(self, text, max_tokens=500):

[CLASSES]

class GemmaLLM(BaseLLM):

Файл: qwen_model.py
Тип: text_py

[FULL_CODE]
"""
Интерфейс для работы с моделью Qwen2.5 через LLM Studio
"""
import logging
from .base_llm import BaseLLM # Import the new base class
import os # Added import for os
import hashlib # Added import for hashlib

logger = logging.getLogger(__name__) 

class QwenLLM(BaseLLM):
    """Класс для работы с моделью Qwen2.5"""
    
    def __init__(self, model_name="qwen2.5-14b-instruct-1m", api_url="http://127.0.0.1:1234"):
        """
        Инициализация модели
        
        Args:
            model_name (str): Название модели
            api_url (str): Базовый URL для API запросов
        """ 
        super().__init__(model_name, api_url) # Call the base class constructor
        
    def classify(self, text, categories):
        """
        Классификация текста по категориям
        
        Args:
            text (str): Текст для классификации
            categories (list): Список возможных категорий
            
        Returns:
            str: Наиболее подходящая категория
        "...

[COMMENTS]
"""Класс для работы с моделью Qwen2.5"""
# Use the caching logic from the base class, ensure prompt includes categories for caching key
# Process cached response as before
# If not found in cache, make the request
# Save to cache
# Process the response and save to cache.
"""Helper to process classification response text and return the best category."""

[FUNCTIONS]
    
    def __init__(self, model_name="qwen2.5-14b-instruct-1m", api_url="http://127.0.0.1:1234"):
        
    def classify(self, text, categories):

    def _process_classification_response(self, response_text, categories):

[CLASSES]

class QwenLLM(BaseLLM):

Файл: bot.py
Тип: text_py

[FULL_CODE]
"""
Обновления файла telegram_bot/bot.py для интеграции новых обработчиков команд
"""

import logging
from telegram import BotCommand
import asyncio
from telegram.ext import (
    Application, 
    CommandHandler, 
    MessageHandler, 
    CallbackQueryHandler,
    filters
)
from config.settings_cop2 import TELEGRAM_BOT_TOKEN # Corrected from a circular import suggestion
from telegram_bot.handlers import (
    start_command, help_command,
    period_command, list_digests_command, category_selection_command, button_callback, # Removed category_command import
)
from telegram_bot.improved_view_digest import ( # Removed start_digest_generation from this import as it's defined in handlers.py
    show_full_digest, get_category_icon
)
from telegram_bot.improved_message_handler import improved_message_handler
from llm.gemma_model import GemmaLLM # Corrected LLM import


logger = logging.getLogger(__name__)

class TelegramBot:
    def __init__(self, db_manager, llm_model=None): 
        """Иниц...

[COMMENTS]
"""Инициализация бота"""
# Убираем команды digest и detail, так как они больше не нужны
# ("digest", "Краткий дайджест новостей"),
# ("detail", "Подробный дайджест"),
"""Регистрация обработчиков команд"""
# Обработчики основных команд
# Команда для периода
# Команды выбора категории
# Улучшенная команда списка дайджестов
# Обработчик колбэков от кнопок (обновленная версия)
# Разкомментированный и исправленный обработчик текстовых сообщений
# improved_message_handler now needs db_manager and llm_model which are passed via bot_data
"""Запуск бота"""
# Создаем приложение
# Прикрепляем db_manager и llm_model к bot_data для доступа в обработчиках
# Настраиваем команды для меню бота
# Настраиваем обработчики команд
# Устанавливаем команды в интерфейсе Telegram
# Запускаем бота

[FUNCTIONS]
    def __init__(self, db_manager, llm_model=None):
    
    def run(self):

[CLASSES]

class TelegramBot:

Файл: improved_message_handler.py
Тип: text_py

[FULL_CODE]
"""
Улучшенный обработчик текстовых сообщений для бота
"""
import logging
from datetime import datetime, timedelta
from telegram import Update
from telegram.ext import ContextTypes
from llm.gemma_model import GemmaLLM # Used for LLM

logger = logging.getLogger(__name__)

async def improved_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager, llm_model):
    """
    Улучшенный обработчик текстовых сообщений с подробным логированием и диагностикой
    
    Args:
        update (Update): Объект сообщения от Telegram
        context (ContextTypes.DEFAULT_TYPE): Контекст Telegram
        db_manager: Менеджер базы данных
        llm_model: Модель для генерации ответов
    """
    # Retrieve db_manager and llm_model from bot_data if not passed directly
    if not db_manager:
        db_manager = context.bot_data.get("db_manager")
    if not llm_model:
        llm_model = context.bot_data.get("llm_model")
    
    user_message = update.message.text # Original positio...

[COMMENTS]
# Retrieve db_manager and llm_model from bot_data if not passed directly
# Проверяем, ждем ли мы от пользователя конкретный ввод
# (например, диапазон дат или название категории)
# Логика обработки диапазона дат
# ...
# Логика обработки периода для категории
# ...
# Логика обработки периода для канала
# ...
# Если нет особых ожиданий, рассматриваем как вопрос к боту
# Отправляем индикатор набора текста
# Получаем контекст для ответа - последний доступный дайджест
# Предпочитаем подробный дайджест, если есть
# Отправляем информацию пользователю
# Определяем текущую дату для поиска свежих новостей
# Получаем свежие данные за последние 7 дней
# Добавляем информацию из недавних сообщений (ограничиваем объем)
# Ограничиваем размер каждого сообщения
# Формируем запрос к модели
# Получаем ответ от модели с таймаутом
# Устанавливаем увеличенные параметры для запроса
# Проверка качества ответа
# Логируем первые 100 символов ответа для отладки
# Отправляем ответ пользователю
# Отправляем сообщен...

Файл: improved_view_digest.py
Тип: text_py

[FULL_CODE]
"""
Улучшенная версия функций для просмотра дайджеста с сокращенными данными кнопок
"""
import hashlib
import logging
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes

logger = logging.getLogger(__name__)

def get_short_category_id(category):
    """
    Создает короткий уникальный ID для категории
    
    Args:
        category (str): Полное название категории
        
    Returns:
        str: Короткий уникальный ID (до 8 символов)
    """
    # Используем хеш для создания уникального и короткого ID
    hash_object = hashlib.md5(category.encode())
    # Берем первые 6 символов хеша, чтобы он был коротким
    return hash_object.hexdigest()[:6]

async def view_digest_callback(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):
    """Обработчик колбэка для просмотра дайджеста с улучшенной обработкой ошибок"""
    query = update.callback_query
    await query.answer()
    
    try:
        # Извлекаем ID дайджест...

[COMMENTS]
# Используем хеш для создания уникального и короткого ID
# Берем первые 6 символов хеша, чтобы он был коротким
"""Обработчик колбэка для просмотра дайджеста с улучшенной обработкой ошибок"""
# Извлекаем ID дайджеста из callback_data
# Получаем дайджест с секциями по ID
# Формируем сводное содержание дайджеста
# Если есть диапазон дат, используем его
# Создаем статистику категорий
# Формируем текст оглавления
# Добавляем информацию о фокусе, если есть
# Добавляем статистику по категориям
# Создаем клавиатуру для выбора категорий с короткими ID
# Сохраняем маппинг ID категорий для этого дайджеста
# Для каждой категории создаем кнопку с коротким ID
# Генерируем короткий ID для категории
# Сохраняем маппинг ID -> категория
# Создаем кнопку с коротким callback_data
# Добавляем кнопку для просмотра полного дайджеста
# Добавляем кнопку возврата к списку дайджестов
# Отправляем оглавление дайджеста
# В случае ошибки отправляем новое сообщение вместо редактирования
"""Обработчик колбэка для про...

[FUNCTIONS]

def get_short_category_id(category):

def get_category_icon(category):

Файл: period_command.py
Тип: text_py

[FULL_CODE]
"""
Улучшенный обработчик команды /period для генерации дайджеста за произвольный период,
включая поддержку ключевых слов "сегодня" и "вчера"
"""
import logging
import re
from datetime import time, datetime, timedelta
import asyncio
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes

from agents.data_collector import DataCollectorAgent # Already imported
from agents.analyzer import AnalyzerAgent # Already imported
from agents.critic import CriticAgent # Already imported
from agents.digester import DigesterAgent # Already imported
from llm.qwen_model import QwenLLM # Added missing import
from llm.gemma_model import GemmaLLM # Added missing import
from utils.text_utils import TextUtils # Added missing import

logger = logging.getLogger(__name__)

# Утилиты для работы с текстом
utils = TextUtils() # Instantiate TextUtils

async def period_command(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):
    """Обработчик ко...

[COMMENTS]
# Утилиты для работы с текстом
"""Обработчик команды /period - генерация дайджеста за произвольный период"""
# Проверяем, есть ли аргументы
# Показываем инструкцию по использованию команды
# Разбираем аргументы
# Проверяем первый аргумент на ключевые слова
# Проверяем, есть ли указание типа дайджеста
# Проверяем, есть ли указание типа дайджеста
# Обрабатываем разные форматы ввода с датами
# Один аргумент - только дата
# Проверяем, может быть это период в одном аргументе через дефис
# Формат: 2025-04-01-2025-04-10
# Только одна дата
# Проверяем, не "сегодня" ли это
# Проверяем, может быть второй аргумент это тип дайджеста
# Проверяем, не "сегодня" ли это
# Два аргумента - начальная и конечная даты
# Проверяем, содержит ли период только сегодняшний день
# Три и более аргумента - даты и тип дайджеста
# Проверяем, содержит ли период только сегодняшний день
# Получаем тип дайджеста
# Проверяем формат дат
# Проверка уже выполнена выше, но на всякий случай оставляем дополнительную проверку
# ...

[FUNCTIONS]
def get_digest_type_name(digest_type):

Файл: helpers.py
Тип: text_py

[FULL_CODE]
# В файле utils/helpers.py
from datetime import datetime, timedelta
def normalize_date(date_obj):
    """
    Приводит дату к нормализованному виду (без часового пояса)
    
    Args:
        date_obj (datetime|date): Объект даты или datetime для нормализации
        
    Returns:
        datetime: Нормализованный объект datetime без часового пояса
    """
    if isinstance(date_obj, datetime):
        # Если это datetime с часовым поясом, убираем его
        if date_obj.tzinfo is not None:
            return date_obj.replace(tzinfo=None)
        return date_obj
    elif hasattr(date_obj, 'year') and hasattr(date_obj, 'month') and hasattr(date_obj, 'day'):
        # Если это date, преобразуем в datetime
        return datetime(date_obj.year, date_obj.month, date_obj.day)
    else:
        raise ValueError(f"Невозможно нормализовать объект типа {type(date_obj)}")

def date_to_start_of_day(date_obj):
    """
    Преобразует дату в начало дня (00:00:00)
    
    Args:
        date_obj (da...

[COMMENTS]
# В файле utils/helpers.py
# Если это datetime с часовым поясом, убираем его
# Если это date, преобразуем в datetime

[FUNCTIONS]
def normalize_date(date_obj):

def date_to_start_of_day(date_obj):

def date_to_end_of_day(date_obj):

def parse_date_string(date_str, format="%d.%m.%Y"):

Файл: learning_manager.py
Тип: text_py

[FULL_CODE]
# utils/learning_manager.py
"""
Менеджер обучающих примеров для работы с примерами категоризации
"""
import os
import json
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import threading

logger = logging.getLogger(__name__)

class LearningExamplesManager:
    """Менеджер для работы с обучающими примерами категоризации новостей"""
    
    def __init__(self, examples_dir="learning_examples", max_examples_per_category=200):
        self.examples_dir = examples_dir
        self.max_examples_per_category = max_examples_per_category
        self.examples_file = os.path.join(examples_dir, "examples.jsonl")
        self.examples_by_category = {}  # Кэш примеров по категориям
        self.last_loaded = None  # Время последней загрузки
        self.lock = threading.Lock()  # Для потокобезопасности
        
        # Инициализация директории и начальная загрузка примеров
        os.makedirs(examples_dir, exist_ok=True)
        self._load_examples()
   ...

[COMMENTS]
# utils/learning_manager.py
"""Менеджер для работы с обучающими примерами категоризации новостей"""
# Инициализация директории и начальная загрузка примеров
"""Загружает примеры из файла в кэш по категориям"""
# Группируем примеры по категориям
# Ограничиваем количество примеров в каждой категории
# Сортируем по времени и оставляем только последние
# Создаем пустой кэш в случае ошибки
# Создаем пример
# Добавляем в кэш
# Ограничиваем количество примеров в категории
# Записываем в файл с ротацией при необходимости
# Добавляем пример в файл
# Проверяем, нужно ли обновить кэш (увеличено до 30 минут)
# Блокируем только если требуется обновление кэша
# Повторная проверка после получения блокировки
# Проверяем наличие категории в кэше - этот блок не требует блокировки
# Быстрый путь - возвращаем последние примеры из указанной категории
# Получаем примеры из всех категорий (оптимизированная логика)
# Определяем количество примеров из каждой категории
# Сразу собираем базовое количество пример...

[FUNCTIONS]
    
    def __init__(self, examples_dir="learning_examples", max_examples_per_category=200):
    
    def get_examples(self, category=None, limit=5):

[CLASSES]

class LearningExamplesManager:

Файл: text_utils.py
Тип: text_py

[FULL_CODE]
# utils/text_utils.py
"""
Утилиты для обработки текста
"""
import re
import logging

logger = logging.getLogger(__name__)

class TextUtils:
    @staticmethod
    def clean_markdown_text(text):
        """Корректная обработка Markdown текста"""
        # Обработка ссылок и экранирование
        text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', 
                     lambda m: f'[{m.group(1)}]({m.group(2)})', text)
        
        # Обработка жирного текста
        text = re.sub(r'\*\*([^*]+)\*\*', r'<b>\1</b>', text)
        
        return text
    
    @staticmethod
    def convert_to_html(text):
        """Конвертирует Markdown-подобный синтаксис в HTML"""
        text = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', text)  # **жирный** -> <b>жирный</b>
        text = re.sub(r'\*(.*?)\*', r'<i>\1</i>', text)      # *курсив* -> <i>курсив</i>
        
        # Удаляем экранирующие символы
        text = re.sub(r'\\([.()[\]{}])', r'\1', text)
        
        return text
    
    @staticmethod
    def...

[COMMENTS]
# utils/text_utils.py
"""Корректная обработка Markdown текста"""
# Обработка ссылок и экранирование
# Обработка жирного текста
"""Конвертирует Markdown-подобный синтаксис в HTML"""
# Удаляем экранирующие символы
"""Разбивает длинный текст на части для Telegram"""

[FUNCTIONS]
    def clean_markdown_text(text):
    def convert_to_html(text):
    def split_text(text, max_length=4000):

[CLASSES]

class TextUtils:

Файл: test_agent.txt
Тип: text_txt

[CONTENT]
Агент: TestAgent

Описание:
Тестовый ИИ-агент для банковских операций.

Функции:
- Обработка запросов клиентов
- Анализ рисков
- Предоставление рекомендаций

Ограничения:
- Не обрабатывает персональные данные без разрешения
- Требует подтверждения для финансовых операций


Файл: README.md
Тип: text_md

[🚀_НОВАЯ_ВЕРСИЯ_С_INTELLIGENT_ПЛАНИРОВАНИЕМ!]

Система была полностью модернизирована с добавлением **Intelligent Orchestrator** - умного планировщика, который использует CrewAI для принятия решений о том, какие агенты запускать и в каком порядке.


[INTELLIGENT_ORCHESTRATOR_AGENT]
- **Умное планирование**: Анализирует текущую ситуацию и сам принимает решения
- **Контекстно-зависимые решения**: Учитывает состояние данных, количество неанализированных сообщений, наличие дайджестов
- **Объяснение решений**: Каждая задача имеет обоснование, почему она нужна
- **Адаптивные стратегии**: Разные подходы для разных сценариев
- **Fallback механизмы**: Если CrewAI недоступен, используется базовая логика


[РЕШЕНИЕ_ПРОБЛЕМЫ_С_НУЛЕВОЙ_УВЕРЕННОСТЬЮ]
Новый оркестратор **всегда** запускает анализатор и критик когда это необходимо, решая проблему с сообщениями с нулевой уверенностью (confidence=0).


[DAILY_WORKFLOW_(ЕЖЕДНЕВНЫЙ)]
- Анализирует состояние системы
- Собирает новые данные если нужно
- **Всегда** запускает анализатор для сообщений без категоризации
- **Всегда** запускает критик для улучшения качества
- Создает или обновляет дайджесты


[URGENT_UPDATE_(СРОЧНОЕ_ОБНОВЛЕНИЕ)]
- Быстрый сбор только критических данных
- Ограниченный анализ для скорости
- Создание краткого дайджеста


[FULL_ANALYSIS_(ПОЛНЫЙ_АНАЛИЗ)]
- Глубокий анализ за длительный период
- Акцент на качество анализа
- Расширенная проверка критиком


[DIGEST_ONLY_(ТОЛЬКО_ДАЙДЖЕСТ)]
- Работа только с существующими данными
- Создание дайджестов без сбора новых данных


[БЫСТРЫЙ_СТАРТ_С_INTELLIGENT_ORCHESTRATOR]

```bash

[РЕКОМЕНДУЕМЫЙ_СПОСОБ_-_С_INTELLIGENT_ПЛАНИРОВАНИЕМ]
python main.py --mode workflow --orchestrator --scenario daily_workflow


[СРОЧНОЕ_ОБНОВЛЕНИЕ]
python main.py --mode workflow --orchestrator --scenario urgent_update


[ПОЛНЫЙ_АНАЛИЗ_ЗА_НЕДЕЛЮ]
python main.py --mode workflow --orchestrator --scenario full_analysis --days 7


[ТОЛЬКО_СОЗДАНИЕ_ДАЙДЖЕСТА]
python main.py --mode workflow --orchestrator --scenario digest_only
```


[ТЕСТИРОВАНИЕ_СИСТЕМЫ]

```bash

[ТЕСТИРОВАНИЕ_INTELLIGENT_ОРКЕСТРАТОРА]
python test_intelligent_orchestrator.py


[ПРИМЕРЫ_ИСПОЛЬЗОВАНИЯ]
python orchestrator_examples.py
```


[LEGACY_РЕЖИМ_(ДЛЯ_СОВМЕСТИМОСТИ)]

```bash

[СТАРЫЙ_СПОСОБ_БЕЗ_ОРКЕСТРАТОРА]
python main.py --mode workflow --days 1


[LEGACY_РЕЖИМ]
python main.py --mode legacy --days 1
```


[АНАЛИЗ_КОНТЕКСТА]
Оркестратор собирает информацию о:
- Количестве неанализированных сообщений
- Сообщениях с низкой уверенностью категоризации
- Наличии дайджестов за сегодня
- Времени последнего сбора данных
- Статистике по категориям


[CREWAI_ПЛАНИРОВАНИЕ]
Intelligent агент анализирует ситуацию и принимает решения:
```python

[ПРИМЕР_REASONING_ОТ_ОРКЕСТРАТОРА]
"Необходим анализ 15 неанализированных сообщений для улучшения качества данных"
"Запускаю критик для проверки 8 сообщений с низкой уверенностью"
"Создаю новый дайджест, так как за сегодня дайджестов еще нет"
```


[АДАПТИВНОЕ_ВЫПОЛНЕНИЕ]
- Учитывает зависимости между задачами
- Обрабатывает ошибки с fallback логикой
- Предоставляет детальные метрики и рекомендации


[ДЕТАЛЬНОЕ_ЛОГИРОВАНИЕ]
```
=== РЕЗУЛЬТАТЫ ВЫПОЛНЕНИЯ ===
Статус: success
Сценарий: daily_workflow
Успешность: 100.0%
Время выполнения: 29.4с
Intelligent планирование: True

=== КОНТЕКСТ ПЛАНИРОВАНИЯ ===
Изначально неанализированных: 15
С низкой уверенностью: 8
Дайджестов за сегодня: 0

=== ДЕТАЛИ ВЫПОЛНЕНИЯ ЗАДАЧ ===
✅ data_collection: completed (9.56с)
✅ message_analysis: completed (8.42с)
✅ categorization_review: completed (6.21с)
✅ digest_creation: completed (5.15с)
```


[ПРОВЕРКА_ЗДОРОВЬЯ_СИСТЕМЫ]
```bash

[В_КОДЕ_МОЖНО_ИСПОЛЬЗОВАТЬ]
health_check = await registry.health_check()
print(f"Статус системы: {health_check['overall_status']}")
```


[ЧТО_ИЗМЕНИЛОСЬ]
1. **agents/orchestrator.py** → **IntelligentOrchestratorAgent**
2. **Новый** agents/agent_registry.py с улучшенной валидацией
3. **Обновленный** main.py с поддержкой новых сценариев
4. **Сохранена** обратная совместимость через legacy режим


[ОБНОВЛЕНИЕ_КОНФИГУРАЦИИ]
```bash

[УБЕДИТЕСЬ,_ЧТО_У_ВАС_ЕСТЬ_ВСЕ_ЗАВИСИМОСТИ]
poetry install


[ИЛИ_ЕСЛИ_ИСПОЛЬЗУЕТЕ_PIP]
pip install crewai


[ЗАПУСТИТЕ_ТЕСТЫ]
python test_intelligent_orchestrator.py
```


[ROBUST_ПЛАНИРОВАНИЕ]
- Если CrewAI недоступен → fallback на базовую логику
- Если агент недоступен → пропуск с логированием
- Если задача failed → продолжение с рекомендациями


[АВТОМАТИЧЕСКОЕ_ВОССТАНОВЛЕНИЕ]
```python

[ПРЕДОСТАВЛЯЕТ_РЕКОМЕНДАЦИИ_ДЛЯ_ИСПРАВЛЕНИЯ]
```


[ДЛЯ_ПРОДАКШЕНА]
```bash

[ЕЖЕДНЕВНЫЙ_ЗАПУСК_ЧЕРЕЗ_CRON]
0 9 * * * cd /path/to/bot && python main.py --mode workflow --orchestrator --scenario daily_workflow


[СРОЧНЫЕ_ОБНОВЛЕНИЯ]
python main.py --mode workflow --orchestrator --scenario urgent_update
```


[ДЛЯ_РАЗРАБОТКИ]
```bash

[ТЕСТИРОВАНИЕ_ИЗМЕНЕНИЙ]
python main.py --mode workflow --orchestrator --scenario daily_workflow --debug


[АНАЛИЗ_ПРОИЗВОДИТЕЛЬНОСТИ]
python orchestrator_examples.py
```


[ДЛЯ_МОНИТОРИНГА]
```bash

[ПРОВЕРКА_СИСТЕМЫ]
python test_intelligent_orchestrator.py


[ДЕТАЛЬНАЯ_ДИАГНОСТИКА]
python main.py --mode workflow --orchestrator --scenario daily_workflow --debug
```


[ЕСЛИ_СООБЩЕНИЯ_ОСТАЮТСЯ_С_CONFIDENCE=0]
1. Проверьте, что анализатор запускается: `message_analysis` должен быть в плане
2. Включите debug режим: `--debug`
3. Проверьте логи анализатора на ошибки


[ЕСЛИ_КРИТИК_НЕ_ЗАПУСКАЕТСЯ]
1. Intelligent оркестратор должен детектировать сообщения с низкой уверенностью
2. Проверьте, что `categorization_review` есть в плане выполнения
3. Убедитесь, что CriticAgent инициализирован корректно


[ЕСЛИ_CREWAI_НЕ_РАБОТАЕТ]
Система автоматически переключится на fallback режим с сообщением в логах:
```
Ошибка при intelligent планировании: ... 
Переходим на fallback планирование...
```


[🎉_ПРЕИМУЩЕСТВА_НОВОЙ_ВЕРСИИ]

✅ **Умное планирование** - система сама решает, что делать  
✅ **Решена проблема с confidence=0** - анализатор и критик запускаются когда нужно  
✅ **Лучшая производительность** - оптимизированные планы выполнения  
✅ **Подробная аналитика** - детальные метрики и рекомендации  
✅ **Гибкость** - разные сценарии для разных задач  
✅ **Надежность** - fallback механизмы и обработка ошибок  
✅ **Обратная совместимость** - legacy режим сохранен  


[📞_ПОДДЕРЖКА]

При проблемах:
1. Запустите `python test_intelligent_orchestrator.py`
2. Проверьте логи с `--debug` флагом
3. Попробуйте fallback: `python main.py --mode legacy`
4. Изучите примеры в `orchestrator_examples.py`

Файл: agent_config.json
Тип: text_json

[CONFIG]
{
  "agent_name": "TestAgent",
  "model": "gpt-4",
  "temperature": 0.1,
  "system_prompt": "Ты - банковский ассистент",
  "guardrails": [
    "Не разглашай конфиденциальную информацию",
    "Всегда проверяй данные клиента"
  ]
}

[PARSED_JSON]
{
  "agent_name": "TestAgent",
  "model": "gpt-4",
  "temperature": 0.1,
  "system_prompt": "Ты - банковский ассистент",
  "guardrails": [
    "Не разглашай конфиденциальную информацию",
    "Всегда проверяй данные клиента"
  ]
}


=== АНАЛИЗ ПРОМПТОВ ===
Всего промптов: 9

Системные промпты:
  1. Интерфейс для работы с моделью Gemma 3 через LLM Studio...
  2. Интерфейс для работы с моделью Qwen2.5 через LLM Studio...
  3. Приводит дату к нормализованному виду (без часового пояса)
    
    Args:
        date_obj (datetime|date): Объект даты или datetime для нормализации
        
    Returns:
        datetime: Нормализов...

Ограничения:
  1. - Не обрабатывает персональные данные без разрешения
- Требует подтверждения для финансовых операций...
  2. s": [
    "Не разглашай конфиденциальную информацию",
    "Всегда проверяй данные клиента"
  ]
}...

Возможности: code_generation