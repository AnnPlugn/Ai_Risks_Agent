# quick_test_workflow.py
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ workflow
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç
"""

import asyncio
import sys
import tempfile
import json
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, str(Path(__file__).parent / "src"))

async def test_fixed_workflow():
    """–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ workflow"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ workflow...")
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        from src.workflow import create_workflow_from_env
        from src.models.risk_models import WorkflowState
        
        print("‚úÖ –ò–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã")
        
        # –°–æ–∑–¥–∞–µ–º workflow
        workflow = create_workflow_from_env()
        print("‚úÖ Workflow —Å–æ–∑–¥–∞–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–æ—Ä–æ–≤—å–µ LLM
        llm_healthy = await workflow.profiler.health_check()
        if not llm_healthy:
            print("‚ö†Ô∏è LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return await test_with_mock_data()
        
        print("‚úÖ LLM –¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write('''# test_agent.py
class TestAgent:
    def __init__(self):
        self.name = "TestAgent"
        self.system_prompt = "–¢—ã —Ç–µ—Å—Ç–æ–≤—ã–π –ø–æ–º–æ—â–Ω–∏–∫"
    
    def process(self, query):
        return f"–û—Ç–≤–µ—Ç: {query}"
''')
            test_file = f.name
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write('''–¢–µ—Å—Ç–æ–≤—ã–π –∞–≥–µ–Ω—Ç

–ù–∞–∑–≤–∞–Ω–∏–µ: TestAgent
–¢–∏–ø: –ß–∞—Ç-–±–æ—Ç
–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã

–û–ø–∏—Å–∞–Ω–∏–µ:
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤.
–ù–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º.

–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:
- –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- –¢—Ä–µ–±—É–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –Ω–∞–¥–∑–æ—Ä–∞
''')
            doc_file = f.name
        
        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä—É—é –æ—Ü–µ–Ω–∫—É
            print("üîÑ –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏...")
            
            result = await workflow.run_assessment(
                source_files=[test_file, doc_file],
                agent_name="TestAgent"
            )
            
            if result["success"]:
                print("‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                
                assessment = result.get("final_assessment")
                if assessment:
                    print(f"üìä –û–±—â–∏–π —Ä–∏—Å–∫: {assessment['overall_risk_level']} ({assessment['overall_risk_score']}/25)")
                    print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.get('processing_time', 0):.1f}—Å")
                    print(f"üéØ –°—Ç–∞—Ç—É—Å: {result['current_step']}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Ü–µ–Ω–æ–∫
                    risk_evaluations = assessment.get("risk_evaluations", {})
                    print(f"üîç –û—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–∞: {len(risk_evaluations)}/6")
                    
                    if len(risk_evaluations) > 0:
                        print("‚úÖ –†–∏—Å–∫–∏ —É—Å–ø–µ—à–Ω–æ –æ—Ü–µ–Ω–µ–Ω—ã")
                        for risk_type, evaluation in risk_evaluations.items():
                            if isinstance(evaluation, dict):
                                level = evaluation.get("risk_level", "unknown")
                                score = evaluation.get("total_score", 0)
                                print(f"  ‚Ä¢ {risk_type}: {level} ({score}/25)")
                    
                    return True
                else:
                    print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞")
                    return False
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏: {result.get('error')}")
                return False
                
        finally:
            # –û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
            try:
                import os
                os.unlink(test_file)
                os.unlink(doc_file)
            except:
                pass
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_with_mock_data():
    """–¢–µ—Å—Ç —Å –º–æ–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –µ—Å–ª–∏ LM Studio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    print("üé≠ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–æ–∫–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
    
    try:
        from src.models.risk_models import WorkflowState, RiskType
        
        # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ workflow
        initial_state = WorkflowState(
            assessment_id="mock_test_001",
            source_files=["mock_agent.py"],
            preliminary_agent_name="MockAgent"
        )
        
        print("‚úÖ WorkflowState —Å–æ–∑–¥–∞–Ω–æ")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        test_value = initial_state.get("assessment_id")
        print(f"‚úÖ –ú–µ—Ç–æ–¥ get() —Ä–∞–±–æ—Ç–∞–µ—Ç: {test_value}")
        
        initial_state.update({"test_field": "test_value"})
        print("‚úÖ –ú–µ—Ç–æ–¥ update() —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        state_dict = initial_state.dict()
        print(f"‚úÖ –ú–µ—Ç–æ–¥ dict() —Ä–∞–±–æ—Ç–∞–µ—Ç: {len(state_dict)} –ø–æ–ª–µ–π")
        
        # –ú–æ–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        mock_agent_profile = {
            "name": "MockAgent",
            "description": "–¢–µ—Å—Ç–æ–≤—ã–π –∞–≥–µ–Ω—Ç",
            "agent_type": "chatbot",
            "llm_model": "mock-model",
            "autonomy_level": "supervised",
            "data_access": ["internal"],
            "target_audience": "–¢–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–∏",
            "system_prompts": ["–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç"],
            "guardrails": ["–¢–µ—Å—Ç–æ–≤–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ"],
            "integrations": [],
            "analyzed_files": ["mock_agent.py"],
            "code_complexity": 5,
            "documentation_quality": 7
        }
        
        initial_state.agent_profile = mock_agent_profile
        print("‚úÖ –ü—Ä–æ—Ñ–∏–ª—å –∞–≥–µ–Ω—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ú–æ–∫–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤
        mock_evaluation_results = {}
        for risk_type in RiskType:
            mock_evaluation_results[risk_type.value] = {
                "status": "completed",
                "result_data": {
                    "risk_evaluation": {
                        "risk_type": risk_type.value,
                        "evaluator_agent": f"Mock{risk_type.value.title()}Evaluator",
                        "probability_score": 3,
                        "impact_score": 3,
                        "total_score": 9,
                        "risk_level": "medium",
                        "probability_reasoning": f"–ú–æ–∫–æ–≤–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è {risk_type.value}",
                        "impact_reasoning": f"–ú–æ–∫–æ–≤–æ–µ –≤–ª–∏—è–Ω–∏–µ –¥–ª—è {risk_type.value}",
                        "identified_risks": [f"–ú–æ–∫–æ–≤—ã–π —Ä–∏—Å–∫ {risk_type.value}"],
                        "recommendations": [f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ {risk_type.value}"],
                        "suggested_controls": [f"–ö–æ–Ω—Ç—Ä–æ–ª—å {risk_type.value}"],
                        "confidence_level": 0.8
                    }
                }
            }
        
        initial_state.evaluation_results = mock_evaluation_results
        print(f"‚úÖ –ú–æ–∫–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ —Å–æ–∑–¥–∞–Ω—ã: {len(mock_evaluation_results)} —Ä–∏—Å–∫–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É
        final_assessment = {
            "agent_profile": mock_agent_profile,
            "assessment_id": initial_state.assessment_id,
            "risk_evaluations": {k: v["result_data"]["risk_evaluation"] 
                               for k, v in mock_evaluation_results.items()},
            "overall_risk_score": 12,
            "overall_risk_level": "medium",
            "priority_recommendations": [
                "–£–ª—É—á—à–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤",
                "–î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
            ],
            "processing_time_seconds": 5.0,
            "quality_checks_passed": True
        }
        
        initial_state.final_assessment = final_assessment
        initial_state.current_step = "completed"
        
        print("‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–æ–∑–¥–∞–Ω–∞")
        print(f"üìä –û–±—â–∏–π —Ä–∏—Å–∫: {final_assessment['overall_risk_level']} ({final_assessment['overall_risk_score']}/25)")
        print(f"üîç –û—Ü–µ–Ω–æ–∫ —Ä–∏—Å–∫–∞: {len(final_assessment['risk_evaluations'])}/6")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–∫–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û WORKFLOW")
    print("=" * 50)
    
    success = await test_fixed_workflow()
    
    if success:
        print("\n‚úÖ –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù –£–°–ü–ï–®–ù–û!")
        print("üéâ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print("\nüöÄ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:")
        print("   python main.py demo")
        print("   python main.py assess <—Ñ–∞–π–ª—ã>")
    else:
        print("\n‚ùå –¢–ï–°–¢ –ù–ï –ü–†–û–ô–î–ï–ù")
        print("üîß –¢—Ä–µ–±—É—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    
    return success

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)