[
  {
    "chunk_id": 0,
    "context_type": "agent_overview",
    "size_tokens": 1495,
    "content": "=== README.md ===\n# LawDigest Bot v2.0 - Intelligent Orchestrator\n\n##  –ù–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —Å Intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º!\n\n–°–∏—Å—Ç–µ–º–∞ –±—ã–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º **Intelligent Orchestrator** - —É–º–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç CrewAI –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –æ —Ç–æ–º, –∫–∞–∫–∏–µ –∞–≥–µ–Ω—Ç—ã –∑–∞–ø—É—Å–∫–∞—Ç—å –∏ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ.\n\n##  –ß—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ v2.0\n\n### Intelligent Orchestrator Agent\n- **–£–º–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é –∏ —Å–∞–º –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è\n- **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã–µ —Ä–µ—à–µ–Ω–∏—è**: –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, –Ω–∞–ª–∏—á–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n- **–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π**: –ö–∞–∂–¥–∞—è –∑–∞–¥–∞—á–∞ –∏–º–µ–µ—Ç –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ, –ø–æ—á–µ–º—É –æ–Ω–∞ –Ω—É–∂–Ω–∞\n- **–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏**: –†–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤\n- **Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã**: –ï—Å–ª–∏ CrewAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞\n\n### –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω—É–ª–µ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n–ù–æ–≤—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä **–≤—Å–µ–≥–¥–∞** –∑–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ –∫—Ä–∏—Ç–∏–∫ –∫–æ–≥–¥–∞ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —Ä–µ—à–∞—è –ø—Ä–æ–±–ª–µ–º—É —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ —Å –Ω—É–ª–µ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (confidence=0).\n\n##  –°—Ü–µ–Ω–∞—Ä–∏–∏ —Ä–∞–±–æ—Ç—ã\n\n### 1. daily_workflow (–µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π)\n- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã\n- –°–æ–±–∏—Ä–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n- **–í—Å–µ–≥–¥–∞** –∑–∞–ø—É—Å–∫–∞–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n- **–í—Å–µ–≥–¥–∞** –∑–∞–ø—É—Å–∫–∞–µ—Ç –∫—Ä–∏—Ç–∏–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞\n- –°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç—ã\n\n### 2. urgent_update (—Å—Ä–æ—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ)\n- –ë—ã—Å—Ç—Ä—ã–π —Å–±–æ—Ä —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n- –°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n\n### 3. full_analysis (–ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑)\n- –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥\n- –ê–∫—Ü–µ–Ω—Ç –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–∞\n- –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏–∫–æ–º\n\n### 4. digest_only (—Ç–æ–ª—å–∫–æ –¥–∞–π–¥–∂–µ—Å—Ç)\n- –†–∞–±–æ—Ç–∞ —Ç–æ–ª—å–∫–æ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n- –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –±–µ–∑ —Å–±–æ—Ä–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n\n## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫\n\n### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —Å Intelligent Orchestrator\n\n```bash\n# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å–ø–æ—Å–æ–± - —Å intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º\npython main.py --mode workflow --orchestrator --scenario daily_workflow\n\n# –°—Ä–æ—á–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ\npython main.py --mode workflow --orchestrator --scenario urgent_update\n\n# –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞ –Ω–µ–¥–µ–ª—é\npython main.py --mode workflow --orchestrator --scenario full_analysis --days 7\n\n# –¢–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\npython main.py --mode workflow --orchestrator --scenario digest_only\n```\n\n### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã\n\n```bash\n# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\npython test_intelligent_orchestrator.py\n\n# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\npython orchestrator_examples.py\n```\n\n### Legacy —Ä–µ–∂–∏–º (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)\n\n```bash\n# –°—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–± –±–µ–∑ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\npython main.py --mode workflow --days 1\n\n# Legacy —Ä–µ–∂–∏–º\npython main.py --mode legacy --days 1\n```\n\n##  –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Intelligent Planning\n\n### 1. –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Å–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ:\n- –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n- –°–æ–æ–±—â–µ–Ω–∏—è—Ö —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n- –ù–∞–ª–∏—á–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n- –í—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n\n### 2. CrewAI –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\nIntelligent –∞–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏—Ç—É–∞—Ü–∏—é –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è:\n```python\n# –ü—Ä–∏–º–µ—Ä reasoning –æ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞:\n\"–ù–µ–æ–±—Ö–æ–¥–∏–º –∞–Ω–∞–ª–∏–∑ 15 –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö\"\n\"–ó–∞–ø—É—Å–∫–∞—é –∫—Ä–∏—Ç–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ 8 —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\"\n\"–°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç, —Ç–∞–∫ –∫–∞–∫ –∑–∞ —Å–µ–≥–æ–¥–Ω—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –µ—â–µ –Ω–µ—Ç\"\n```\n\n### 3. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\n- –£—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏\n- –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ —Å fallback –ª–æ–≥–∏–∫–æ–π\n- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n##  –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –º–µ—Ç—Ä–∏–∫–∏\n\n### –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n```\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–´–ü–û–õ–ù–ï–ù–ò–Ø ===\n–°—Ç–∞—Ç—É—Å: success\n–°—Ü–µ–Ω–∞—Ä–∏–π: daily_workflow\n–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: 100.0%\n–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: 29.4—Å\nIntelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: True\n\n=== –ö–û–ù–¢–ï–ö–°–¢ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø ===\n–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: 15\n–° –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: 8\n–î–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è: 0\n\n=== –î–ï–¢–ê–õ–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ó–ê–î–ê–ß ===\n data_collection: completed (9.56—Å)\n message_analysis: completed (8.42—Å)\n categorization_review: completed (6.21—Å)\n digest_creation: completed (5.15—Å)\n```\n\n### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–∏—Å—Ç–µ–º—ã\n```bash\n# –í –∫–æ–¥–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å\nhealth_check = await registry.health_check()\nprint(f\"–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã: {health_check['overall_status']}\")\n```\n\n##  –ú–∏–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏\n\n### –ß—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å\n1. **agents/orchestrator.py** ‚Üí **IntelligentOrchestratorAgent**\n2. **–ù–æ–≤—ã–π** agents/agent_registry.py —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\n3. **–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π** main.py —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤\n4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞** –æ–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —á–µ—Ä–µ–∑ legacy —Ä–µ–∂–∏–º\n\n### –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n```bash\n# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\npoetry install\n\n# –ò–ª–∏ –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ pip\npip install crewai\n\n# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã\npython test_intelligent_orchestrator.py\n```\n\n## üõ° –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫\n\n### Robust –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n- –ï—Å–ª–∏ CrewAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí fallback –Ω–∞ –±–∞–∑–æ–≤—É—é –ª–æ–≥–∏–∫—É\n- –ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Üí –ø—Ä–æ–ø—É—Å–∫ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n- –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ failed ‚Üí –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\n\n### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ\n```python\n# –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n# 1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ –∞–≥–µ–Ω—Ç–æ–≤\n# 2. –ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –ø–ª–∞–Ω –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö\n# 3. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n```\n\n##  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é\n\n### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞\n```bash\n# –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ cron\n0 9 * * * cd /path/to/bot && python main.py --mode workflow --orchestrator --scenario daily_workflow\n\n# –°—Ä–æ—á–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\npython main.py --mode workflow --orchestrator --scenario urgent_update\n```\n\n### –î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏\n```bash\n# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π\npython main.py --mode workflow --orchestrator --scenario daily_workflow --debug\n\n# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\npython orchestrator_examples.py\n```\n\n### –î–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n```bash\n# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã\npython test_intelligent_orchestrator.py\n\n# –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞\npython main.py --mode workflow --orchestrator --scenario daily_workflow --debug\n```\n\n##  –û—Ç–ª–∞–¥–∫–∞ –ø—Ä–æ–±–ª–µ–º\n\n### –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Å—Ç–∞—é—Ç—Å—è —Å confidence=0\n1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è: `message_analysis` –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –ø–ª–∞–Ω–µ\n2. –í–∫–ª—é—á–∏—Ç–µ debug —Ä–µ–∂–∏–º: `--debug`\n3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ –æ—à–∏–±–∫–∏\n\n### –ï—Å–ª–∏ –∫—Ä–∏—Ç–∏–∫ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è\n1. Intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–æ–ª–∂–µ–Ω –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ `categorization_review` –µ—Å—Ç—å –≤ –ø–ª–∞–Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
  },
  {
    "chunk_id": 1,
    "context_type": "agent_overview",
    "size_tokens": 235,
    "content": "3. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ CriticAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\n\n### –ï—Å–ª–∏ CrewAI –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç\n–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ fallback —Ä–µ–∂–∏–º —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –≤ –ª–æ–≥–∞—Ö:\n```\n–û—à–∏–±–∫–∞ –ø—Ä–∏ intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏: ... \n–ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ fallback –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ...\n```\n\n##  –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏\n\n **–£–º–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** - —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–∞ —Ä–µ—à–∞–µ—Ç, —á—Ç–æ –¥–µ–ª–∞—Ç—å  \n **–†–µ—à–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å confidence=0** - –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ –∫—Ä–∏—Ç–∏–∫ –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ  \n **–õ—É—á—à–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–ª–∞–Ω—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è  \n **–ü–æ–¥—Ä–æ–±–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞** - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏  \n **–ì–∏–±–∫–æ—Å—Ç—å** - —Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á  \n **–ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å** - fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫  \n **–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** - legacy —Ä–µ–∂–∏–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω  \n\n##  –ü–æ–¥–¥–µ—Ä–∂–∫–∞\n\n–ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö:\n1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ `python test_intelligent_orchestrator.py`\n2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å `--debug` —Ñ–ª–∞–≥–æ–º\n3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ fallback: `python main.py --mode legacy`\n4. –ò–∑—É—á–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã –≤ `orchestrator_examples.py`"
  },
  {
    "chunk_id": 2,
    "context_type": "technical_architecture",
    "size_tokens": 2721,
    "content": "=== bot.py ===\n\"\"\"\n–û–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ telegram_bot/bot.py –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥\n\"\"\"\n\nimport logging\nfrom telegram import BotCommand\nimport asyncio\nfrom telegram.ext import (\n    Application, \n    CommandHandler, \n    MessageHandler, \n    CallbackQueryHandler,\n    filters\n)\nfrom config.settings_cop2 import TELEGRAM_BOT_TOKEN # Corrected from a circular import suggestion\nfrom telegram_bot.handlers import (\n    start_command, help_command,\n    period_command, list_digests_command, category_selection_command, button_callback, # Removed category_command import\n)\nfrom telegram_bot.improved_view_digest import ( # Removed start_digest_generation from this import as it's defined in handlers.py\n    show_full_digest, get_category_icon\n)\nfrom telegram_bot.improved_message_handler import improved_message_handler\nfrom llm.gemma_model import GemmaLLM # Corrected LLM import\n\n\nlogger = logging.getLogger(__name__)\n\nclass TelegramBot:\n    def __init__(self, db_manager, llm_model=None): \n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞\"\"\"\n        self.db_manager = db_manager\n        self.llm_model = llm_model or GemmaLLM()\n        self.application = None\n        self.menu_commands = [\n            # –£–±–∏—Ä–∞–µ–º –∫–æ–º–∞–Ω–¥—ã digest –∏ detail, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã\n            # (\"digest\", \"–ö—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π\"),\n            # (\"detail\", \"–ü–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\"),\n            (\"period\", \"–î–∞–π–¥–∂–µ—Å—Ç –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ (—Å–µ–≥–æ–¥–Ω—è/–≤—á–µ—Ä–∞/YYYY-MM-DD)\"),\n            (\"cat\", \"–í—ã–±—Ä–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–æ–≤–æ—Å—Ç–µ–π\"),\n            (\"list\", \"–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\"),\n            (\"help\", \"–°–ø—Ä–∞–≤–∫–∞\")\n        ]\n    \n    async def setup_commands(self):\n        \"\"\"–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥\"\"\"\n        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–∞–Ω–¥\n        self.application.add_handler(\n            CommandHandler(\"start\", lambda update, context: \n                        start_command(update, context, self.db_manager))\n        )\n        \n        self.application.add_handler(\n            CommandHandler(\"help\", lambda update, context: \n                        help_command(update, context, self.db_manager))\n        )\n        \n              \n               \n        # –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞\n        self.application.add_handler(\n            CommandHandler(\"period\", lambda update, context: \n                        period_command(update, context, self.db_manager))\n        )\n        \n        # –ö–æ–º–∞–Ω–¥—ã –≤—ã–±–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        self.application.add_handler(\n            CommandHandler(\"category\", lambda update, context: \n                        category_selection_command(update, context, self.db_manager))\n        )\n\n        self.application.add_handler(\n            CommandHandler(\"cat\", lambda update, context: \n                        category_selection_command(update, context, self.db_manager))\n        )\n        \n        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ —Å–ø–∏—Å–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        self.application.add_handler(\n            CommandHandler(\"list\", lambda update, context: \n                        list_digests_command(update.message, context, self.db_manager))\n        )\n        \n        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–æ–≤ –æ—Ç –∫–Ω–æ–ø–æ–∫ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)\n        self.application.add_handler(\n            CallbackQueryHandler(lambda update, context: \n                                button_callback(update, context, self.db_manager))\n        )\n        \n        # –†–∞–∑–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n        # improved_message_handler now needs db_manager and llm_model which are passed via bot_data\n        self.application.add_handler(\n            MessageHandler(filters.TEXT & ~filters.COMMAND, \n                           lambda update, context: improved_message_handler(update, context, \n                                                                           self.db_manager, self.llm_model))\n        )\n    \n    def run(self):\n        \"\"\"–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞\"\"\"\n        logger.info(\"–ó–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞\")\n        \n        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\n        self.application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()\n        \n        # –ü—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º db_manager –∏ llm_model –∫ bot_data –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞—Ö\n        self.application.bot_data[\"db_manager\"] = self.db_manager\n        self.application.bot_data[\"llm_model\"] = self.llm_model\n        \n        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –º–µ–Ω—é –±–æ—Ç–∞\n        commands = [\n            BotCommand(command, description) for command, description in self.menu_commands\n        ]\n        \n        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        loop.run_until_complete(self.setup_commands())\n        \n        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—ã –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Telegram\n        async def setup_commands_job(context):\n            await context.bot.set_my_commands(commands)\n        \n        self.application.job_queue.run_once(setup_commands_job, 1)\n        \n        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞\n        self.application.run_polling()\n        \n        return self.application\n\n\n=== agent_registry.py ===\n\"\"\"\n–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Intelligent Orchestrator\n\"\"\"\nimport logging\nfrom typing import Dict, Any, Optional\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\nclass AgentType(Enum):\n    \"\"\"–¢–∏–ø—ã –∞–≥–µ–Ω—Ç–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–µ\"\"\"\n    DATA_COLLECTOR = \"data_collector\"\n    ANALYZER = \"analyzer\" \n    CRITIC = \"critic\"\n    DIGESTER = \"digester\"\n\nclass AgentRegistry:\n    \"\"\"\n    –†–µ–µ—Å—Ç—Ä –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\n    \"\"\"\n    \n    def __init__(self, db_manager):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–µ—Å—Ç—Ä–∞ –∞–≥–µ–Ω—Ç–æ–≤\n        \n        Args:\n            db_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n        \"\"\"\n        self.db_manager = db_manager\n        self.agents = {}\n        self._initialize_agents()\n        \n        logger.info(f\"–†–µ–µ—Å—Ç—Ä –∞–≥–µ–Ω—Ç–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å {len(self.agents)} –∞–≥–µ–Ω—Ç–∞–º–∏\")\n    \n    def _initialize_agents(self):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\"\"\"\n        try:\n            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤\n            from agents.data_collector import DataCollectorAgent\n            from agents.analyzer import AnalyzerAgent\n            from agents.critic import CriticAgent\n            from agents.digester import DigesterAgent\n            \n            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä—ã –∞–≥–µ–Ω—Ç–æ–≤\n            self.agents[AgentType.DATA_COLLECTOR] = DataCollectorAgent(self.db_manager)\n            self.agents[AgentType.ANALYZER] = AnalyzerAgent(self.db_manager)\n            self.agents[AgentType.CRITIC] = CriticAgent(self.db_manager)\n            self.agents[AgentType.DIGESTER] = DigesterAgent(self.db_manager)\n            \n            logger.info(\"–í—Å–µ –∞–≥–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã\")\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤: {str(e)}\")\n            raise\n    \n    def get_agent(self, agent_name: str):\n        \"\"\"\n        –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –ø–æ –∏–º–µ–Ω–∏\n        \n        Args:\n            agent_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞\n            \n        Returns:\n            –≠–∫–∑–µ–º–ø–ª—è—Ä –∞–≥–µ–Ω—Ç–∞\n        \"\"\"\n        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è, —Ç–∞–∫ –∏ enum\n        if isinstance(agent_name, str):\n            agent_map = {\n                \"data_collector\": AgentType.DATA_COLLECTOR,\n                \"analyzer\": AgentType.ANALYZER,\n                \"critic\": AgentType.CRITIC,\n                \"digester\": AgentType.DIGESTER\n            }\n            agent_type = agent_map.get(agent_name)\n        else:\n            agent_type = agent_name\n        \n        if agent_type not in self.agents:\n            raise ValueError(f\"–ê–≥–µ–Ω—Ç {agent_name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–µ—Å—Ç—Ä–µ\")\n        \n        return self.agents[agent_type]\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"\n        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n        \n        Returns:\n            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º –∞–≥–µ–Ω—Ç–æ–≤\n        \"\"\"\n        status = {\n            \"total_agents\": len(self.agents),\n            \"agents\": {}\n        }\n        \n        for agent_type, agent in self.agents.items():\n            try:\n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã –∞–≥–µ–Ω—Ç–∞\n                agent_status = {\n                    \"initialized\": True,\n                    \"type\": agent_type.value,\n                    \"class\": agent.__class__.__name__\n                }\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞\n                if hasattr(agent, 'get_status'):\n                    agent_status.update(agent.get_status())\n                \n                status[\"agents\"][agent_type.value] = agent_status\n                \n            except Exception as e:\n                status[\"agents\"][agent_type.value] = {\n                    \"initialized\": False,\n                    \"error\": str(e)\n                }\n        \n        return status\n    \n    def validate_agents(self) -> Dict[str, bool]:\n        \"\"\"\n        –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n        \n        Returns:\n            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n        \"\"\"\n        validation_results = {}\n        \n        for agent_type, agent in self.agents.items():\n            try:\n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤\n                required_methods = {\n                    AgentType.DATA_COLLECTOR: ['collect_data'],\n                    AgentType.ANALYZER: ['analyze_messages'],\n                    AgentType.CRITIC: ['review_recent_categorizations'],\n                    AgentType.DIGESTER: ['create_digest']  # –£–±—Ä–∞–ª–∏ update_digest, —Ç–æ–ª—å–∫–æ create_digest\n                }\n                \n                methods_to_check = required_methods.get(agent_type, [])\n                \n                for method_name in methods_to_check:\n                    if not hasattr(agent, method_name):\n                        raise AttributeError(f\"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –º–µ—Ç–æ–¥ {method_name}\")\n                    \n                    method = getattr(agent, method_name)\n                    if not callable(method):\n                        raise AttributeError(f\"–ê—Ç—Ä–∏–±—É—Ç {method_name} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ç–æ–¥–æ–º\")\n                \n                validation_results[agent_type.value] = True\n                \n            except Exception as e:\n                logger.error(f\"–í–∞–ª–∏–¥–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞ {agent_type.value} –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞: {str(e)}\")\n                validation_results[agent_type.value] = False\n        \n        return validation_results\n    \n    async def health_check(self) -> Dict[str, Any]:\n        \"\"\"\n        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n        \n        Returns:\n            –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤\n        \"\"\"\n        health_report = {\n            \"timestamp\": logger.info(\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è –∞–≥–µ–Ω—Ç–æ–≤\"),\n            \"overall_status\": \"healthy\",\n            \"agents\": {}\n        }\n        \n        failed_agents = []\n        \n        for agent_type, agent in self.agents.items():\n            agent_health = {\n                \"status\": \"unknown\",\n                \"details\": {}\n            }\n            \n            try:\n                # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n                if agent is None:"
  },
  {
    "chunk_id": 3,
    "context_type": "technical_architecture",
    "size_tokens": 2041,
    "content": "                    raise Exception(\"–ê–≥–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n                \n                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î\n                if hasattr(agent, 'db_manager') and agent.db_manager:\n                    agent_health[\"details\"][\"database\"] = \"connected\"\n                else:\n                    agent_health[\"details\"][\"database\"] = \"not_connected\"\n                \n                # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞\n                if agent_type == AgentType.DATA_COLLECTOR:\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Telegram —Å–µ—Å—Å–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ\n                    if hasattr(agent, 'session_manager'):\n                        agent_health[\"details\"][\"telegram\"] = \"available\"\n                \n                elif agent_type == AgentType.ANALYZER:\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\n                    if hasattr(agent, 'llm_client'):\n                        agent_health[\"details\"][\"llm\"] = \"configured\"\n                \n                elif agent_type == AgentType.CRITIC:\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º learning manager\n                    if hasattr(agent, 'learning_manager'):\n                        agent_health[\"details\"][\"learning\"] = \"loaded\"\n                \n                elif agent_type == AgentType.DIGESTER:\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —à–∞–±–ª–æ–Ω—ã –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n                    if hasattr(agent, 'templates'):\n                        agent_health[\"details\"][\"templates\"] = \"loaded\"\n                \n                agent_health[\"status\"] = \"healthy\"\n                \n            except Exception as e:\n                agent_health[\"status\"] = \"unhealthy\"\n                agent_health[\"error\"] = str(e)\n                failed_agents.append(agent_type.value)\n            \n            health_report[\"agents\"][agent_type.value] = agent_health\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å\n        if failed_agents:\n            health_report[\"overall_status\"] = \"degraded\" if len(failed_agents) < len(self.agents) else \"critical\"\n            health_report[\"failed_agents\"] = failed_agents\n        \n        logger.info(f\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°—Ç–∞—Ç—É—Å: {health_report['overall_status']}\")\n        \n        return health_report\n\n=== main.py ===\n\"\"\"\n–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π main.py —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Intelligent Orchestrator\n–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å + –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏\n\"\"\"\nimport asyncio\nimport logging\nimport argparse\nimport threading\nimport os\nimport sys\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\n\n# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è\nload_dotenv()\n\nfrom config.logging_config import setup_logging\nfrom config.settings_cop2 import (\n    DATABASE_URL, \n    TELEGRAM_API_ID, \n    TELEGRAM_API_HASH, \n    TELEGRAM_CHANNELS,\n    TELEGRAM_BOT_TOKEN\n)\nfrom database.db_manager import DatabaseManager\nfrom utils.telegram_session_manager import TelegramSessionManager\nfrom telegram_bot.bot import TelegramBot\nfrom scheduler.jobs import JobScheduler\nfrom telethon import TelegramClient\n\n# –ò–º–ø–æ—Ä—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ workflow\nfrom llm.qwen_model import QwenLLM\nfrom llm.gemma_model import GemmaLLM\nfrom agents.orchestrator import OrchestratorAgent  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\nfrom agents.orchestrator import IntelligentOrchestratorAgent  # –ù–æ–≤—ã–π intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\nfrom agents.agent_registry import AgentRegistry\nfrom agents.task_queue import TaskQueue\nfrom agents.critic import CriticAgent\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\nlogger = setup_logging()\n\ndef enable_detailed_reasoning_logs():\n    \"\"\"–í–∫–ª—é—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ reasoning –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤\"\"\"\n    \n    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤\n    logging.getLogger('agents.analyzer').setLevel(logging.INFO)\n    logging.getLogger('agents.critic').setLevel(logging.INFO)\n    \n    # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è reasoning –ª–æ–≥–æ–≤\n    reasoning_formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        datefmt='%H:%M:%S'\n    )\n    \n    # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–≥–µ—Ä—ã –∞–≥–µ–Ω—Ç–æ–≤\n    analyzer_logger = logging.getLogger('agents.analyzer')\n    critic_logger = logging.getLogger('agents.critic')\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ handlers (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å)\n    if not analyzer_logger.handlers:\n        analyzer_handler = logging.StreamHandler()\n        analyzer_handler.setFormatter(reasoning_formatter)\n        analyzer_logger.addHandler(analyzer_handler)\n    \n    if not critic_logger.handlers:\n        critic_handler = logging.StreamHandler()\n        critic_handler.setFormatter(reasoning_formatter)\n        critic_logger.addHandler(critic_handler)\n    \n    # –û—Ç–∫–ª—é—á–∞–µ–º propagation —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–æ–≥–æ–≤\n    analyzer_logger.propagate = False\n    critic_logger.propagate = False\n    \n    print(\"üß† –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ reasoning –í–ö–õ–Æ–ß–ï–ù–û\")\n\ndef run_scheduler(scheduler):\n    \"\"\"–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\"\"\"\n    scheduler.start()\n\nasync def collect_messages(client, db_manager, channel, days_back=1, limit_per_request=100):\n    \"\"\"–°–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î\"\"\"\n    logger.info(f\"–°–±–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_back} –¥–Ω–µ–π...\")\n    \n    try:\n        entity = await client.get_entity(channel)\n        \n        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days_back)\n        \n        logger.info(f\"–ü–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞: —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π\n        offset_id = 0\n        all_messages = []\n        total_messages = 0\n        \n        while True:\n            messages = await client.get_messages(\n                entity, \n                limit=limit_per_request,\n                offset_id=offset_id\n            )\n            \n            if not messages:\n                break\n                \n            total_messages += len(messages)\n            \n            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–∞—Ç–µ\n            filtered_messages = []\n            for msg in messages:\n                if msg.date.replace(tzinfo=None) >= start_date:\n                    filtered_messages.append(msg)\n                else:\n                    # –î–æ—Å—Ç–∏–≥–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Å—Ç–∞—Ä—à–µ –Ω—É–∂–Ω–æ–π –¥–∞—Ç—ã, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Å–±–æ—Ä\n                    break\n            \n            if not filtered_messages:\n                break\n                \n            all_messages.extend(filtered_messages)\n            \n            # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞, –∑–Ω–∞—á–∏—Ç –¥–æ—Å—Ç–∏–≥–ª–∏ –∫–æ–Ω—Ü–∞\n            if len(messages) < limit_per_request:\n                break\n                \n            offset_id = messages[-1].id\n            \n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏ –º—ã —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n            if messages[-1].date.replace(tzinfo=None) < start_date:\n                break\n        \n        logger.info(f\"–°–æ–±—Ä–∞–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {total_messages} –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö\")\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ë–î\n        saved_count = 0\n        for msg in all_messages:\n            if msg.text:  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                try:\n                    db_manager.save_message(\n                        channel=channel,\n                        message_id=msg.id,\n                        text=msg.text,\n                        date=msg.date.replace(tzinfo=None)\n                    )\n                    saved_count += 1\n                except Exception as e:\n                    logger.warning(f\"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è {msg.id}: {str(e)}\")\n        \n        logger.info(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n        return {\"channel\": channel, \"collected\": len(all_messages), \"saved\": saved_count}\n        \n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel}: {str(e)}\")\n        return {\"channel\": channel, \"collected\": 0, \"saved\": 0, \"error\": str(e)}\n\nasync def run_data_collection(db_manager, days_back=1, force_update=False):\n    \"\"\"–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤\"\"\"\n    logger.info(f\"–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_back} –¥–Ω–µ–π...\")\n    \n    session_manager = TelegramSessionManager(api_id=TELEGRAM_API_ID, api_hash=TELEGRAM_API_HASH)"
  },
  {
    "chunk_id": 4,
    "context_type": "technical_architecture",
    "size_tokens": 1491,
    "content": "    client = await session_manager.get_client()\n    \n    try:\n        results = []\n        for channel in TELEGRAM_CHANNELS:\n            result = await collect_messages(client, db_manager, channel, days_back)\n            results.append(result)\n        \n        total_collected = sum(r['collected'] for r in results)\n        total_saved = sum(r['saved'] for r in results)\n        \n        logger.info(f\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –°–æ–±—Ä–∞–Ω–æ: {total_collected}, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {total_saved}\")\n        return {\"status\": \"success\", \"total_collected\": total_collected, \"total_saved\": total_saved, \"results\": results}\n        \n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}\")\n        return {\"status\": \"error\", \"error\": str(e)}\n    finally:\n        await session_manager.disconnect_client()\n\nasync def run_message_analysis(db_manager, llm_model):\n    \"\"\"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n    logger.info(\"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...\")\n    \n    from agents.analyzer import AnalyzerAgent\n    analyzer = AnalyzerAgent(db_manager, llm_model)\n    \n    try:\n        results = analyzer.analyze_messages()\n        logger.info(f\"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –†–µ–∑—É–ª—å—Ç–∞—Ç: {results}\")\n        return results\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–æ–±—â–µ–Ω–∏–π: {str(e)}\")\n        return {\"status\": \"error\", \"error\": str(e)}\n\nasync def run_categorization_review(db_manager, llm_model):\n    \"\"\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏–∫–æ–º\"\"\"\n    logger.info(\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏–∫–æ–º...\")\n    \n    try:\n        critic = CriticAgent(db_manager, llm_model)\n        results = critic.review_recent_categorizations(\n            confidence_threshold=3,  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é <= 3\n            limit=50,               # –ú–∞–∫—Å–∏–º—É–º 50 —Å–æ–æ–±—â–µ–Ω–∏–π\n            batch_size=5,           # –ü–æ 5 –≤ –ø–∞–∫–µ—Ç–µ\n            max_workers=3\n        )\n        logger.info(f\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±–Ω–æ–≤–ª–µ–Ω–æ: {results.get('updated', 0)}, \"\n                   f\"–≤—Å–µ–≥–æ: {results.get('total', 0)}\")\n        return results\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}\")\n        return {\"status\": \"error\", \"error\": str(e)}\n\nasync def create_digest(db_manager, llm_model, days_back=1):\n    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n    logger.info(f\"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_back} –¥–Ω–µ–π...\")\n    \n    from agents.digester import DigesterAgent\n    digester = DigesterAgent(db_manager, llm_model)\n    digest = digester.create_digest(days_back=days_back)\n    \n    logger.info(f\"–î–∞–π–¥–∂–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {digest.get('status', 'unknown')}\")\n    return digest\n\nasync def run_full_workflow(days_back=1, force_update=False):\n    \"\"\"–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ (legacy –≤–µ—Ä—Å–∏—è)\"\"\"\n    logger.info(f\"–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∑–∞ {days_back} –¥–Ω–µ–π...\")\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n    db_manager = DatabaseManager(DATABASE_URL)\n    llm_model = QwenLLM()\n    \n    try:\n        # –≠—Ç–∞–ø 1: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n        collection_result = await run_data_collection(db_manager, days_back, force_update)\n        if collection_result['status'] != 'success':\n            logger.error(\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π\")\n            return False\n        \n        # –≠—Ç–∞–ø 2: –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π\n        analysis_result = await run_message_analysis(db_manager, llm_model)\n        if analysis_result.get('status') == 'error':\n            logger.error(\"–ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π\")\n            return False\n        \n        # –≠—Ç–∞–ø 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n        review_result = await run_categorization_review(db_manager, llm_model)\n        if review_result.get('status') == 'error':\n            logger.error(\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π\")\n            return False\n        \n        # –≠—Ç–∞–ø 4: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        digest_result = await create_digest(db_manager, llm_model, days_back)\n        if digest_result.get('status') != 'success':\n            logger.error(\"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —Å –æ—à–∏–±–∫–æ–π\")\n            return False\n        \n        logger.info(\"–ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!\")\n        return True\n        \n    except Exception as e:\n        logger.error(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ä–∞–±–æ—á–µ–º –ø—Ä–æ—Ü–µ—Å—Å–µ: {str(e)}\")\n        return False\n    finally:\n        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\n        from utils.telegram_session_manager import TelegramSessionManager\n        session_manager = TelegramSessionManager()\n        await session_manager.close_all_clients()\n\nasync def run_orchestrated_workflow(scenario: str = \"daily_workflow\", **kwargs):\n    \"\"\"–ó–∞–ø—É—Å–∫ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —á–µ—Ä–µ–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\"\"\"\n    logger.info(f\"–ó–∞–ø—É—Å–∫ –æ—Ä–∫–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞: {scenario}\")\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n    db_manager = DatabaseManager(DATABASE_URL)\n    agent_registry = AgentRegistry(db_manager)\n    orchestrator = OrchestratorAgent(db_manager, agent_registry)  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n    \n    try:\n        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\n        result = await orchestrator.plan_and_execute(scenario, **kwargs)\n        \n        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n        logger.info(\"=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–´–ü–û–õ–ù–ï–ù–ò–Ø ===\")\n        logger.info(f\"–°—Ç–∞—Ç—É—Å: {result.get('status')}\")\n        logger.info(f\"–°—Ü–µ–Ω–∞—Ä–∏–π: {result.get('metrics', {}).get('scenario')}\")\n        logger.info(f\"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {result.get('metrics', {}).get('success_rate', 0):.1%}\")\n        logger.info(f\"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {result.get('metrics', {}).get('total_execution_time', 0):.1f}—Å\")\n        \n        summary = result.get('summary', {})\n        logger.info(f\"–°–æ–±—Ä–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {summary.get('collected_messages', 0)}\")\n        logger.info(f\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {summary.get('analyzed_messages', 0)}\")\n        logger.info(f\"–£–ª—É—á—à–µ–Ω–æ –∫—Ä–∏—Ç–∏–∫–æ–º: {summary.get('reviewed_messages', 0)}\")\n        logger.info(f\"–°–æ–∑–¥–∞–Ω–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {len(summary.get('created_digests', []))}\")\n        logger.info(f\"–û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {len(summary.get('updated_digests', []))}\")\n        \n        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
  },
  {
    "chunk_id": 5,
    "context_type": "technical_architecture",
    "size_tokens": 1491,
    "content": "        recommendations = result.get('recommendations', [])\n        if recommendations:\n            logger.info(\"=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===\")\n            for rec in recommendations:\n                logger.info(f\"- {rec.get('description')}\")\n        \n        return result.get('status') == 'success'\n        \n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –æ—Ä–∫–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞: {str(e)}\")\n        return False\n    finally:\n        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è\n        from utils.telegram_session_manager import TelegramSessionManager\n        session_manager = TelegramSessionManager()\n        await session_manager.close_all_clients()\n\nasync def run_intelligent_workflow(scenario: str = \"daily_workflow\", **kwargs):\n    \"\"\"\n    –ó–∞–ø—É—Å–∫ intelligent workflow —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n    \n    Args:\n        scenario: –°—Ü–µ–Ω–∞—Ä–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n    \"\"\"\n    try:\n        logger.info(f\"–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ: intelligent workflow\")\n        logger.info(f\"–ó–∞–ø—É—Å–∫ intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞: {scenario}\")\n        \n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤\n        db_manager = DatabaseManager(DATABASE_URL)\n        agent_registry = AgentRegistry(db_manager)\n        orchestrator = IntelligentOrchestratorAgent(db_manager, agent_registry)\n        \n        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∞–≥–µ–Ω—Ç–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º\n        health_check = await agent_registry.health_check()\n        logger.info(f\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∞–≥–µ–Ω—Ç–æ–≤: {health_check['overall_status']}\")\n        \n        if health_check['overall_status'] == 'critical':\n            logger.error(\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∞–≥–µ–Ω—Ç–∞–º–∏, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ\")\n            return {\"status\": \"error\", \"reason\": \"critical_agent_failures\"}\n        \n        # –ó–∞–ø—É—Å–∫ intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        result = await orchestrator.plan_and_execute(scenario=scenario, **kwargs)\n        \n        # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n        _log_execution_results(result)\n        \n        return result\n        \n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ intelligent workflow: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return {\"status\": \"error\", \"error\": str(e)}\n    \n    finally:\n        # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π\n        try:\n            from utils.telegram_session_manager import TelegramSessionManager\n            session_manager = TelegramSessionManager()\n            await session_manager.close_all_clients()\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {str(e)}\")\n\ndef _log_execution_results(result: dict):\n    \"\"\"–î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\"\"\"\n    try:\n        logger.info(\"=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ –í–´–ü–û–õ–ù–ï–ù–ò–Ø ===\")\n        logger.info(f\"–°—Ç–∞—Ç—É—Å: {result.get('status')}\")\n        \n        metrics = result.get('metrics', {})\n        if metrics:\n            logger.info(f\"–°—Ü–µ–Ω–∞—Ä–∏–π: {metrics.get('scenario')}\")\n            logger.info(f\"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {metrics.get('success_rate', 0)*100:.1f}%\")\n            logger.info(f\"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {metrics.get('total_execution_time', 0):.1f}—Å\")\n            logger.info(f\"Intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: {metrics.get('intelligent_planning', False)}\")\n        \n        summary = result.get('summary', {})\n        if summary:\n            logger.info(f\"–°–æ–±—Ä–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {summary.get('collected_messages', 0)}\")\n            logger.info(f\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {summary.get('analyzed_messages', 0)}\")\n            logger.info(f\"–£–ª—É—á—à–µ–Ω–æ –∫—Ä–∏—Ç–∏–∫–æ–º: {summary.get('reviewed_messages', 0)}\")\n            \n            created_digests = summary.get('created_digests', [])\n            if created_digests:\n                logger.info(f\"–°–æ–∑–¥–∞–Ω–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {len(created_digests)}\")\n                for digest in created_digests:\n                    logger.info(f\"  - {digest}\")\n            \n            updated_digests = summary.get('updated_digests', [])\n            if updated_digests:\n                logger.info(f\"–û–±–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {len(updated_digests)}\")\n        \n        # –õ–æ–≥–∏—Ä—É–µ–º context –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n        planning_context = result.get('planning_context', {})\n        if planning_context:\n            logger.info(\"=== –ö–û–ù–¢–ï–ö–°–¢ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø ===\")\n            logger.info(f\"–ò–∑–Ω–∞—á–∞–ª—å–Ω–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {planning_context.get('original_unanalyzed', 0)}\")\n            logger.info(f\"–° –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {planning_context.get('original_low_confidence', 0)}\")\n            logger.info(f\"–î–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è: {planning_context.get('original_digests_count', 0)}\")\n        \n        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n        recommendations = result.get('recommendations', [])\n        if recommendations:\n            logger.info(\"=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===\")\n            for rec in recommendations:\n                logger.info(f\"  - {rec.get('description')}\")\n        \n        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á\n        task_results = result.get('task_results', [])\n        if task_results:\n            logger.info(\"=== –î–ï–¢–ê–õ–ò –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ó–ê–î–ê–ß ===\")\n            for task_result in task_results:\n                status_icon = \"‚úÖ\" if task_result['status'] == 'completed' else \"‚ùå\"\n                logger.info(f\"  {status_icon} {task_result['task']}: {task_result['status']} \"\n                           f\"({task_result['execution_time']:.2f}—Å)\")\n                if task_result.get('error'):\n                    logger.info(f\"    –û—à–∏–±–∫–∞: {task_result['error']}\")\n                    \n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}\")\n\nasync def cleanup_on_shutdown(loop, scheduler=None, bot=None):\n    \"\"\"–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã\"\"\"\n    logger.info(\"–ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ–¥—É—Ä—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã...\")\n    \n    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n    if scheduler:\n        logger.info(\"–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫...\")\n        scheduler.stop()\n    \n    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ—Ç–∞ –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n    if bot and hasattr(bot, 'application'):\n        logger.info(\"–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Telegram –±–æ—Ç–∞...\")"
  },
  {
    "chunk_id": 6,
    "context_type": "technical_architecture",
    "size_tokens": 1498,
    "content": "        await bot.application.stop()\n    \n    # –û—Ç–º–µ–Ω–∞ –≤—Å–µ—Ö –∑–∞–¥–∞—á\n    tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]\n    logger.info(f\"–û—Ç–º–µ–Ω–∞ {len(tasks)} –∑–∞–¥–∞—á...\")\n    for task in tasks:\n        task.cancel()\n    \n    # –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏—Å–∫–ª—é—á–µ–Ω–∏–π\n    await asyncio.gather(*tasks, return_exceptions=True)\n    \n    logger.info(\"–ó–∞–∫—Ä—ã–≤–∞–µ–º event loop...\")\n    loop.stop()\n\ndef run_bot_with_scheduler():\n    \"\"\"–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º –∑–∞–¥–∞—á\"\"\"\n    logger.info(\"–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ Telegram –±–æ—Ç–∞ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º\")\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –ë–î\n    db_manager = DatabaseManager(DATABASE_URL)\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n    scheduler = JobScheduler(db_manager)\n    scheduler_thread = threading.Thread(target=run_scheduler, args=(scheduler,))\n    scheduler_thread.daemon = True\n    scheduler_thread.start()\n    logger.info(\"–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—É—â–µ–Ω –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\")\n    \n    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ Telegram-–±–æ—Ç–∞\n    bot = TelegramBot(db_manager)\n    bot.run()\n    \n    # –≠—Ç–æ—Ç –∫–æ–¥ –Ω–µ –±—É–¥–µ—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç, –ø–æ–∫–∞ –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç\n    logger.info(\"–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É\")\n    scheduler.stop()\n    \n    # –û—á–∏—Å—Ç–∫–∞ —Å–µ—Å—Å–∏–∏ Telethon –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏\n    session_manager = TelegramSessionManager(api_id=TELEGRAM_API_ID, api_hash=TELEGRAM_API_HASH)\n    asyncio.run(session_manager.disconnect_client())\n\ndef parse_arguments():\n    \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏\"\"\"\n    parser = argparse.ArgumentParser(description='LawDigest Bot - Intelligent News Processing System')\n    \n    parser.add_argument('--mode', \n                       choices=['bot', 'workflow', 'legacy', 'digest'], \n                       default='bot',\n                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: bot - –∑–∞–ø—É—Å–∫ –±–æ—Ç–∞ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞, '\n                            'workflow - –∑–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞, '\n                            'legacy - legacy workflow –±–µ–∑ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞, '\n                            'digest - —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞')\n    \n    parser.add_argument('--orchestrator', \n                       action='store_true',\n                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —Ä–µ–∂–∏–º–∞ workflow')\n    \n    parser.add_argument('--intelligent', \n                       action='store_true',\n                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä (–Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è)')\n    \n    parser.add_argument('--scenario', \n                       choices=['daily_workflow', 'urgent_update', 'full_analysis', 'digest_only'],\n                       default='daily_workflow',\n                       help='–°—Ü–µ–Ω–∞—Ä–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞')\n    \n    parser.add_argument('--days', \n                       type=int, \n                       default=1,\n                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')\n    \n    parser.add_argument('--force-update', \n                       action='store_true',\n                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö')\n    \n    parser.add_argument('--debug', \n                       action='store_true',\n                       help='–í–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏')\n    \n    return parser.parse_args()\n\ndef main():\n    \"\"\"–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\"\"\"\n    args = parse_arguments()\n    enable_detailed_reasoning_logs()\n    \n    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω verbose –∏–ª–∏ debug\n    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Ä–æ–≤–Ω—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n    if args.debug:\n        logging.getLogger().setLevel(logging.DEBUG)\n        logging.getLogger('agents.analyzer').setLevel(logging.DEBUG)\n        logging.getLogger('agents.critic').setLevel(logging.DEBUG)\n        logging.getLogger('agents.orchestrator').setLevel(logging.DEBUG)\n        logger.debug(\"–†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω\")\n        print(\"üîç –í–∫–ª—é—á–µ–Ω debug —Ä–µ–∂–∏–º —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏\")\n    \n    logger.info(f\"–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ: {args.mode}\")\n    logger.info(f\"LawDigest Bot v2.0 —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\")\n    \n    try:\n        if args.mode == 'bot':\n            run_bot_with_scheduler()\n            \n        elif args.mode == 'workflow':\n            if args.intelligent:\n                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n                logger.info(\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\")\n                result = asyncio.run(run_intelligent_workflow(\n                    scenario=args.scenario,\n                    days_back=args.days,\n                    force_update=args.force_update\n                ))\n                \n                # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å\n                if result.get('status') == 'success':\n                    logger.info(\"üéâ Intelligent –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!\")\n                else:\n                    logger.error(f\"‚ùå Intelligent –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏: {result.get('error', 'Unknown error')}\")\n                    \n            elif args.orchestrator:\n                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n                logger.info(\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\")\n                success = asyncio.run(run_orchestrated_workflow(\n                    scenario=args.scenario, \n                    days_back=args.days,\n                    force_update=args.force_update\n                ))\n                \n                if success:\n                    logger.info(\"üéâ –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!\")\n                else:\n                    logger.error(\"‚ùå –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏\")\n            else:\n                # Legacy —Ä–µ–∂–∏–º\n                logger.info(\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è legacy —Ä–µ–∂–∏–º\")\n                success = asyncio.run(run_full_workflow(\n                    days_back=args.days, \n                    force_update=args.force_update\n                ))\n                \n                if success:\n                    logger.info(\"üéâ Legacy –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!\")\n                else:\n                    logger.error(\"‚ùå Legacy –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –æ—à–∏–±–∫–∞–º–∏\")\n                    \n        elif args.mode == 'legacy':\n            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ legacy —Ä–µ–∂–∏–º\n            logger.info(\"–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π legacy —Ä–µ–∂–∏–º\")"
  },
  {
    "chunk_id": 7,
    "context_type": "technical_architecture",
    "size_tokens": 400,
    "content": "            success = asyncio.run(run_full_workflow(\n                days_back=args.days,\n                force_update=args.force_update\n            ))\n            \n        elif args.mode == 'digest':\n            # –¢–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            if args.intelligent:\n                # –ß–µ—Ä–µ–∑ intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\n                result = asyncio.run(run_intelligent_workflow(\n                    scenario='digest_only',\n                    days_back=args.days\n                ))\n            else:\n                # Legacy —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n                db_manager = DatabaseManager(DATABASE_URL)\n                gemma_model = GemmaLLM()\n                digest = asyncio.run(create_digest(db_manager, gemma_model, days_back=args.days))\n                \n                if digest and digest.get('status') == 'success':\n                    logger.info(\"–î–∞–π–¥–∂–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω\")\n                    logger.info(digest.get('digest_text', ''))\n                else:\n                    logger.error(\"–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç\")\n        \n    except KeyboardInterrupt:\n        logger.info(\"–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...\")\n    except Exception as e:\n        logger.error(f\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()\n\n=== _code_summary ===\n{\n  \"total_files\": 21,\n  \"languages\": {\n    \"python\": 21\n  },\n  \"total_lines\": 8556,\n  \"average_file_size\": 407.42857142857144,\n  \"complexity_indicators\": [\n    \"ai_ml_related\",\n    \"object_oriented\",\n    \"asynchronous_code\"\n  ]\n}"
  },
  {
    "chunk_id": 8,
    "context_type": "prompts_and_instructions",
    "size_tokens": 39,
    "content": "=== _prompt_summary ===\n{\n  \"total_prompts\": 0,\n  \"average_length\": 0,\n  \"has_system_prompts\": false,\n  \"has_guardrails\": false,\n  \"complexity_score\": 0.0\n}"
  },
  {
    "chunk_id": 9,
    "context_type": "business_logic",
    "size_tokens": 2298,
    "content": "=== gemma_model.py ===\n\"\"\"\n–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é Gemma 3 —á–µ—Ä–µ–∑ LLM Studio\n\"\"\"\nimport logging\nimport requests\nimport hashlib\nimport os\nimport time\nfrom .base_llm import BaseLLM # Added import for BaseLLM\n\nlogger = logging.getLogger(__name__)\n\nclass GemmaLLM(BaseLLM):\n    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é Gemma 3\"\"\"\n    \n    def __init__(self, model_name=\"gemma-3-12b-it\", api_url=\"http://127.0.0.1:1234\"):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n        \n        Args:\n            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n            api_url (str): –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤\n        \"\"\" \n        super().__init__(model_name, api_url) # Call the base class constructor\n\n    def generate(self, prompt, max_tokens=1500, temperature=0.7):\n        \"\"\"\n        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞\n        \n        Args:\n            prompt (str): –ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏\n            max_tokens (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ\n            temperature (float): –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.0-1.0)\n            \n        Returns:\n            str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç\n        \"\"\"\n        # Use the caching logic from the base class\n        cached_response, is_cached = self._get_cached_response(prompt, max_tokens, temperature)\n        if is_cached:\n            return cached_response\n\n        # If no cache, generate response\n        response = self._generate_response(prompt, max_tokens, temperature)\n        \n        # Save to cache\n        with open(os.path.join(self.cache_dir, f\"{hashlib.md5((prompt + f'_tokens{max_tokens}_temp{temperature}').encode()).hexdigest()}.txt\"), 'w', encoding='utf-8') as f:\n            f.write(response)\n        \n        return response.strip()\n    \n    def summarize(self, text, max_tokens=500):\n        \"\"\"\n        –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\n        \n        Args:\n            text (str): –¢–µ–∫—Å—Ç –¥–ª—è —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è\n            max_tokens (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ\n            \n        Returns:\n            str: –†–µ–∑—é–º–µ —Ç–µ–∫—Å—Ç–∞\n        \"\"\"\n        prompt = f\"\"\"\n        –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n        \n        {text}\n        \n        –†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å 3-4 –∞–±–∑–∞—Ü–∞.\n        \"\"\"\n        \n        try:\n            response = self._generate_response(prompt, max_tokens, temperature=0.5) # Call _generate_response from base\n            return response.strip()\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}\")\n            return \"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑—é–º–µ –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏.\"\n\n\n=== qwen_model.py ===\n\"\"\"\n–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é Qwen2.5 —á–µ—Ä–µ–∑ LLM Studio\n\"\"\"\nimport logging\nfrom .base_llm import BaseLLM # Import the new base class\nimport os # Added import for os\nimport hashlib # Added import for hashlib\n\nlogger = logging.getLogger(__name__) \n\nclass QwenLLM(BaseLLM):\n    \"\"\"–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é Qwen2.5\"\"\"\n    \n    def __init__(self, model_name=\"qwen2.5-14b-instruct-1m\", api_url=\"http://127.0.0.1:1234\"):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n        \n        Args:\n            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n            api_url (str): –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤\n        \"\"\" \n        super().__init__(model_name, api_url) # Call the base class constructor\n        \n    def classify(self, text, categories):\n        \"\"\"\n        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n        \n        Args:\n            text (str): –¢–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n            categories (list): –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n            \n        Returns:\n            str: –ù–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n        \"\"\"\n        prompt = f\"\"\"\n        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–æ –æ–¥–Ω–æ–π –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {', '.join(categories)}.\n        –¢–µ–∫—Å—Ç: {text}\n        –ö–∞—Ç–µ–≥–æ—Ä–∏—è:\n        \"\"\"\n        \n        try: # Now using base class caching and retry logic\n            # Use the caching logic from the base class, ensure prompt includes categories for caching key\n            cached_response, is_cached = self._get_cached_response(prompt, max_tokens=50, temperature=0.0) # Temperature is 0 for classification\n            if is_cached:\n                # Process cached response as before\n                return self._process_classification_response(cached_response, categories)\n            \n            # If not found in cache, make the request\n            response = self._generate_response(prompt, max_tokens=50)\n            result = response.strip()\n            \n            # Save to cache\n            with open(os.path.join(self.cache_dir, f\"{hashlib.md5((prompt + f'_tokens{50}_temp{0.0}').encode()).hexdigest()}.txt\"), 'w', encoding='utf-8') as f:\n                f.write(result)\n            \n            # Process the response and save to cache.\n            return self._process_classification_response(result, categories)\n        \n        except Exception as e: # Catch exceptions from _generate_response or file ops\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}\")\n            return categories[-1] # Fallback on error\n\n    def _process_classification_response(self, response_text, categories):\n        \"\"\"Helper to process classification response text and return the best category.\"\"\"\n        response_text = response_text.strip()\n        for category in categories:\n            if category.lower() in response_text.lower():\n                return category\n        return categories[-1] # Fallback to the last category (often \"–¥—Ä—É–≥–æ–µ\")\n\n\n=== text_utils.py ===\n# utils/text_utils.py\n\"\"\"\n–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n\"\"\"\nimport re\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass TextUtils:\n    @staticmethod\n    def clean_markdown_text(text):\n        \"\"\"–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Markdown —Ç–µ–∫—Å—Ç–∞\"\"\"\n        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫ –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n        text = re.sub(r'\\[([^\\]]+)\\]\\(([^)]+)\\)', \n                     lambda m: f'[{m.group(1)}]({m.group(2)})', text)\n        \n        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞\n        text = re.sub(r'\\*\\*([^*]+)\\*\\*', r'<b>\\1</b>', text)\n        \n        return text\n    \n    @staticmethod\n    def convert_to_html(text):\n        \"\"\"–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Markdown-–ø–æ–¥–æ–±–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –≤ HTML\"\"\"\n        text = re.sub(r'\\*\\*(.*?)\\*\\*', r'<b>\\1</b>', text)  # **–∂–∏—Ä–Ω—ã–π** -> <b>–∂–∏—Ä–Ω—ã–π</b>\n        text = re.sub(r'\\*(.*?)\\*', r'<i>\\1</i>', text)      # *–∫—É—Ä—Å–∏–≤* -> <i>–∫—É—Ä—Å–∏–≤</i>\n        \n        # –£–¥–∞–ª—è–µ–º —ç–∫—Ä–∞–Ω–∏—Ä—É—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã\n        text = re.sub(r'\\\\([.()[\\]{}])', r'\\1', text)\n        \n        return text\n    \n    @staticmethod\n    def split_text(text, max_length=4000):\n        \"\"\"–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è Telegram\"\"\"\n        if len(text) <= max_length:\n            return [text]\n        \n        parts = []\n        paragraphs = text.split(\"\\n\\n\")\n        current_part = \"\"\n        \n        for paragraph in paragraphs:\n            if len(current_part) + len(paragraph) + 2 <= max_length:\n                if current_part:\n                    current_part += \"\\n\\n\" + paragraph\n                else:\n                    current_part = paragraph\n            else:\n                parts.append(current_part)\n                current_part = paragraph\n        \n        if current_part:\n            parts.append(current_part)\n        \n        return parts\n\n=== helpers.py ===\n# –í —Ñ–∞–π–ª–µ utils/helpers.py\nfrom datetime import datetime, timedelta\ndef normalize_date(date_obj):\n    \"\"\"\n    –ü—Ä–∏–≤–æ–¥–∏—Ç –¥–∞—Ç—É –∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –≤–∏–¥—É (–±–µ–∑ —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞)\n    \n    Args:\n        date_obj (datetime|date): –û–±—ä–µ–∫—Ç –¥–∞—Ç—ã –∏–ª–∏ datetime –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏\n        \n    Returns:\n        datetime: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç datetime –±–µ–∑ —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞\n    \"\"\"\n    if isinstance(date_obj, datetime):\n        # –ï—Å–ª–∏ —ç—Ç–æ datetime —Å —á–∞—Å–æ–≤—ã–º –ø–æ—è—Å–æ–º, —É–±–∏—Ä–∞–µ–º –µ–≥–æ\n        if date_obj.tzinfo is not None:\n            return date_obj.replace(tzinfo=None)\n        return date_obj\n    elif hasattr(date_obj, 'year') and hasattr(date_obj, 'month') and hasattr(date_obj, 'day'):\n        # –ï—Å–ª–∏ —ç—Ç–æ date, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ datetime\n        return datetime(date_obj.year, date_obj.month, date_obj.day)\n    else:\n        raise ValueError(f\"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ {type(date_obj)}\")\n\ndef date_to_start_of_day(date_obj):\n    \"\"\"\n    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞—Ç—É –≤ –Ω–∞—á–∞–ª–æ –¥–Ω—è (00:00:00)\n    \n    Args:\n        date_obj (datetime|date): –û–±—ä–µ–∫—Ç –¥–∞—Ç—ã –∏–ª–∏ datetime\n        \n    Returns:\n        datetime: datetime —Å –≤—Ä–µ–º–µ–Ω–µ–º 00:00:00\n    \"\"\"\n    normalized = normalize_date(date_obj)\n    return normalized.replace(hour=0, minute=0, second=0, microsecond=0)\n\ndef date_to_end_of_day(date_obj):\n    \"\"\"\n    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞—Ç—É –≤ –∫–æ–Ω–µ—Ü –¥–Ω—è (23:59:59)\n    \n    Args:\n        date_obj (datetime|date): –û–±—ä–µ–∫—Ç –¥–∞—Ç—ã –∏–ª–∏ datetime\n        \n    Returns:\n        datetime: datetime —Å –≤—Ä–µ–º–µ–Ω–µ–º 23:59:59\n    \"\"\"\n    normalized = normalize_date(date_obj)\n    return normalized.replace(hour=23, minute=59, second=59, microsecond=999999)\n\ndef parse_date_string(date_str, format=\"%d.%m.%Y\"):\n    \"\"\"\n    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Å –¥–∞—Ç–æ–π –≤ –æ–±—ä–µ–∫—Ç datetime\n    \n    Args:\n        date_str (str): –°—Ç—Ä–æ–∫–∞ —Å –¥–∞—Ç–æ–π\n        format (str): –§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã\n        \n    Returns:\n        datetime: –û–±—ä–µ–∫—Ç datetime\n    \"\"\"\n    try:\n        return datetime.strptime(date_str, format)\n    except ValueError:\n        raise ValueError(f\"–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞—Ç—É '{date_str}' –≤ —Ñ–æ—Ä–º–∞—Ç–µ '{format}'\")"
  },
  {
    "chunk_id": 10,
    "context_type": "business_logic",
    "size_tokens": 2812,
    "content": "=== base_llm.py ===\n\"\"\"\n–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö LLM –º–æ–¥–µ–ª–µ–π, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏–π –æ–±—â—É—é –ª–æ–≥–∏–∫—É –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤.\n\"\"\"\nimport logging\nimport requests\nimport hashlib\nimport os\nimport time\n\nlogger = logging.getLogger(__name__)\n\nclass BaseLLM:\n    \"\"\"\n    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è LLM –º–æ–¥–µ–ª–µ–π, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è\n    –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API.\n    \"\"\"\n    def __init__(self, model_name: str, api_url: str, cache_dir: str = 'llm_cache'):\n        self.model_name = model_name\n        self.api_url = f\"{api_url}/v1/chat/completions\"\n        self.cache_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), cache_dir)\n        os.makedirs(self.cache_dir, exist_ok=True)\n \n    def _get_cached_response(self, prompt: str, max_tokens: int, temperature: float) -> tuple[str | None, bool]:\n        \"\"\"\n        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –∫—ç—à–∞ —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞ –∏ TTL.\n        \"\"\"\n        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ö—ç—à–∞, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å\n        cache_key = hashlib.md5((prompt + f\"_tokens{max_tokens}_temp{temperature}\").encode()).hexdigest()\n        cache_file = os.path.join(self.cache_dir, f\"{cache_key}.txt\")\n\n        if os.path.exists(cache_file):\n            file_age = time.time() - os.path.getmtime(cache_file)\n\n            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º TTL –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞\n            cache_ttl = 86400  # 24 —á–∞—Å–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n\n            if \"–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å\" in prompt.lower() or \"–∫–∞—Ç–µ–≥–æ—Ä–∏\" in prompt.lower():\n                cache_ttl = 604800  # 7 –¥–Ω–µ–π\n            elif \"–¥–∞–π–¥–∂–µ—Å—Ç\" in prompt.lower() or \"–Ω–æ–≤–æ—Å—Ç\" in prompt.lower():\n                cache_ttl = 43200  # 12 —á–∞—Å–æ–≤\n            \n            # –î–ª—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–±–æ–ª—å—à–µ 5000 —Å–∏–º–≤–æ–ª–æ–≤) - –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ\n            if len(prompt) > 5000:\n                cache_ttl = 21600  # 6 —á–∞—Å–æ–≤\n            \n            if file_age < cache_ttl:\n                try:\n                    with open(cache_file, 'r', encoding='utf-8') as f:\n                        cached_response = f.read()\n                        logger.debug(f\"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∫—ç—à –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (—Ö—ç—à: {cache_key[:8]}..., TTL: {cache_ttl/3600:.1f}h)\")\n                        return cached_response, True\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∫—ç—à–∞ –∏–∑ —Ñ–∞–π–ª–∞ {cache_file}: {str(e)}\")\n\n        return None, False\n\n    def _generate_response(self, prompt: str, max_tokens: int = 1000, temperature: float = 0.7, retry_count: int = 0) -> str:\n        \"\"\"\n        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ API –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–∞–π–º–∞—É—Ç–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.\n        \"\"\"\n        payload = {\n            \"model\": self.model_name,\n            \"messages\": [\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            \"max_tokens\": max_tokens,\n            \"temperature\": temperature\n        }\n        \n        prompt_length = len(prompt)\n        logger.debug(f\"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM ({prompt_length} —Å–∏–º–≤–æ–ª–æ–≤, {max_tokens} —Ç–æ–∫–µ–Ω–æ–≤) –∫ {self.api_url}\")\n        \n        start_time = time.time()\n        try:\n            response = requests.post(self.api_url, json=payload, timeout=60) # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç\n            response.raise_for_status()\n            \n            elapsed = time.time() - start_time\n            logger.debug(f\"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM –∑–∞ {elapsed:.2f} —Å–µ–∫—É–Ω–¥\")\n            \n            data = response.json()\n            return data['choices'][0]['message']['content']\n            \n        except requests.exceptions.Timeout:\n            logger.warning(f\"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM –ø–æ—Å–ª–µ {time.time() - start_time:.2f} —Å–µ–∫—É–Ω–¥ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count+1})\")\n            if retry_count < 2: # Max 3 attempts\n                # Strategy: first retry with fewer tokens, then shorten prompt\n                if retry_count == 0 and max_tokens > 500:\n                    new_max_tokens = int(max_tokens * 0.5) # Try halving tokens\n                    logger.info(f\"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º —á–∏—Å–ª–æ–º —Ç–æ–∫–µ–Ω–æ–≤ ({max_tokens} -> {new_max_tokens})\")\n                    return self._generate_response(prompt, max_tokens=new_max_tokens, temperature=temperature, retry_count=retry_count+1)\n                elif retry_count == 1 and prompt_length > 1500:\n                    shortened_prompt = prompt[:1500] + \"...[—Ç–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω –¥–ª—è —Ä–µ—Ç—Ä–∞—è]\"\n                    logger.info(f\"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º ({prompt_length} -> {len(shortened_prompt)} —Å–∏–º–≤–æ–ª–æ–≤)\")\n                    return self._generate_response(shortened_prompt, max_tokens=500, temperature=temperature, retry_count=retry_count+1)\n            \n            # If all retries fail due to timeout, return a default error message\n            return \"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM –∏–∑-–∑–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∞–π–º–∞—É—Ç–∞.\"\n        \n        except requests.exceptions.RequestException as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ API –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ {time.time() - start_time:.2f} —Å–µ–∫—É–Ω–¥ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count+1}): {str(e)}\")\n            if retry_count < 1: # Max 2 attempts for other request errors\n                time.sleep(1) # Small pause before retrying\n                return self._generate_response(prompt, max_tokens, temperature, retry_count+1)\n            raise # Re-raise if retries exhausted or non-retryable error\n\n\n=== improved_message_handler.py ===\n\"\"\"\n–£–ª—É—á—à–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –±–æ—Ç–∞\n\"\"\"\nimport logging\nfrom datetime import datetime, timedelta\nfrom telegram import Update\nfrom telegram.ext import ContextTypes\nfrom llm.gemma_model import GemmaLLM # Used for LLM\n\nlogger = logging.getLogger(__name__)\n\nasync def improved_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager, llm_model):\n    \"\"\"\n    –£–ª—É—á—à–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π\n    \n    Args:\n        update (Update): –û–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç Telegram\n        context (ContextTypes.DEFAULT_TYPE): –ö–æ–Ω—Ç–µ–∫—Å—Ç Telegram\n        db_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n        llm_model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤\n    \"\"\"\n    # Retrieve db_manager and llm_model from bot_data if not passed directly\n    if not db_manager:\n        db_manager = context.bot_data.get(\"db_manager\")\n    if not llm_model:\n        llm_model = context.bot_data.get(\"llm_model\")\n    \n    user_message = update.message.text # Original position. No change needed.\n    user_id = update.effective_user.id\n    \n    logger.info(f\"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {user_message[:50]}...\")\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∂–¥–µ–º –ª–∏ –º—ã –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–≤–æ–¥ \n    # (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)\n    if context.user_data.get(\"awaiting_date_range\"):\n        logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –≤–≤–æ–¥–∞ (–¥–∞—Ç–∞): {user_message}\")\n        # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç\n        # ...\n        return\n    \n    if context.user_data.get(\"awaiting_category_period\"):\n        logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –≤–≤–æ–¥–∞ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è): {user_message}\")\n        # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        # ...\n        return\n    \n    if context.user_data.get(\"awaiting_channel_period\"):\n        logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –≤–≤–æ–¥–∞ (–∫–∞–Ω–∞–ª): {user_message}\")\n        # –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è –∫–∞–Ω–∞–ª–∞\n        # ...\n        return\n    \n    # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Å–æ–±—ã—Ö –æ–∂–∏–¥–∞–Ω–∏–π, —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–∫ –≤–æ–ø—Ä–æ—Å –∫ –±–æ—Ç—É\n    try:\n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–∞–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞\n        await update.message.chat.send_action(action=\"typing\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ - –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\n        logger.info(f\"–ü–æ–∏—Å–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}...\")\n        brief_digest = db_manager.get_latest_digest_with_sections(digest_type=\"brief\")\n        detailed_digest = db_manager.get_latest_digest_with_sections(digest_type=\"detailed\")\n        \n        # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å\n        digest = detailed_digest or brief_digest\n        \n        if digest:\n            logger.info(f\"–ù–∞–π–¥–µ–Ω –¥–∞–π–¥–∂–µ—Å—Ç ID={digest['id']} –æ—Ç {digest['date'].strftime('%Y-%m-%d')} ({digest['digest_type']}) –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\")\n        else:\n            logger.warning(\"–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.\")\n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n            await update.message.reply_text(\n                \"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —É –º–µ–Ω—è –ø–æ–∫–∞ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å. \"\n                \"–î–∞–π–¥–∂–µ—Å—Ç –µ—â–µ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω. –í—ã –º–æ–∂–µ—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /period\"\n            )\n            return\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π\n        current_date = datetime.now()\n        date_from = current_date - timedelta(days=7)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π\n        \n        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π\n        recent_messages = db_manager.get_messages_by_date_range(\n            start_date=date_from,\n            end_date=current_date\n        )\n        \n        recent_data = \"\"\n        if recent_messages:\n            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—ä–µ–º)\n            max_recent_msgs = min(5, len(recent_messages))\n            recent_data = \"\\n\\n–ù–µ–¥–∞–≤–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏:\\n\"\n            for i, msg in enumerate(recent_messages[:max_recent_msgs]):\n                recent_data += f\"{i+1}. –ö–∞–Ω–∞–ª {msg.channel}, {msg.date.strftime('%d.%m.%Y')}: \"\n                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n                msg_preview = msg.text[:150] + \"...\" if len(msg.text) > 150 else msg.text\n                recent_data += f\"{msg_preview}\\n\\n\"\n        \n        logger.info(f\"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(recent_messages[:5])} –Ω–µ–¥–∞–≤–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\")\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏\n        prompt = f\"\"\"\n        –í–æ–ø—Ä–æ—Å: {user_message}\n        \n        –ö–æ–Ω—Ç–µ–∫—Å—Ç (–¥–∞–π–¥–∂–µ—Å—Ç –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π):\n        {digest[\"text\"]}\n        {recent_data}\n        \n        –î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∏ —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n        –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.\n        –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π, —É–∫–∞–∂–∏, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç \n        –ø–æ–ª—É—á–∏—Ç—å –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ–º–∞–Ω–¥—ã /category.\n        \"\"\"\n        \n        logger.info(f\"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM, –¥–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º\n        try:\n            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\n            response = llm_model.generate(\n                prompt=prompt,\n                max_tokens=500,\n                temperature=0.7  # –ù–µ–º–Ω–æ–≥–æ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n            )\n            \n            logger.info(f\"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç LLM, –¥–ª–∏–Ω–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤\")\n            \n            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞\n            if len(response.strip()) < 10:\n                logger.warning(f\"–ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: '{response}'\")\n                response = \"–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–Ω–∞—á–µ –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.\"\n            \n            # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n            logger.info(f\"–û—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {response[:100]}...\")\n            \n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é\n            await update.message.reply_text(response)\n            \n        except Exception as e:"
  },
  {
    "chunk_id": 11,
    "context_type": "business_logic",
    "size_tokens": 1680,
    "content": "            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}\", exc_info=True)\n            \n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ\n            await update.message.reply_text(\n                \"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. \"\n                \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∫–æ–º–∞–Ω–¥–∞–º–∏ /digest –∏–ª–∏ /category.\"\n            )\n    \n    except Exception as e:\n        logger.error(f\"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π: {str(e)}\", exc_info=True)\n        \n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ\n        await update.message.reply_text(\n            \"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. \"\n            \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.\"\n        )\n\n\n=== learning_manager.py ===\n# utils/learning_manager.py\n\"\"\"\n–ú–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n\"\"\"\nimport os\nimport json\nimport logging\nfrom datetime import datetime\nfrom typing import List, Dict, Any, Optional\nimport threading\n\nlogger = logging.getLogger(__name__)\n\nclass LearningExamplesManager:\n    \"\"\"–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–±—É—á–∞—é—â–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π\"\"\"\n    \n    def __init__(self, examples_dir=\"learning_examples\", max_examples_per_category=200):\n        self.examples_dir = examples_dir\n        self.max_examples_per_category = max_examples_per_category\n        self.examples_file = os.path.join(examples_dir, \"examples.jsonl\")\n        self.examples_by_category = {}  # –ö—ç—à –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n        self.last_loaded = None  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–≥—Ä—É–∑–∫–∏\n        self.lock = threading.Lock()  # –î–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n        \n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤\n        os.makedirs(examples_dir, exist_ok=True)\n        self._load_examples()\n    \n    def _load_examples(self) -> None:\n        \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∫—ç—à –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\"\"\"\n        with self.lock:\n            self.examples_by_category = {}\n            \n            if not os.path.exists(self.examples_file):\n                logger.info(f\"–§–∞–π–ª –ø—Ä–∏–º–µ—Ä–æ–≤ {self.examples_file} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω.\")\n                return\n            \n            try:\n                examples = []\n                with open(self.examples_file, \"r\", encoding=\"utf-8\") as f:\n                    for line in f:\n                        example = json.loads(line)\n                        examples.append(example)\n                \n                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n                for example in examples:\n                    category = example.get(\"category\", \"–¥—Ä—É–≥–æ–µ\")\n                    if category not in self.examples_by_category:\n                        self.examples_by_category[category] = []\n                    self.examples_by_category[category].append(example)\n                \n                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n                for category in self.examples_by_category:\n                    if len(self.examples_by_category[category]) > self.max_examples_per_category:\n                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ\n                        self.examples_by_category[category].sort(\n                            key=lambda x: x.get(\"timestamp\", \"\"), reverse=True\n                        )\n                        self.examples_by_category[category] = self.examples_by_category[category][:self.max_examples_per_category]\n                \n                self.last_loaded = datetime.now()\n                logger.info(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {sum(len(examples) for examples in self.examples_by_category.values())} –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ {len(self.examples_by_category)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π\")\n            \n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–∏–º–µ—Ä–æ–≤: {str(e)}\")\n                # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –∫—ç—à –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏\n                self.examples_by_category = {}\n    \n    def save_example(self, text: str, category: str, justification: str) -> bool:\n        \"\"\"\n        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä –≤ –∫—ç—à –∏ —Ñ–∞–π–ª\n        \n        Args:\n            text (str): –¢–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä–∞\n            category (str): –ö–∞—Ç–µ–≥–æ—Ä–∏—è\n            justification (str): –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n            \n        Returns:\n            bool: True –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ\n        \"\"\"\n        with self.lock:\n            try:\n                # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä\n                example = {\n                    \"text\": text,\n                    \"category\": category,\n                    \"justification\": justification,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à\n                if category not in self.examples_by_category:\n                    self.examples_by_category[category] = []\n                \n                self.examples_by_category[category].append(example)\n                \n                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n                if len(self.examples_by_category[category]) > self.max_examples_per_category:\n                    self.examples_by_category[category].sort(\n                        key=lambda x: x.get(\"timestamp\", \"\"), reverse=True\n                    )\n                    self.examples_by_category[category] = self.examples_by_category[category][:self.max_examples_per_category]\n                \n                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n                if self._should_rotate_file():\n                    self._rotate_examples_file()\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä –≤ —Ñ–∞–π–ª\n                with open(self.examples_file, \"a\", encoding=\"utf-8\") as f:\n                    f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n                \n                logger.debug(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n                return True\n            \n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –æ–±—É—á–∞—é—â–µ–≥–æ –ø—Ä–∏–º–µ—Ä–∞: {str(e)}\")\n                return False\n    \n    def get_examples(self, category=None, limit=5):\n        \"\"\"\n        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–ª–∏ –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã\n        —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n        \n        Args:\n            category (str, optional): –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤\n            limit (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤\n            \n        Returns:\n            list: –°–ø–∏—Å–æ–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n        \"\"\"\n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –∫—ç—à (—É–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 30 –º–∏–Ω—É—Ç)\n        current_time = datetime.now()\n        cache_needs_update = (self.last_loaded is None or \n                            (current_time - self.last_loaded).total_seconds() > 1800)  # 30 –º–∏–Ω—É—Ç\n        \n        # –ë–ª–æ–∫–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞\n        if cache_needs_update:"
  },
  {
    "chunk_id": 12,
    "context_type": "business_logic",
    "size_tokens": 2728,
    "content": "            with self.lock:\n                # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏\n                if self.last_loaded is None or (current_time - self.last_loaded).total_seconds() > 1800:\n                    self._load_examples()\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ –∫—ç—à–µ - —ç—Ç–æ—Ç –±–ª–æ–∫ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏\n        if category and category in self.examples_by_category:\n            # –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            raw_examples = self.examples_by_category[category][-limit:]\n        elif category is None:\n            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞)\n            raw_examples = []\n            categories = list(self.examples_by_category.keys())\n            \n            if not categories:\n                return []\n                \n            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            examples_per_category = max(1, limit // len(categories))\n            \n            # –°—Ä–∞–∑—É —Å–æ–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤\n            for cat in categories:\n                if cat in self.examples_by_category and self.examples_by_category[cat]:\n                    # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n                    cat_examples = self.examples_by_category[cat][-examples_per_category:]\n                    raw_examples.extend(cat_examples)\n            \n            # –ï—Å–ª–∏ —Å–æ–±—Ä–∞–ª–∏ –º–µ–Ω—å—à–µ —á–µ–º –Ω—É–∂–Ω–æ, –¥–æ–ø–æ–ª–Ω—è–µ–º\n            if len(raw_examples) < limit:\n                # –°–æ–±–∏—Ä–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤\n                sorted_categories = sorted(\n                    categories, \n                    key=lambda c: len(self.examples_by_category.get(c, [])),\n                    reverse=True\n                )\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–∏–º–µ—Ä–æ–≤\n                for cat in sorted_categories:\n                    if len(raw_examples) >= limit:\n                        break\n                        \n                    # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—â—ë –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã\n                    used = set(id(ex) for ex in raw_examples if ex in self.examples_by_category.get(cat, []))\n                    available = [ex for ex in self.examples_by_category.get(cat, []) \n                                if id(ex) not in used]\n                    \n                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\n                    need_more = limit - len(raw_examples)\n                    raw_examples.extend(available[-need_more:] if need_more <= len(available) else available)\n            \n            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ –ª–∏–º–∏—Ç–∞\n            raw_examples = raw_examples[:limit]\n        else:\n            # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —É–∫–∞–∑–∞–Ω–∞, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫\n            return []\n        \n        # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ø–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ - –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Ü–∏–∫–ª–æ–≤\n        optimized_examples = []\n        for ex in raw_examples:\n            # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ - –∫–æ–ø–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è\n            optimized = {\n                'category': ex.get('category', ''),\n                'text': ex.get('text', '')[:200] + ('...' if len(ex.get('text', '')) > 200 else ''),\n                'justification': ex.get('justification', '')[:100] + ('...' if len(ex.get('justification', '')) > 100 else '')\n            }\n            \n            optimized_examples.append(optimized)\n        \n        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n        return optimized_examples\n    \n    def _should_rotate_file(self) -> bool:\n        \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª –ø—Ä–∏–º–µ—Ä–æ–≤\"\"\"\n        if not os.path.exists(self.examples_file):\n            return False\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–±–æ–ª–µ–µ 5 –ú–ë)\n        file_size = os.path.getsize(self.examples_file)\n        return file_size > 5 * 1024 * 1024\n    \n    def _rotate_examples_file(self) -> None:\n        \"\"\"–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é —Ñ–∞–π–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –∞—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—É—é\"\"\"\n        if not os.path.exists(self.examples_file):\n            return\n        \n        try:\n            # –°–æ–∑–¥–∞–µ–º –∏–º—è –∞—Ä—Ö–∏–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –¥–∞—Ç–æ–π\n            timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n            archive_path = os.path.join(self.examples_dir, f\"examples_{timestamp}.jsonl.bak\")\n            \n            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª –≤ –∞—Ä—Ö–∏–≤\n            os.rename(self.examples_file, archive_path)\n            \n            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫—ç—à –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª\n            with open(self.examples_file, \"w\", encoding=\"utf-8\") as f:\n                for category, examples in self.examples_by_category.items():\n                    for example in examples:\n                        f.write(json.dumps(example, ensure_ascii=False) + \"\\n\")\n            \n            logger.info(f\"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª –ø—Ä–∏–º–µ—Ä–æ–≤, —Å—Ç–∞—Ä—ã–π –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ {archive_path}\")\n        \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–æ—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤: {str(e)}\")\n\n    \n\n=== context_manager.py ===\n\"\"\"\n–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Å–∏—Å—Ç–µ–º—ã –∏ –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏ –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏\n\"\"\"\nimport logging\nimport json\nfrom datetime import datetime, timedelta\nfrom typing import Dict, Any, Optional, List\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\n\nlogger = logging.getLogger(__name__)\n\nclass ContextScope(Enum):\n    \"\"\"–û–±–ª–∞—Å—Ç—å –≤–∏–¥–∏–º–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\"\"\"\n    GLOBAL = \"global\"           # –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n    SESSION = \"session\"         # –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n    TASK = \"task\"              # –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–∏\n    AGENT = \"agent\"            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –∞–≥–µ–Ω—Ç–∞\n\n@dataclass\nclass ContextEntry:\n    \"\"\"–ó–∞–ø–∏—Å—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ\"\"\"\n    key: str\n    value: Any\n    scope: ContextScope\n    created_at: datetime\n    expires_at: Optional[datetime] = None\n    metadata: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        if self.metadata is None:\n            self.metadata = {}\n\nclass ContextManager:\n    \"\"\"\n    –ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∏ –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏\n    \"\"\"\n    \n    def __init__(self, db_manager):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\n        \n        Args:\n            db_manager: –ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n        \"\"\"\n        self.db_manager = db_manager\n        self.context_store = {}  # –í –ø–∞–º—è—Ç–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞\n        self.session_id = None\n        \n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n        self._initialize_global_context()\n        \n        logger.info(\"–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    def _initialize_global_context(self):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\"\"\"\n        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã\n        self.set_global(\"system_started_at\", datetime.now())\n        self.set_global(\"system_status\", \"running\")\n        \n        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n        from config.settings_cop2 import CATEGORIES, TELEGRAM_CHANNELS\n        self.set_global(\"categories\", CATEGORIES)\n        self.set_global(\"channels\", TELEGRAM_CHANNELS)\n        \n        # –ö—ç—à –¥–ª—è —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n        self.set_global(\"stats_cache\", {})\n    \n    def start_session(self, session_id: str = None) -> str:\n        \"\"\"\n        –ù–∞—á–∞–ª–æ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        \n        Args:\n            session_id: ID —Å–µ—Å—Å–∏–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)\n            \n        Returns:\n            ID —Å–µ—Å—Å–∏–∏\n        \"\"\"\n        if session_id is None:\n            session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        \n        self.session_id = session_id\n        self.set_session(\"started_at\", datetime.now())\n        self.set_session(\"status\", \"active\")\n        \n        logger.info(f\"–ù–∞—á–∞—Ç–∞ —Å–µ—Å—Å–∏—è: {session_id}\")\n        return session_id\n    \n    def end_session(self):\n        \"\"\"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏\"\"\"\n        if self.session_id:\n            self.set_session(\"ended_at\", datetime.now())\n            self.set_session(\"status\", \"completed\")\n            logger.info(f\"–ó–∞–≤–µ—Ä—à–µ–Ω–∞ —Å–µ—Å—Å–∏—è: {self.session_id}\")\n            \n            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏\n            self._cleanup_session_context()\n            self.session_id = None\n    \n    def set_global(self, key: str, value: Any, expires_in_hours: int = None):\n        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –≥–ª–æ–±–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ\"\"\"\n        expires_at = None\n        if expires_in_hours:\n            expires_at = datetime.now() + timedelta(hours=expires_in_hours)\n        \n        self._set_context(key, value, ContextScope.GLOBAL, expires_at)\n    \n    def set_session(self, key: str, value: Any, expires_in_hours: int = None):\n        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–µ—Å—Å–∏–∏\"\"\"\n        if not self.session_id:\n            logger.warning(\"–°–µ—Å—Å–∏—è –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—é –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\")\n            return self.set_global(key, value, expires_in_hours)\n        \n        expires_at = None\n        if expires_in_hours:\n            expires_at = datetime.now() + timedelta(hours=expires_in_hours)\n        \n        session_key = f\"session:{self.session_id}:{key}\"\n        self._set_context(session_key, value, ContextScope.SESSION, expires_at)\n    \n    def set_task(self, task_id: str, key: str, value: Any, expires_in_minutes: int = 60):\n        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∑–∞–¥–∞—á–∏\"\"\"\n        expires_at = datetime.now() + timedelta(minutes=expires_in_minutes)\n        task_key = f\"task:{task_id}:{key}\"\n        self._set_context(task_key, value, ContextScope.TASK, expires_at)\n    \n    def set_agent(self, agent_type: str, key: str, value: Any, expires_in_hours: int = 24):\n        \"\"\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∞–≥–µ–Ω—Ç–∞\"\"\"\n        expires_at = datetime.now() + timedelta(hours=expires_in_hours)\n        agent_key = f\"agent:{agent_type}:{key}\"\n        self._set_context(agent_key, value, ContextScope.AGENT, expires_at)\n    \n    def get_global(self, key: str, default: Any = None) -> Any:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\"\"\"\n        return self._get_context(key, default)\n    \n    def get_session(self, key: str, default: Any = None) -> Any:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–µ—Å—Å–∏–∏\"\"\"\n        if not self.session_id:\n            return default\n        \n        session_key = f\"session:{self.session_id}:{key}\"\n        return self._get_context(session_key, default)\n    \n    def get_task(self, task_id: str, key: str, default: Any = None) -> Any:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–¥–∞—á–∏\"\"\"\n        task_key = f\"task:{task_id}:{key}\"\n        return self._get_context(task_key, default)\n    \n    def get_agent(self, agent_type: str, key: str, default: Any = None) -> Any:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∞–≥–µ–Ω—Ç–∞\"\"\"\n        agent_key = f\"agent:{agent_type}:{key}\"\n        return self._get_context(agent_key, default)\n    \n    def _set_context(self, key: str, value: Any, scope: ContextScope, expires_at: datetime = None):\n        \"\"\"–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è\"\"\"\n        entry = ContextEntry(\n            key=key,\n            value=value,\n            scope=scope,\n            created_at=datetime.now(),\n            expires_at=expires_at"
  },
  {
    "chunk_id": 13,
    "context_type": "business_logic",
    "size_tokens": 1453,
    "content": "        )\n        \n        self.context_store[key] = entry\n        logger.debug(f\"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {key} (scope: {scope.value})\")\n    \n    def _get_context(self, key: str, default: Any = None) -> Any:\n        \"\"\"–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è\"\"\"\n        entry = self.context_store.get(key)\n        \n        if entry is None:\n            return default\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è\n        if entry.expires_at and datetime.now() > entry.expires_at:\n            del self.context_store[key]\n            logger.debug(f\"–ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —É—Å—Ç–∞—Ä–µ–ª–æ –∏ —É–¥–∞–ª–µ–Ω–æ: {key}\")\n            return default\n        \n        return entry.value\n    \n    def get_system_stats(self) -> Dict[str, Any]:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º\"\"\"\n        cache_key = \"system_stats\"\n        cached_stats = self.get_global(cache_key)\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (–æ–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑ –≤ 5 –º–∏–Ω—É—Ç)\n        cache_time = self.get_global(f\"{cache_key}_time\")\n        if cached_stats and cache_time:\n            if (datetime.now() - cache_time).total_seconds() < 300:  # 5 –º–∏–Ω—É—Ç\n                return cached_stats\n        \n        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n        try:\n            stats = {\n                \"unanalyzed_messages\": len(self.db_manager.get_unanalyzed_messages(limit=1000)),\n                \"low_confidence_messages\": len(self.db_manager.get_messages_with_low_confidence(limit=100)),\n                \"latest_digest\": None,\n                \"today_digests_count\": 0\n            }\n            \n            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ\n            latest_digest = self.db_manager.get_latest_digest()\n            if latest_digest:\n                stats[\"latest_digest\"] = {\n                    \"date\": latest_digest.date.strftime(\"%Y-%m-%d\"),\n                    \"type\": latest_digest.digest_type\n                }\n            \n            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n            today_digests = self.db_manager.find_digests_by_parameters(is_today=True, limit=10)\n            stats[\"today_digests_count\"] = len(today_digests)\n            \n            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n            self.set_global(cache_key, stats, expires_in_hours=1)\n            self.set_global(f\"{cache_key}_time\", datetime.now())\n            \n            return stats\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã: {str(e)}\")\n            return {}\n    \n    def update_agent_status(self, agent_type: str, status: str, metadata: Dict[str, Any] = None):\n        \"\"\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞–≥–µ–Ω—Ç–∞\"\"\"\n        status_data = {\n            \"status\": status,\n            \"updated_at\": datetime.now(),\n            \"metadata\": metadata or {}\n        }\n        \n        self.set_agent(agent_type, \"status\", status_data)\n        logger.debug(f\"–û–±–Ω–æ–≤–ª–µ–Ω —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–∞ {agent_type}: {status}\")\n    \n    def get_agent_status(self, agent_type: str) -> Dict[str, Any]:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∞–≥–µ–Ω—Ç–∞\"\"\"\n        return self.get_agent(agent_type, \"status\", {\n            \"status\": \"unknown\",\n            \"updated_at\": None,\n            \"metadata\": {}\n        })\n    \n    def record_task_metrics(self, task_id: str, metrics: Dict[str, Any]):\n        \"\"\"–ó–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏\"\"\"\n        self.set_task(task_id, \"metrics\", metrics, expires_in_minutes=120)\n        \n        # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n        self._update_aggregated_metrics(metrics)\n    \n    def _update_aggregated_metrics(self, metrics: Dict[str, Any]):\n        \"\"\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫\"\"\"\n        current_metrics = self.get_global(\"aggregated_metrics\", {})\n        \n        # –ü—Ä–æ—Å—Ç–æ–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ - –ø–æ–¥—Å—á–µ—Ç –∑–∞–¥–∞—á –∏ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        current_metrics[\"total_tasks\"] = current_metrics.get(\"total_tasks\", 0) + 1\n        current_metrics[\"total_execution_time\"] = current_metrics.get(\"total_execution_time\", 0) + metrics.get(\"execution_time\", 0)\n        \n        if metrics.get(\"status\") == \"success\":\n            current_metrics[\"successful_tasks\"] = current_metrics.get(\"successful_tasks\", 0) + 1\n        \n        self.set_global(\"aggregated_metrics\", current_metrics, expires_in_hours=24)\n    \n    def _cleanup_session_context(self):\n        \"\"\"–û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–µ—Å—Å–∏–∏\"\"\"\n        if not self.session_id:\n            return\n        \n        session_prefix = f\"session:{self.session_id}:\"\n        keys_to_remove = [key for key in self.context_store.keys() if key.startswith(session_prefix)]\n        \n        for key in keys_to_remove:\n            del self.context_store[key]\n        \n        logger.debug(f\"–û—á–∏—â–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–µ—Å—Å–∏–∏ {self.session_id}: {len(keys_to_remove)} –∑–∞–ø–∏—Å–µ–π\")\n    \n    def cleanup_expired(self):\n        \"\"\"–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π\"\"\"\n        now = datetime.now()\n        expired_keys = []\n        \n        for key, entry in self.context_store.items():\n            if entry.expires_at and now > entry.expires_at:\n                expired_keys.append(key)\n        \n        for key in expired_keys:\n            del self.context_store[key]\n        \n        if expired_keys:\n            logger.debug(f\"–û—á–∏—â–µ–Ω–æ {len(expired_keys)} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\")\n    \n    def get_context_summary(self) -> Dict[str, Any]:\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É\"\"\"\n        summary = {\n            \"total_entries\": len(self.context_store),\n            \"by_scope\": {},\n            \"session_id\": self.session_id,\n            \"global_keys\": []\n        }\n        \n        for entry in self.context_store.values():\n            scope = entry.scope.value\n            summary[\"by_scope\"][scope] = summary[\"by_scope\"].get(scope, 0) + 1\n            \n            if entry.scope == ContextScope.GLOBAL and not entry.key.startswith((\"session:\", \"task:\", \"agent:\")):\n                summary[\"global_keys\"].append(entry.key)\n        \n        return summary"
  },
  {
    "chunk_id": 14,
    "context_type": "business_logic",
    "size_tokens": 1496,
    "content": "=== analyzer.py ===\n\"\"\"\n–ê–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π\n\"\"\"\nimport logging\nimport json\nimport os\nfrom langchain.tools import Tool\nfrom crewai import Agent, Task\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom config.settings_cop2 import CATEGORIES\nimport datetime\nfrom datetime import datetime as dt\nimport time\nfrom utils.learning_manager import LearningExamplesManager\nlogger = logging.getLogger(__name__)\n\n\nclass AnalyzerAgent:\n    def __init__(self, db_manager, llm_model=None):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\"\"\"\n        self.db_manager = db_manager\n        \n        # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤\n        from llm.qwen_model import QwenLLM\n        self.llm_model = llm_model or QwenLLM()\n        \n        # –§–ª–∞–≥ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫—Ä–∏—Ç–∏–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n        self.fast_check = False\n        \n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n        self.learning_manager = LearningExamplesManager()\n        \n        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\n        analyze_tool = Tool(\n            name=\"analyze_messages\",\n            func=self.analyze_messages,\n            description=\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ Telegram-–∫–∞–Ω–∞–ª–æ–≤\"\n        )\n        \n        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ CrewAI\n        self.agent = Agent(\n            name=\"Analyzer\",\n            role=\"–ê–Ω–∞–ª–∏—Ç–∏–∫\",\n            goal=\"–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\",\n            backstory=\"–Ø –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª—è—é –∏—Ö —Ç–µ–º–∞—Ç–∏–∫—É –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞.\",\n            verbose=True,\n            tools=[analyze_tool]\n        )\n    \n    \n    # –í agents/analyzer.py - —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ _classify_message\n# –ó–∞–º–µ–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –Ω–∞ —ç—Ç–æ—Ç\n\n    def _classify_message(self, message_text):\n        \"\"\"\n        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–º reasoning –∏ –æ—Ü–µ–Ω–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n        \n        Args:\n            message_text (str): –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\n            \n        Returns:\n            tuple: (–∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è, —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ 1-5)\n        \"\"\"\n        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —á–µ—Ä–µ–∑ LearningExamplesManager\n        examples = self.learning_manager.get_examples(limit=3)\n        examples_text = \"\"\n        if examples:\n            examples_text = \"–ü–†–ò–ú–ï–†–´ –ü–†–ê–í–ò–õ–¨–ù–û–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:\\n\\n\"\n            for i, ex in enumerate(examples, 1):\n                short_text = ex['text'][:120] + \"...\" if len(ex['text']) > 120 else ex['text']\n                examples_text += f\"–ü—Ä–∏–º–µ—Ä {i}:\\n\"\n                examples_text += f\"–¢–µ–∫—Å—Ç: {short_text}\\n\"\n                examples_text += f\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {ex['category']}\\n\"\n                examples_text += f\"–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {ex['justification']}\\n\\n\"\n\n        # –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ —Å –±–æ–ª–µ–µ —á–µ—Ç–∫–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º\n        enhanced_prompt = f\"\"\"\n    –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–∞–≤–æ–≤–æ–º—É –∞–Ω–∞–ª–∏–∑—É. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é.\n\n    {examples_text if examples else \"\"}\n\n    –°–û–û–ë–©–ï–ù–ò–ï:\n    {message_text}\n\n    –î–û–°–¢–£–ü–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò:\n    1. –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã - –ø—Ä–æ–µ–∫—Ç—ã, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –≤ –ì–æ—Å–¥—É–º–µ\n    2. –Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã - –ø—Ä–∏–Ω—è—Ç—ã–µ –∏ –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω—ã, –≤—Å—Ç—É–ø–∞—é—â–∏–µ –≤ —Å–∏–ª—É\n    3. –ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º - –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–∫–æ–Ω—ã\n    4. –Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ - —Ä–µ—à–µ–Ω–∏—è, –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É–¥–æ–≤\n    5. –¥—Ä—É–≥–æ–µ - –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–æ–≤—ã–º –≤–æ–ø—Ä–æ—Å–∞–º\n\n    –ê–ù–ê–õ–ò–ó:\n    –ù–∞–π–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —Å—Ç–∞–¥–∏—é –ø—Ä–æ—Ü–µ—Å—Å–∞.\n\n    –ï—Å–ª–∏ –≤–∏–¥–∏—à—å \"–ø—Ä–∏–Ω—è—Ç\", \"–ø–æ–¥–ø–∏—Å–∞–Ω\", \"–≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É\" + –Ω–æ–º–µ—Ä –∑–∞–∫–æ–Ω–∞ = \"–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã\"\n    –ï—Å–ª–∏ –≤–∏–¥–∏—à—å \"–ø—Ä–æ–µ–∫—Ç\", \"—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ\", \"–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\", \"–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞\" = \"–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã\"  \n    –ï—Å–ª–∏ –≤–∏–¥–∏—à—å \"–∏–∑–º–µ–Ω–µ–Ω–∏—è\", \"–ø–æ–ø—Ä–∞–≤–∫–∏\", \"–≤–Ω–µ—Å–µ–Ω—ã –≤\" + –Ω–∞–∑–≤–∞–Ω–∏–µ –∑–∞–∫–æ–Ω–∞ = \"–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º\"\n    –ï—Å–ª–∏ –≤–∏–¥–∏—à—å \"—Å—É–¥\", \"—Ä–µ—à–µ–Ω–∏–µ\", \"–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ\", \"–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\" = \"–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞\"\n    –ò–Ω–∞—á–µ = \"–¥—Ä—É–≥–æ–µ\"\n\n    –°–¢–†–û–ì–û –æ—Ç–≤–µ—á–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n    –ö–∞—Ç–µ–≥–æ—Ä–∏—è: [–æ–¥–Ω–∞ –∏–∑ 5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ—á–Ω–æ –∫–∞–∫ –Ω–∞–ø–∏—Å–∞–Ω–æ –≤—ã—à–µ]\n    –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [—á–∏—Å–ª–æ 1-5]\"\"\"\n\n        try:\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ classify —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º\n            response = self.llm_model.classify(enhanced_prompt, CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"])\n            \n            # –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–ê–†–°–ò–ù–ì –æ—Ç–≤–µ—Ç–∞\n            category = None\n            confidence = 3\n            \n            # –†–∞–∑–±–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –∏—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n            lines = response.strip().split('\\n')\n            response_text = response.lower()\n            \n            # –ò—â–µ–º —Å—Ç—Ä–æ–∫—É —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π\n            for line in lines:\n                line_clean = line.strip()\n                if line_clean.lower().startswith(\"–∫–∞—Ç–µ–≥–æ—Ä–∏—è\"):\n                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è\n                    if \":\" in line_clean:\n                        category_part = line_clean.split(\":\", 1)[1].strip().lower()\n                        \n                        # –¢–æ—á–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏\n                        for cat in CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"]:\n                            if cat.lower() == category_part or cat.lower() in category_part:\n                                category = cat\n                                break\n                    break\n            \n            # –ò—â–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å\n            for line in lines:\n                line_clean = line.strip()\n                if line_clean.lower().startswith(\"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å\"):\n                    if \":\" in line_clean:\n                        conf_part = line_clean.split(\":\", 1)[1].strip()\n                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ\n                        import re\n                        numbers = re.findall(r'\\d+', conf_part)\n                        if numbers:\n                            confidence = int(numbers[0])\n                            confidence = max(1, min(5, confidence))\n                    break\n            \n            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ –æ—Ç–≤–µ—Ç–∞\n            if not category:\n                for cat in CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"]:\n                    if cat.lower() in response_text:\n                        category = cat\n                        break\n            "
  },
  {
    "chunk_id": 15,
    "context_type": "business_logic",
    "size_tokens": 1486,
    "content": "            logger.debug(f\"–ü–∞—Ä—Å–∏–Ω–≥: –Ω–∞–π–¥–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è='{category}', —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={confidence}\")\n            \n            # –õ–æ–≥–∏—Ä—É–µ–º enhanced —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n            if category:\n                self._log_classification_reasoning(message_text, category, confidence, response)\n                logger.info(f\"Enhanced –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞: {category} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})\")\n                return category, confidence\n            \n            # Fallback: –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å enhanced –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑\n            logger.warning(\"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å enhanced –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback\")\n            \n            # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –æ—Ç–≤–µ—Ç–µ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞)\n            response_lower = response.lower()\n            for cat in CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"]:\n                if cat.lower() in response_lower:\n                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å\n                    confidence = 3 if cat != \"–¥—Ä—É–≥–æ–µ\" else 2\n                    \n                    # –ü–æ–≤—ã—à–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã\n                    if any(marker in response_lower for marker in [\n                        \"–∑–∞–∫–æ–Ω –ø—Ä–∏–Ω—è—Ç\", \"–ø–æ–¥–ø–∏—Å–∞–Ω\", \"–≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É\", \n                        \"—Ä–µ—à–µ–Ω–∏–µ —Å—É–¥–∞\", \"–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ\", \"–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞\"\n                    ]):\n                        confidence = min(5, confidence + 1)\n                    \n                    return cat, confidence\n            \n            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n            return \"–¥—Ä—É–≥–æ–µ\", 1\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ enhanced –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}\")\n            # Fallback –Ω–∞ —Å–∞–º—É—é –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É\n            if any(word in message_text.lower() for word in [\"–∑–∞–∫–æ–Ω\", \"–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ\", \"—Ä–µ—à–µ–Ω–∏–µ\"]):\n                return \"–¥—Ä—É–≥–æ–µ\", 2\n            return \"–¥—Ä—É–≥–æ–µ\", 1\n\n\n    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π helper –º–µ—Ç–æ–¥ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤\n    def _format_examples_for_reasoning(self, examples):\n        \"\"\"–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è reasoning –ø—Ä–æ–º–ø—Ç–∞\"\"\"\n        if not examples:\n            return \"\"\n        \n        formatted = \"–ü–†–ò–ú–ï–†–´ –£–°–ü–ï–®–ù–û–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:\\n\\n\"\n        for i, ex in enumerate(examples, 1):\n            # –°–æ–∫—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤\n            short_text = ex['text'][:100] + \"...\" if len(ex['text']) > 100 else ex['text']\n            formatted += f\"–ü—Ä–∏–º–µ—Ä {i}:\\n\"\n            formatted += f\"–¢–µ–∫—Å—Ç: {short_text}\\n\"\n            formatted += f\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {ex['category']}\\n\"\n            formatted += f\"–ü–æ—á–µ–º—É: {ex['justification'][:80]}{'...' if len(ex['justification']) > 80 else ''}\\n\\n\"\n        \n        return formatted\n\n    def _log_classification_reasoning(self, message_text, category, confidence, response):\n        \"\"\"–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ reasoning –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞\"\"\"\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º reasoning –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM\n        reasoning_parts = {\n            \"–∫–ª—é—á–µ–≤—ã–µ_–ø—Ä–∏–∑–Ω–∞–∫–∏\": \"\",\n            \"–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ\": \"\",\n            \"—Å—Ç–∞–¥–∏—è_–ø—Ä–æ—Ü–µ—Å—Å–∞\": \"\",\n            \"raw_response\": response[:200] + \"...\" if len(response) > 200 else response\n        }\n        \n        lines = response.strip().split('\\n')\n        for line in lines:\n            line_clean = line.strip()\n            if line_clean.lower().startswith(\"–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:\"):\n                reasoning_parts[\"–∫–ª—é—á–µ–≤—ã–µ_–ø—Ä–∏–∑–Ω–∞–∫–∏\"] = line_clean.split(\":\", 1)[1].strip()\n            elif line_clean.lower().startswith(\"–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:\"):\n                reasoning_parts[\"–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ\"] = line_clean.split(\":\", 1)[1].strip()\n            elif \"—Å—Ç–∞–¥–∏—è\" in line_clean.lower() and \"–ø—Ä–æ—Ü–µ—Å—Å\" in line_clean.lower():\n                reasoning_parts[\"—Å—Ç–∞–¥–∏—è_–ø—Ä–æ—Ü–µ—Å—Å–∞\"] = line_clean.split(\":\", 1)[1].strip()\n        \n        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Å–∏–≤—ã–π reasoning –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª\n        logger.info(\"üß† REASONING –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê:\")\n        logger.info(f\"   üìù –¢–µ–∫—Å—Ç: {message_text[:80]}{'...' if len(message_text) > 80 else ''}\")\n        logger.info(f\"   üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {category} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence})\")\n        \n        if reasoning_parts[\"–∫–ª—é—á–µ–≤—ã–µ_–ø—Ä–∏–∑–Ω–∞–∫–∏\"]:\n            logger.info(f\"   üîç –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {reasoning_parts['–∫–ª—é—á–µ–≤—ã–µ_–ø—Ä–∏–∑–Ω–∞–∫–∏']}\")\n        if reasoning_parts[\"–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ\"]:\n            logger.info(f\"   üí≠ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {reasoning_parts['–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ']}\")\n        if reasoning_parts[\"—Å—Ç–∞–¥–∏—è_–ø—Ä–æ—Ü–µ—Å—Å–∞\"]:\n            logger.info(f\"   ‚öñÔ∏è –°—Ç–∞–¥–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞: {reasoning_parts['—Å—Ç–∞–¥–∏—è_–ø—Ä–æ—Ü–µ—Å—Å–∞']}\")\n        \n        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç LLM –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤)\n        logger.debug(f\"   ü§ñ –û—Ç–≤–µ—Ç LLM: {reasoning_parts['raw_response']}\")\n        \n        logger.info(\"   \" + \"‚îÄ\" * 60)\n        \n    def analyze_messages(self, limit=1500, batch_size=20):\n        \"\"\"\n        –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ—Ü–µ–Ω–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n        \"\"\"\n        logger.info(f\"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–π, –ª–∏–º–∏—Ç: {limit}, —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {batch_size}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n        messages = self.db_manager.get_unanalyzed_messages(limit=limit)\n        \n        if not messages:\n            logger.info(\"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")\n            return {\n                \"status\": \"success\",\n                \"analyzed_count\": 0,\n                \"categories\": {}\n            }\n        \n        categories_count = {category: 0 for category in CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"]}\n        confidence_stats = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏\n        analyzed_count = 0\n        \n        # –†–∞–∑–±–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ –ø–∞–∫–µ—Ç—ã –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n        batches = [messages[i:i+batch_size] for i in range(0, len(messages), batch_size)]\n        logger.info(f\"–†–∞–∑–¥–µ–ª–µ–Ω–æ –Ω–∞ {len(batches)} –ø–∞–∫–µ—Ç–æ–≤ –ø–æ ~{batch_size} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n        \n        # –°–æ–∑–¥–∞–µ–º –ø—É–ª –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–∂–¥–æ–≥–æ –ø–∞–∫–µ—Ç–∞\n        with ThreadPoolExecutor(max_workers=min(6, len(batches))) as executor:\n            future_to_batch = {}\n            \n            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞\n            def process_batch(batch_idx, batch):\n                batch_start_time = time.time()"
  },
  {
    "chunk_id": 16,
    "context_type": "business_logic",
    "size_tokens": 1498,
    "content": "                logger.info(f\"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–∫–µ—Ç–∞ {batch_idx+1}/{len(batches)}\")\n                \n                batch_results = []\n                for msg_idx, msg in enumerate(batch):\n                    if not msg.text:\n                        continue\n                    \n                    try:\n                        msg_start_time = time.time()\n                        # –°–æ–∫—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π\n                        msg_text = msg.text\n                        if len(msg_text) > 2000:\n                            msg_text = msg_text[:2000] + \"... [—Å–æ–∫—Ä–∞—â–µ–Ω–æ]\"\n                            logger.debug(f\"–°–æ–æ–±—â–µ–Ω–∏–µ {msg.id} —Å–æ–∫—Ä–∞—â–µ–Ω–æ —Å {len(msg.text)} –¥–æ 2000 —Å–∏–º–≤–æ–ª–æ–≤\")\n                        \n                        # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ\n                        category, confidence = self._classify_message(msg_text)\n                        \n                        msg_elapsed = time.time() - msg_start_time\n                        logger.debug(f\"–°–æ–æ–±—â–µ–Ω–∏–µ {msg_idx+1}/{len(batch)} –≤ –ø–∞–∫–µ—Ç–µ {batch_idx+1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {msg_elapsed:.2f}—Å: {category} ({confidence})\")\n                        \n                        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n                        result = {\n                            \"message_id\": msg.id,\n                            \"category\": category,\n                            \"confidence\": confidence,\n                            \"success\": True,\n                            \"processing_time\": msg_elapsed\n                        }\n                        \n                        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –Ω—É–∂–µ–Ω –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n                        if self.fast_check and (category == \"–¥—Ä—É–≥–æ–µ\" or confidence <= 2):\n                            try:\n                                critic_start = time.time()\n                                from agents.critic import CriticAgent\n                                critic = CriticAgent(self.db_manager)\n                                critic_result = critic.review_categorization(msg.id, category)\n                                \n                                critic_elapsed = time.time() - critic_start\n                                logger.debug(f\"–ö—Ä–∏—Ç–∏–∫ –ø—Ä–æ–≤–µ—Ä–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞ {critic_elapsed:.2f}—Å\")\n                                \n                                # –ï—Å–ª–∏ –∫—Ä–∏—Ç–∏–∫ –∏–∑–º–µ–Ω–∏–ª –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n                                if critic_result[\"status\"] == \"updated\":\n                                    result[\"category\"] = critic_result[\"new_category\"]\n                                    result[\"confidence\"] = critic_result[\"confidence\"]\n                                    result[\"reviewed_by_critic\"] = True\n                                    result[\"critic_time\"] = critic_elapsed\n                            except Exception as e:\n                                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {msg.id}: {str(e)}\")\n                    except Exception as e:\n                        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {msg.id}: {str(e)}\")\n                        result = {\n                            \"message_id\": msg.id,\n                            \"error\": str(e),\n                            \"success\": False\n                        }\n                    \n                    batch_results.append(result)\n                \n                batch_elapsed = time.time() - batch_start_time\n                logger.info(f\"–ó–∞–≤–µ—Ä—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_idx+1}/{len(batches)} –∑–∞ {batch_elapsed:.2f}—Å\")\n                return batch_results\n            \n            # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–∞–∫–µ—Ç–æ–≤\n            for i, batch in enumerate(batches):\n                future = executor.submit(process_batch, i, batch)\n                future_to_batch[future] = i\n            \n            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n            all_results = []\n            for future in as_completed(future_to_batch):\n                batch_idx = future_to_batch[future]\n                try:\n                    batch_results = future.result()\n                    all_results.extend(batch_results)\n                    \n                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–æ–º—É –ø–∞–∫–µ—Ç—É\n                    batch_success = sum(1 for r in batch_results if r[\"success\"])\n                    batch_times = [r.get(\"processing_time\", 0) for r in batch_results if \"processing_time\" in r]\n                    avg_time = sum(batch_times) / len(batch_times) if batch_times else 0\n                    \n                    logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω –ø–∞–∫–µ—Ç {batch_idx+1}/{len(batches)}: {batch_success} —É—Å–ø–µ—à–Ω–æ, —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {avg_time:.2f}—Å\")\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∞–∫–µ—Ç–∞ {batch_idx+1}: {str(e)}\")\n        \n        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ë–î\n        successful_updates = []\n        for result in all_results:\n            if result[\"success\"]:\n                # update_message_category returns True/False\n                success = self.db_manager.update_message_category( \n                    result[\"message_id\"],\n                    result[\"category\"],\n                    result[\"confidence\"])\n                \n                if success:\n                    categories_count[result[\"category\"]] += 1\n                    confidence_stats[result[\"confidence\"]] += 1\n                    analyzed_count += 1\n                    successful_updates.append(result)\n        \n        logger.info(f\"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ {analyzed_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n        logger.info(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {categories_count}\")\n        logger.info(f\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {confidence_stats}\")\n        \n        return {\n            \"status\": \"success\",\n            \"analyzed_count\": analyzed_count,\n            \"categories\": categories_count,\n            \"confidence_stats\": confidence_stats,\n            \"all_results\": all_results\n        }\n    def create_task(self):\n        \"\"\""
  },
  {
    "chunk_id": 17,
    "context_type": "business_logic",
    "size_tokens": 1578,
    "content": "        –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n        \n        Returns:\n            Task: –ó–∞–¥–∞—á–∞ CrewAI\n        \"\"\"\n        return Task(\n            description=\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\",\n            agent=self.agent,\n            expected_output=\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö\"\n        )\n\n\n=== improved_view_digest.py ===\n\"\"\"\n–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∫–Ω–æ–ø–æ–∫\n\"\"\"\nimport hashlib\nimport logging\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import ContextTypes\n\nlogger = logging.getLogger(__name__)\n\ndef get_short_category_id(category):\n    \"\"\"\n    –°–æ–∑–¥–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n    \n    Args:\n        category (str): –ü–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \n    Returns:\n        str: –ö–æ—Ä–æ—Ç–∫–∏–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID (–¥–æ 8 —Å–∏–º–≤–æ–ª–æ–≤)\n    \"\"\"\n    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ö–µ—à –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ ID\n    hash_object = hashlib.md5(category.encode())\n    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 6 —Å–∏–º–≤–æ–ª–æ–≤ —Ö–µ—à–∞, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª –∫–æ—Ä–æ—Ç–∫–∏–º\n    return hash_object.hexdigest()[:6]\n\nasync def view_digest_callback(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):\n    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫\"\"\"\n    query = update.callback_query\n    await query.answer()\n    \n    try:\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–∑ callback_data\n        digest_id = int(query.data.replace(\"view_digest_\", \"\"))\n        \n        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å —Å–µ–∫—Ü–∏—è–º–∏ –ø–æ ID\n        digest = db_manager.get_digest_by_id_with_sections(digest_id)\n        \n        if not digest:\n            await query.message.reply_text(\"‚ùå –î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±—ã–ª —É–¥–∞–ª–µ–Ω.\")\n            return\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–≤–æ–¥–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        digest_type = \"–∫—Ä–∞—Ç–∫–∏–π\" if digest[\"digest_type\"] == \"brief\" else \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\"\n        date_str = digest[\"date\"].strftime(\"%d.%m.%Y\")\n        \n        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ\n        if digest.get(\"date_range_start\") and digest.get(\"date_range_end\"):\n            if digest[\"date_range_start\"].date() != digest[\"date_range_end\"].date():\n                date_str = f\"{digest['date_range_start'].strftime('%d.%m.%Y')} - {digest['date_range_end'].strftime('%d.%m.%Y')}\"\n        \n        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n        categories_stats = {}\n        for section in digest[\"sections\"]:\n            categories_stats[section[\"category\"]] = len(section[\"text\"].split(\"\\n\\n\"))\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è\n        table_of_contents = f\"üìä {digest_type.capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ {date_str}\\n\\n\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–æ–∫—É—Å–µ, –µ—Å–ª–∏ –µ—Å—Ç—å\n        if digest.get(\"focus_category\"):\n            table_of_contents += f\"üîç –§–æ–∫—É—Å: {digest['focus_category']}\\n\\n\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n        table_of_contents += \"üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\\n\"\n        for category, count in categories_stats.items():\n            icon = get_category_icon(category)\n            table_of_contents += f\"{icon} {category.capitalize()}: –ø—Ä–∏–º–µ—Ä–Ω–æ {count} —Å–æ–æ–±—â–µ–Ω–∏–π\\n\"\n        \n        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ ID\n        keyboard = []\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ ID –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        if not context.user_data.get(\"category_mapping\"):\n            context.user_data[\"category_mapping\"] = {}\n        \n        # –î–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É —Å –∫–æ—Ä–æ—Ç–∫–∏–º ID\n        for section in digest[\"sections\"]:\n            category = section[\"category\"]\n            icon = get_category_icon(category)\n            \n            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π ID –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            short_id = get_short_category_id(category)\n            \n            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ ID -> –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n            mapping_key = f\"{digest_id}_{short_id}\"\n            context.user_data[\"category_mapping\"][mapping_key] = category\n            \n            # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫—É —Å –∫–æ—Ä–æ—Ç–∫–∏–º callback_data\n            keyboard.append([\n                InlineKeyboardButton(\n                    f\"{icon} {category.capitalize()}\", \n                    callback_data=f\"ds_{digest_id}_{short_id}\"\n                )\n            ])\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ–ª–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        keyboard.append([\n            InlineKeyboardButton(\"üìÑ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞\", callback_data=f\"df_{digest_id}\")\n        ])\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ —Å–ø–∏—Å–∫—É –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        keyboard.append([\n            InlineKeyboardButton(\"‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ —Å–ø–∏—Å–∫—É\", callback_data=\"sl\")\n        ])\n        \n        reply_markup = InlineKeyboardMarkup(keyboard)\n        \n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        await query.message.edit_text(\n            table_of_contents,\n            reply_markup=reply_markup\n        )\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\", exc_info=True)\n        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n        await query.message.reply_text(\n            f\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\\n\"\n            \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É /list –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.\"\n        )\n\nasync def view_digest_section_callback(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):\n    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–µ–∫—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ ID\"\"\"\n    query = update.callback_query\n    await query.answer()\n        \n    try:\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ callback_data\n        # –§–æ—Ä–º–∞—Ç: ds_DIGEST_ID_SHORT_CATEGORY_ID\n        parts = query.data.split(\"_\", 2)\n        if len(parts) < 3:\n            await query.message.reply_text(\"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç callback_data\")\n            return\n        \n        digest_id = int(parts[1])\n        short_category_id = parts[2]\n        logger.info(f\"digest_id: {digest_id}, short_category_id: {short_category_id}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞\n        mapping_key = f\"{digest_id}_{short_category_id}\"\n        \n        logger.info(f\"–ò—â–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –∫–ª—é—á–∞: '{mapping_key}'\")\n        if context.user_data.get(\"category_mapping\"):\n            logger.info(f\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏ –≤ category_mapping: {list(context.user_data['category_mapping'].keys())}\")\n        else:\n            logger.error(\"category_mapping –≤–æ–æ–±—â–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!\")\n"
  },
  {
    "chunk_id": 18,
    "context_type": "business_logic",
    "size_tokens": 1489,
    "content": "        if not context.user_data.get(\"category_mapping\") or mapping_key not in context.user_data[\"category_mapping\"]:\n            await query.message.reply_text(\n                \"‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–Ω–æ–≤–æ.\"\n            )\n            return\n        \n        category = context.user_data[\"category_mapping\"][mapping_key]\n        \n        if mapping_key not in context.user_data[\"category_mapping\"]:\n            logger.error(f\"–ö–ª—é—á '{mapping_key}' –ù–ï –ù–ê–ô–î–ï–ù –≤ category_mapping!\")\n            logger.error(f\"–í–æ–∑–º–æ–∂–Ω–æ, show_digest_categories –±—ã–ª–∞ –≤—ã–∑–≤–∞–Ω–∞ –±–µ–∑ context\")\n        else:\n            logger.info(f\"–ö–ª—é—á '{mapping_key}' –Ω–∞–π–¥–µ–Ω, –∫–∞—Ç–µ–≥–æ—Ä–∏—è: '{context.user_data['category_mapping'][mapping_key]}'\")\n        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å —Å–µ–∫—Ü–∏—è–º–∏\n        digest = db_manager.get_digest_by_id_with_sections(digest_id)\n        \n        if not digest:\n            await query.message.reply_text(\"‚ùå –î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±—ã–ª —É–¥–∞–ª–µ–Ω.\")\n            return\n        \n        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        section = None\n        for s in digest[\"sections\"]:\n            if s[\"category\"] == category:\n                section = s\n                break\n        \n        if not section:\n            await query.message.reply_text(f\"‚ùå –°–µ–∫—Ü–∏—è '{category}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ.\")\n            return\n        \n        # –†–∞–∑–¥–µ–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–µ–∫—Ü–∏–∏ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n        section_parts = []\n        current_part = \"\"\n        for paragraph in section[\"text\"].split(\"\\n\\n\"):\n            if len(current_part) + len(paragraph) + 2 <= 3500:  # –õ–∏–º–∏—Ç Telegram –Ω–∞ –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è\n                if current_part:\n                    current_part += \"\\n\\n\" + paragraph\n                else:\n                    current_part = paragraph\n            else:\n                section_parts.append(current_part)\n                current_part = paragraph\n        \n        if current_part:\n            section_parts.append(current_part)\n        \n        # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π, —Ä–µ–∞–ª–∏–∑—É–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é\n        if len(section_parts) > 1:\n            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ context_data –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏ —Å–µ–∫—Ü–∏–∏\n            pagination_key = f\"digest_{digest_id}_{short_category_id}\"\n            if not context.user_data.get(\"pagination\"):\n                context.user_data[\"pagination\"] = {}\n            \n            context.user_data[\"pagination\"][pagination_key] = {\n                \"current_page\": 0,\n                \"total_pages\": len(section_parts),\n                \"parts\": section_parts,\n                \"category\": category  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            }\n            \n            # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n            digest_type = \"–∫—Ä–∞—Ç–∫–∏–π\" if digest[\"digest_type\"] == \"brief\" else \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\"\n            date_str = digest[\"date\"].strftime(\"%d.%m.%Y\")\n            \n            header = f\"üìä {digest_type.capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ {date_str}\\n\"\n            header += f\"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category.capitalize()}\\n\"\n            header += f\"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ 1/{len(section_parts)}\\n\\n\"\n            \n            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram\n            from utils.text_utils import TextUtils\n            content = TextUtils.convert_to_html(header + section_parts[0])\n            \n            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏\n            keyboard = []\n            \n            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –¥–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É\n            if len(section_parts) > 1:\n                keyboard.append([\n                    InlineKeyboardButton(\n                        \"–°–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ‚û°Ô∏è\", \n                        callback_data=f\"pg_{digest_id}_{short_category_id}_n\"\n                    )\n                ])\n            \n            # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            keyboard.append([\n                InlineKeyboardButton(\n                    \"üîô –ö –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é\", \n                    callback_data=f\"view_digest_{digest_id}\"\n                )\n            ])\n            \n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å –∫–Ω–æ–ø–∫–∞–º–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n            await query.message.edit_text(\n                content,\n                reply_markup=reply_markup,\n                parse_mode='HTML'\n            )\n        else:\n            # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ —á–∞—Å—Ç—å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –µ–µ –±–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n            digest_type = \"–∫—Ä–∞—Ç–∫–∏–π\" if digest[\"digest_type\"] == \"brief\" else \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\" # Re-evaluate type for clarity\n            date_str = digest[\"date\"].strftime(\"%d.%m.%Y\")\n            \n            header = f\"üìä {digest_type.capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ {date_str}\\n\"\n            header += f\"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category.capitalize()}\\n\\n\"\n            \n            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram\n            from utils.text_utils import TextUtils\n            content = TextUtils.convert_to_html(header + section[\"text\"])\n            \n            # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–æ–π –≤–æ–∑–≤—Ä–∞—Ç–∞\n            keyboard = [[\n                InlineKeyboardButton(\n                    \"üîô –ö –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é\", \n                    callback_data=f\"view_digest_{digest_id}\"\n                )\n            ]]\n            \n            reply_markup = InlineKeyboardMarkup(keyboard)\n            \n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é\n            await query.message.edit_text(\n                content,\n                reply_markup=reply_markup,\n                parse_mode='HTML'\n            )\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ —Å–µ–∫—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\", exc_info=True)\n        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n        await query.message.reply_text(\n            f\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–µ–∫—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\\n\"\n            \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É /list –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.\"\n        )\n\nasync def page_navigation_callback(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):"
  },
  {
    "chunk_id": 19,
    "context_type": "business_logic",
    "size_tokens": 1487,
    "content": "    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–∞ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ —Å–µ–∫—Ü–∏–π –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ ID\"\"\"\n    query = update.callback_query\n    await query.answer()\n    \n    try:\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ callback_data\n        # –§–æ—Ä–º–∞—Ç: pg_DIGEST_ID_SHORT_CATEGORY_ID_ACTION\n        parts = query.data.split(\"_\")\n        if len(parts) < 4:\n            await query.message.reply_text(\"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç callback_data –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\")\n            return\n        \n        digest_id = int(parts[1])\n        short_category_id = parts[2]\n        action = parts[3]  # n (next) –∏–ª–∏ p (prev)\n        \n        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∏–∑ user_data\n        pagination_key = f\"digest_{digest_id}_{short_category_id}\"\n        if not context.user_data.get(\"pagination\") or pagination_key not in context.user_data[\"pagination\"]:\n            await query.message.reply_text(\n                \"‚ùå –î–∞–Ω–Ω—ã–µ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–Ω–æ–≤–æ.\"\n            )\n            return\n        \n        pagination_data = context.user_data[\"pagination\"][pagination_key]\n        current_page = pagination_data[\"current_page\"]\n        total_pages = pagination_data[\"total_pages\"]\n        category = pagination_data[\"category\"]  # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \n        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–µ–π—Å—Ç–≤–∏—è\n        if action == \"n\" and current_page < total_pages - 1:\n            current_page += 1\n        elif action == \"p\" and current_page > 0:\n            current_page -= 1\n        else:\n            # –ï—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º\n            return\n        \n        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ context_data\n        pagination_data[\"current_page\"] = current_page\n        \n        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞\n        digest = db_manager.get_digest_by_id_with_sections(digest_id)\n        \n        if not digest:\n            await query.message.reply_text(\"‚ùå –î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±—ã–ª —É–¥–∞–ª–µ–Ω.\")\n            return\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n        digest_type = \"–∫—Ä–∞—Ç–∫–∏–π\" if digest[\"digest_type\"] == \"brief\" else \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\"\n        date_str = digest[\"date\"].strftime(\"%d.%m.%Y\")\n        \n        header = f\"üìä {digest_type.capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ {date_str}\\n\"\n        header += f\"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category.capitalize()}\\n\"\n        header += f\"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {current_page + 1}/{total_pages}\\n\\n\"\n        \n        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram\n        from utils.text_utils import TextUtils\n        content = TextUtils.convert_to_html(header + pagination_data[\"parts\"][current_page])\n        \n        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–∞–º–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏\n        keyboard = []\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n        pagination_buttons = []\n        if current_page > 0:\n            pagination_buttons.append(\n                InlineKeyboardButton(\n                    \"‚¨ÖÔ∏è –ü—Ä–µ–¥—ã–¥—É—â–∞—è\", \n                    callback_data=f\"pg_{digest_id}_{short_category_id}_p\"\n                )\n            )\n        if current_page < total_pages - 1:\n            pagination_buttons.append(\n                InlineKeyboardButton(\n                    \"–°–ª–µ–¥—É—é—â–∞—è ‚û°Ô∏è\", \n                    callback_data=f\"pg_{digest_id}_{short_category_id}_n\"\n                )\n            )\n        \n        if pagination_buttons:\n            keyboard.append(pagination_buttons)\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        keyboard.append([\n            InlineKeyboardButton(\n                \"üîô –ö –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é\", \n                callback_data=f\"view_digest_{digest_id}\"\n            )\n        ])\n        \n        reply_markup = InlineKeyboardMarkup(keyboard)\n        \n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å–µ–∫—Ü–∏—é —Å –∫–Ω–æ–ø–∫–∞–º–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n        await query.message.edit_text(\n            content,\n            reply_markup=reply_markup,\n            parse_mode='HTML'\n        )\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º: {str(e)}\", exc_info=True)\n        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n        await query.message.reply_text(\n            f\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏: {str(e)}\\n\"\n            \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É /list –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.\"\n        )\n\nasync def show_full_digest(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):\n    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–ª–±—ç–∫–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n    query = update.callback_query\n    await query.answer()\n    \n    try:\n        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–∑ callback_data\n        # –§–æ—Ä–º–∞—Ç: df_DIGEST_ID\n        digest_id = int(query.data.replace(\"df_\", \"\"))\n        \n        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ ID\n        digest = db_manager.get_digest_by_id_with_sections(digest_id)\n        \n        if not digest:\n            await query.message.reply_text(\"‚ùå –î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –±—ã–ª —É–¥–∞–ª–µ–Ω.\")\n            return\n        \n        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤\n        from utils.text_utils import TextUtils\n        safe_text = TextUtils.clean_markdown_text(digest[\"text\"])\n        \n        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ª–∏–º–∏—Ç Telegram\n        chunks = TextUtils.split_text(safe_text, max_length=3500)\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫\n        digest_type = \"–∫—Ä–∞—Ç–∫–∏–π\" if digest[\"digest_type\"] == \"brief\" else \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\"\n        date_str = digest[\"date\"].strftime(\"%d.%m.%Y\")\n        \n        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ\n        if digest.get(\"date_range_start\") and digest.get(\"date_range_end\"):\n            if digest[\"date_range_start\"].date() != digest[\"date_range_end\"].date():\n                date_str = f\"{digest['date_range_start'].strftime('%d.%m.%Y')} - {digest['date_range_end'].strftime('%d.%m.%Y')}\"\n        \n        header = f\"üìä {digest_type.capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ {date_str}\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–æ–∫—É—Å–µ, –µ—Å–ª–∏ –µ—Å—Ç—å\n        if digest.get(\"focus_category\"):\n            header += f\"\\nüîç –§–æ–∫—É—Å: {digest['focus_category']}\"\n        "
  },
  {
    "chunk_id": 20,
    "context_type": "business_logic",
    "size_tokens": 2052,
    "content": "        # –î–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç—è—Ö\n        first_chunk = f\"{header}\\n\\n{chunks[0]}\"\n        if len(chunks) > 1:\n            first_chunk += f\"\\n\\n(–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç, –≤—Å–µ–≥–æ {len(chunks)} —á–∞—Å—Ç–∏)\"\n        \n        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram\n        first_chunk_html = TextUtils.convert_to_html(first_chunk)\n        \n        # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –∫–Ω–æ–ø–∫–æ–π –≤–æ–∑–≤—Ä–∞—Ç–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏\n        keyboard = [[\n            InlineKeyboardButton(\n                \"üîô –ö –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é\", \n                callback_data=f\"view_digest_{digest_id}\"\n            )\n        ]]\n        \n        reply_markup = InlineKeyboardMarkup(keyboard)\n        \n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —á–∞—Å—Ç—å\n        await query.message.edit_text(\n            first_chunk_html,\n            reply_markup=reply_markup,\n            parse_mode='HTML'\n        )\n        \n        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ö –Ω–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏\n        for i in range(1, len(chunks)):\n            part_text = chunks[i]\n            \n            # –î–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å—Å—ã–ª–∫—É\n            if i == len(chunks) - 1:\n                part_text += \"\\n\\n[–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞]\"\n            \n            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram\n            part_html = TextUtils.convert_to_html(part_text)\n            \n            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å\n            await query.message.reply_text(\n                part_html,\n                parse_mode='HTML'\n            )\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ –ø–æ–ª–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\", exc_info=True)\n        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n        await query.message.reply_text(\n            f\"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ–ª–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\\n\"\n            \"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É /list –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.\"\n        )\n\ndef get_category_icon(category):\n    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∫–æ–Ω–∫—É –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\"\"\"\n    icons = {\n        '–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã': 'üìù',\n        '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞': '‚öñÔ∏è',\n        '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã': 'üìú',\n        '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º': '‚úèÔ∏è',\n        '–¥—Ä—É–≥–æ–µ': 'üìå'\n    }\n    return icons.get(category.lower(), '‚Ä¢')\n\n\n=== collaborative_crew.py ===\n# agents/collaborative_crew.py\n\"\"\"\n–°–∏—Å—Ç–µ–º–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ CrewAI\n–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï self.agent –∏–∑ analyzer.py, critic.py, digester.py\n\"\"\"\n\nimport logging\nfrom datetime import datetime\nfrom typing import Dict, List, Any\nfrom enum import Enum\n\nfrom crewai import Task, Crew, Process\n\nlogger = logging.getLogger(__name__)\n\nclass CollaborativeCrew:\n    \"\"\"\n    –°–∏—Å—Ç–µ–º–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ CrewAI\n    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ self.agent –∏–∑ –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã\n    \"\"\"\n    \n    def __init__(self, agent_registry):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\n        \n        Args:\n            agent_registry: –†–µ–µ—Å—Ç—Ä –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã\n        \"\"\"\n        self.agent_registry = agent_registry\n        self.collaboration_history = []\n        \n        # –ü–æ–ª—É—á–∞–µ–º –°–£–©–ï–°–¢–í–£–Æ–©–ò–• CrewAI –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑ –Ω–∞—à–∏—Ö –∫–ª–∞—Å—Å–æ–≤\n        self._get_existing_crewai_agents()\n        \n        logger.info(\"ü§ù CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è —Å –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –∞–≥–µ–Ω—Ç–∞–º–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\")\n    \n    def _get_existing_crewai_agents(self):\n        \"\"\"–ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ CrewAI –∞–≥–µ–Ω—Ç—ã –∏–∑ –Ω–∞—à–∏—Ö –∫–ª–∞—Å—Å–æ–≤\"\"\"\n        \n        try:\n            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—à–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤ –∏–∑ —Ä–µ–µ—Å—Ç—Ä–∞\n            analyzer_instance = self.agent_registry.get_agent(\"analyzer\")\n            critic_instance = self.agent_registry.get_agent(\"critic\") \n            digester_instance = self.agent_registry.get_agent(\"digester\")\n            \n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–• self.agent (CrewAI –∞–≥–µ–Ω—Ç—ã)\n            self.crewai_analyzer = analyzer_instance.agent\n            self.crewai_critic = critic_instance.agent\n            self.crewai_digester = digester_instance.agent\n            \n            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º GemmaLLM –¥–ª—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\n            # –ü–æ—Å–∫–æ–ª—å–∫—É —Ç–æ–ª—å–∫–æ —É –Ω–µ—ë –µ—Å—Ç—å –º–µ—Ç–æ–¥ generate\n            from llm.gemma_model import GemmaLLM\n            self.llm_model = GemmaLLM()\n            logger.info(\"‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º GemmaLLM –¥–ª—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ (–∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ generate)\")\n            \n            logger.info(\"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ CrewAI –∞–≥–µ–Ω—Ç—ã:\")\n            logger.info(f\"   üß† –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä: {self.crewai_analyzer.role}\")\n            logger.info(f\"   üîç –ö—Ä–∏—Ç–∏–∫: {self.crewai_critic.role}\")\n            logger.info(f\"   üìã –î–∞–π–¥–∂–µ—Å—Ç–µ—Ä: {self.crewai_digester.role}\")\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤: {str(e)}\")\n            self.crewai_analyzer = None\n            self.crewai_critic = None  \n            self.crewai_digester = None\n            self.llm_model = None\n    \n    async def collaborate_on_difficult_categorization(self, message_id: int, message_text: str,\n                                                     initial_category: str, confidence: float) -> Dict[str, Any]:\n        \"\"\"\n        CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è –¥–ª—è —Å–ª–æ–∂–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –∞–≥–µ–Ω—Ç–∞–º–∏\n        \"\"\"\n        logger.info(f\"ü§ù CREWAI –ö–û–õ–õ–ê–ë–û–†–ê–¶–ò–Ø: –°–ª–æ–∂–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}\")\n        \n        if not all([self.crewai_analyzer, self.crewai_critic]):\n            logger.error(\"‚ùå –ù–µ –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\")\n            return {\n                \"status\": \"error\",\n                \"final_category\": initial_category,\n                \"final_confidence\": confidence,\n                \"reasoning\": \"–ê–≥–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\"\n            }\n        \n        try:\n            # –ó–ê–î–ê–ß–ê 1: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º\n            deep_analysis_task = Task(\n                description=f\"\"\"\n                –ü—Ä–æ–≤–µ–¥–∏ —É–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ç–æ—á–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏.\n                \n                –°–û–û–ë–©–ï–ù–ò–ï: \"{message_text}\"\n                –¢–ï–ö–£–©–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø: {initial_category}\n                –£–í–ï–†–ï–ù–ù–û–°–¢–¨: {confidence}/5\n                \n                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π:\n                1. –ü—Ä–∞–≤–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é\n                2. –¢–∏–ø –ø—Ä–∞–≤–æ–≤–æ–≥–æ –∞–∫—Ç–∞ –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã\n                3. –°—Ç–∞–¥–∏—é –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞\n                4. –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã\n                \n                –î–û–°–¢–£–ü–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò:\n                - –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã\n                - –Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã\n                - –ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º  \n                - –Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞\n                - –¥—Ä—É–≥–æ–µ\n                \n                –î–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º.\n                \"\"\",\n                agent=self.crewai_analyzer,  # –ò–°–ü–û–õ–¨–ó–£–ï–ú –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û!\n                expected_output=\"–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–∞–≤–æ–≤–æ–π –∞–Ω–∞–ª–∏–∑ —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π\"\n            )\n            \n            # –ó–ê–î–ê–ß–ê 2: –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú –∫—Ä–∏—Ç–∏–∫–æ–º\n            expert_review_task = Task(\n                description=f\"\"\"\n                –î–∞–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–ª–ª–µ–≥–∏.\n                \n                –û—Ü–µ–Ω–∏:\n                1. –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∞–≤–æ–≤–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–∏\n                2. –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: –Ω–µ—Ç –ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π\n                3. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑: —É—á–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤\n                \n                –î–∞–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É.\n                \n                –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:\n                –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: [—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è]\n                –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [1-5]\n                –ü—Ä–∞–≤–æ–≤–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: [–¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ]\n                –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: [–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]\n                \"\"\",\n                agent=self.crewai_critic,  # –ò–°–ü–û–õ–¨–ó–£–ï–ú –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û!\n                expected_output=\"–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –ø—Ä–∞–≤–æ–≤—ã–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º\",\n                context=[deep_analysis_task]\n            )\n            \n            # –°–û–ó–î–ê–ï–ú CREW –° –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –ê–ì–ï–ù–¢–ê–ú–ò\n            categorization_crew = Crew(\n                agents=[self.crewai_analyzer, self.crewai_critic],\n                tasks=[deep_analysis_task, expert_review_task],\n                process=Process.sequential,\n                verbose=True\n            )\n            \n            logger.info(\"üöÄ –ó–∞–ø—É—Å–∫ CrewAI —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏...\")\n            \n            # –í–´–ü–û–õ–ù–Ø–ï–ú —á–µ—Ä–µ–∑ CrewAI, –Ω–æ —Å –Ω–∞—à–µ–π LLM"
  },
  {
    "chunk_id": 21,
    "context_type": "business_logic",
    "size_tokens": 1498,
    "content": "            result = await self._execute_crew_with_existing_agents(categorization_crew)\n            \n            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n            collaboration_result = self._parse_categorization_result(\n                result, message_text, initial_category, confidence\n            )\n            \n            self._log_crewai_collaboration(\"difficult_categorization\", collaboration_result)\n            \n            return collaboration_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"final_category\": initial_category,\n                \"final_confidence\": confidence,\n                \"reasoning\": f\"–û—à–∏–±–∫–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏: {str(e)}\",\n                \"method\": \"crewai_existing_agents_error\"\n            }\n    \n    async def collaborate_on_quality_assurance(self, digest_content: Dict[str, str], \n                                             digest_type: str, categories_data: Dict) -> Dict[str, Any]:\n        \"\"\"\n        CrewAI –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –∞–≥–µ–Ω—Ç–∞–º–∏\n        \"\"\"\n        logger.info(f\"ü§ù CREWAI –ö–û–õ–õ–ê–ë–û–†–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ ({digest_type})\")\n        \n        if not all([self.crewai_digester, self.crewai_critic]):\n            logger.error(\"‚ùå –ù–µ –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\")\n            return {\"status\": \"error\", \"overall_score\": 3.0}\n        \n        try:\n            # –ó–ê–î–ê–ß–ê 1: –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú –¥–∞–π–¥–∂–µ—Å—Ç–µ—Ä–æ–º  \n            content_analysis_task = Task(\n                description=f\"\"\"\n                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏.\n                \n                –¢–ò–ü –î–ê–ô–î–ñ–ï–°–¢–ê: {digest_type}\n                –°–û–î–ï–†–ñ–ò–ú–û–ï: {str(digest_content)[:500]}...\n                \n                –û—Ü–µ–Ω–∏ –ø–æ —à–∫–∞–ª–µ 1-5:\n                1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n                2. –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å\n                3. –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n                4. –ü–æ–ª–Ω–æ—Ç–∞ –æ—Ö–≤–∞—Ç–∞ –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π\n                \n                –î–∞–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.\n                \"\"\",\n                agent=self.crewai_digester,  # –ò–°–ü–û–õ–¨–ó–£–ï–ú –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û!\n                expected_output=\"–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\"\n            )\n            \n            # –ó–ê–î–ê–ß–ê 2: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú –∫—Ä–∏—Ç–∏–∫–æ–º\n            critical_review_task = Task(\n                description=f\"\"\"\n                –ü—Ä–æ–≤–µ–¥–∏ –Ω–µ–∑–∞–≤–∏—Å–∏–º—É—é –∫—Ä–∏—Ç–∏—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –¥–∞–π–¥–∂–µ—Å—Ç–∞.\n                \n                –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞:\n                1. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º\n                2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\n                3. –û—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ü–µ–Ω–Ω–æ—Å—Ç–∏\n                4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –∫–∞—á–µ—Å—Ç–≤–∞\n                \n                –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:\n                –°—Ç—Ä—É–∫—Ç—É—Ä–∞: [–æ—Ü–µ–Ω–∫–∞ 1-5]\n                –ö–æ–Ω—Ç–µ–Ω—Ç: [–æ—Ü–µ–Ω–∫–∞ 1-5]\n                –¢–æ—á–Ω–æ—Å—Ç—å: [–æ—Ü–µ–Ω–∫–∞ 1-5]\n                –ü–æ–ª–Ω–æ—Ç–∞: [–æ—Ü–µ–Ω–∫–∞ 1-5]\n                –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: [–æ—Ü–µ–Ω–∫–∞ 1-5]\n                \n                –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: [—Å–ø–∏—Å–æ–∫ —É–ª—É—á—à–µ–Ω–∏–π]\n                \"\"\",\n                agent=self.crewai_critic,  # –ò–°–ü–û–õ–¨–ó–£–ï–ú –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û!\n                expected_output=\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏\",\n                context=[content_analysis_task]\n            )\n            \n            # –°–û–ó–î–ê–ï–ú CREW –° –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –ê–ì–ï–ù–¢–ê–ú–ò\n            quality_crew = Crew(\n                agents=[self.crewai_digester, self.crewai_critic],\n                tasks=[content_analysis_task, critical_review_task],\n                process=Process.sequential,\n                verbose=True\n            )\n            \n            logger.info(\"üöÄ –ó–∞–ø—É—Å–∫ CrewAI –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞...\")\n            \n            # –í–´–ü–û–õ–ù–Ø–ï–ú —á–µ—Ä–µ–∑ CrewAI\n            result = await self._execute_crew_with_existing_agents(quality_crew)\n            \n            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n            quality_result = self._parse_quality_result(result, digest_type)\n            \n            self._log_crewai_collaboration(\"quality_assurance\", quality_result)\n            \n            return quality_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ CrewAI –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"overall_score\": 3.0,\n                \"method\": \"crewai_existing_agents_error\"\n            }\n    \n    async def collaborate_on_comprehensive_analysis(self, period_start: datetime, \n                                                   period_end: datetime) -> Dict[str, Any]:\n        \"\"\"\n        –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—é –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n        \"\"\"\n        logger.info(f\"ü§ù CREWAI –ö–û–õ–õ–ê–ë–û–†–ê–¶–ò–Ø: –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞ –ø–µ—Ä–∏–æ–¥\")\n        \n        if not all([self.crewai_analyzer, self.crewai_critic, self.crewai_digester]):\n            logger.error(\"‚ùå –ù–µ –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\")\n            return {\"status\": \"error\", \"summary\": \"–ê–≥–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã\"}\n        \n        try:\n            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤\n            analysis_task = Task(\n                description=f\"\"\"\n                –ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–æ–≤—ã—Ö —Ç–µ–Ω–¥–µ–Ω—Ü–∏–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\n                –í—ã—è–≤–∏ –∫–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è.\n                \"\"\",\n                agent=self.crewai_analyzer,\n                expected_output=\"–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ –ø—Ä–∞–≤–æ–≤—ã–º —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è–º\"\n            )\n            \n            critique_task = Task(\n                description=f\"\"\"\n                –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑.\n                –ù–∞–π–¥–∏ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è.\n                \"\"\",\n                agent=self.crewai_critic,\n                expected_output=\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∞–Ω–∞–ª–∏–∑–∞\",\n                context=[analysis_task]\n            )\n            \n            synthesis_task = Task(\n                description=f\"\"\"\n                –°–∏–Ω—Ç–µ–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫—Ä–∏—Ç–∏–∫–∏ –≤ –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç."
  },
  {
    "chunk_id": 22,
    "context_type": "business_logic",
    "size_tokens": 1495,
    "content": "                –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ –≤—ã–≤–æ–¥–∞–º–∏.\n                \"\"\",\n                agent=self.crewai_digester,\n                expected_output=\"–°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç\",\n                context=[analysis_task, critique_task]\n            )\n            \n            # –°–û–ó–î–ê–ï–ú CREW –°–û –í–°–ï–ú–ò –ê–ì–ï–ù–¢–ê–ú–ò\n            comprehensive_crew = Crew(\n                agents=[self.crewai_analyzer, self.crewai_critic, self.crewai_digester],\n                tasks=[analysis_task, critique_task, synthesis_task],\n                process=Process.sequential,\n                verbose=True\n            )\n            \n            logger.info(\"üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ CrewAI –∞–Ω–∞–ª–∏–∑–∞...\")\n            \n            # –í–´–ü–û–õ–ù–Ø–ï–ú\n            result = await self._execute_crew_with_existing_agents(comprehensive_crew)\n            \n            comprehensive_result = {\n                \"status\": \"success\",\n                \"summary\": result[:200] + \"...\" if len(result) > 200 else result,\n                \"full_analysis\": result,\n                \"method\": \"crewai_comprehensive_existing_agents\",\n                \"timestamp\": datetime.now()\n            }\n            \n            self._log_crewai_collaboration(\"comprehensive_analysis\", comprehensive_result)\n            \n            return comprehensive_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"summary\": f\"–û—à–∏–±–∫–∞: {str(e)}\",\n                \"method\": \"crewai_comprehensive_error\"\n            }\n    \n    async def _execute_crew_with_existing_agents(self, crew: Crew) -> str:\n        \"\"\"\n        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ CrewAI —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏ —á–µ—Ä–µ–∑ –Ω–∞—à—É LLM\n        \"\"\"\n        try:\n            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM\n            if not self.llm_model:\n                raise Exception(\"LLM –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞\")\n            \n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É LLM –µ—Å—Ç—å –º–µ—Ç–æ–¥ generate\n            if not hasattr(self.llm_model, 'generate'):\n                raise Exception(f\"LLM {type(self.llm_model).__name__} –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ 'generate'\")\n            \n            logger.info(f\"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM: {type(self.llm_model).__name__} —Å –º–µ—Ç–æ–¥–æ–º generate\")\n            \n            # –ü–æ—Å–∫–æ–ª—å–∫—É CrewAI –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–∞—à–µ–π LLM –Ω–∞–ø—Ä—è–º—É—é,\n            # –≤—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–¥–∞—á–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ –Ω–∞—à—É LLM\n            results = []\n            \n            for i, task in enumerate(crew.tasks):\n                logger.info(f\"üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ {i+1}/{len(crew.tasks)}\")\n                \n                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∑–∞–¥–∞—á–∏\n                full_prompt = f\"\"\"\n                –¢—ã {task.agent.role}.\n                \n                {task.agent.backstory}\n                \n                –ó–ê–î–ê–ß–ê: {task.description}\n                \n                –¶–ï–õ–¨: {task.agent.goal}\n                \n                –í—ã–ø–æ–ª–Ω–∏ –∑–∞–¥–∞—á—É –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.\n                –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω.\n                \"\"\"\n                \n                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º GemmaLLM —Å –º–µ—Ç–æ–¥–æ–º generate\n                result = self.llm_model.generate(\n                    full_prompt,\n                    max_tokens=800,\n                    temperature=0.3\n                )\n                \n                results.append(result)\n                logger.info(f\"‚úÖ –ó–∞–¥–∞—á–∞ {i+1} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {len(result)} —Å–∏–º–≤–æ–ª–æ–≤\")\n            \n            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n            final_result = \"\\n\\n=== –†–ï–ó–£–õ–¨–¢–ê–¢ –ö–û–õ–õ–ê–ë–û–†–ê–¶–ò–ò ===\\n\\n\".join(results)\n            \n            logger.info(f\"üéâ CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")\n            return final_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è CrewAI —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏: {str(e)}\")\n            raise\n    \n    def _parse_categorization_result(self, result: str, message_text: str, \n                                   initial_category: str, confidence: float) -> Dict[str, Any]:\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\"\"\"\n        \n        lines = result.split('\\n')\n        \n        final_category = initial_category\n        final_confidence = confidence\n        reasoning = \"\"\n        \n        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n        for line in lines:\n            line_clean = line.strip()\n            \n            # –ò—â–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n            if line_clean.lower().startswith('–∫–∞—Ç–µ–≥–æ—Ä–∏—è:') or line_clean.lower().startswith('—ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è:'):\n                category_text = line_clean.split(':', 1)[1].strip().lower()\n                categories = ['–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã', '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã', '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º', \n                             '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞', '–¥—Ä—É–≥–æ–µ']\n                for cat in categories:\n                    if cat in category_text:\n                        final_category = cat\n                        break\n            \n            # –ò—â–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å\n            elif line_clean.lower().startswith('—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:') or line_clean.lower().startswith('—ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:'):\n                try:\n                    import re\n                    conf_match = re.search(r'\\d+', line_clean)\n                    if conf_match:\n                        final_confidence = float(conf_match.group())\n                        final_confidence = max(1.0, min(5.0, final_confidence))\n                except:\n                    pass\n            \n            # –ò—â–µ–º –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ\n            elif line_clean.lower().startswith('–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:') or line_clean.lower().startswith('–ø—Ä–∞–≤–æ–≤–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:'):\n                reasoning = line_clean.split(':', 1)[1].strip()\n        \n        # –ú–µ—Ç—Ä–∏–∫–∏\n        category_changed = final_category != initial_category\n        confidence_improved = final_confidence > confidence\n        \n        return {\n            \"status\": \"success\",\n            \"final_category\": final_category,\n            \"final_confidence\": final_confidence,\n            \"category_changed\": category_changed,"
  },
  {
    "chunk_id": 23,
    "context_type": "business_logic",
    "size_tokens": 2409,
    "content": "            \"confidence_improved\": confidence_improved,\n            \"reasoning\": reasoning or f\"CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏\",\n            \"method\": \"crewai_existing_agents\",\n            \"raw_result\": result[:300] + \"...\" if len(result) > 300 else result\n        }\n    \n    def _parse_quality_result(self, result: str, digest_type: str) -> Dict[str, Any]:\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\"\"\"\n        \n        scores = {\"structure\": 3.0, \"content\": 3.0, \"accuracy\": 3.0, \"completeness\": 3.0, \"overall\": 3.0}\n        recommendations = []\n        \n        lines = result.split('\\n')\n        for line in lines:\n            line_clean = line.strip()\n            \n            # –ò—â–µ–º –æ—Ü–µ–Ω–∫–∏\n            import re\n            if '–æ—Ü–µ–Ω–∫–∞' in line_clean.lower():\n                score_match = re.search(r'(\\d+(?:\\.\\d+)?)', line_clean)\n                if score_match:\n                    score = float(score_match.group())\n                    if '—Å—Ç—Ä—É–∫—Ç—É—Ä' in line_clean.lower():\n                        scores[\"structure\"] = score\n                    elif '–∫–æ–Ω—Ç–µ–Ω—Ç' in line_clean.lower():\n                        scores[\"content\"] = score\n                    elif '—Ç–æ—á–Ω–æ—Å—Ç—å' in line_clean.lower():\n                        scores[\"accuracy\"] = score\n                    elif '–ø–æ–ª–Ω–æ—Ç–∞' in line_clean.lower():\n                        scores[\"completeness\"] = score\n                    elif '–æ–±—â–∞—è' in line_clean.lower():\n                        scores[\"overall\"] = score\n            \n            # –ò—â–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n            if '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü' in line_clean.lower() and ':' in line_clean:\n                rec = line_clean.split(':', 1)[1].strip()\n                if rec:\n                    recommendations.append(rec)\n        \n        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É\n        if scores[\"overall\"] == 3.0:\n            scores[\"overall\"] = sum(scores[k] for k in [\"structure\", \"content\", \"accuracy\", \"completeness\"]) / 4\n        \n        return {\n            \"status\": \"success\",\n            \"overall_score\": scores[\"overall\"],\n            \"component_scores\": scores,\n            \"recommendations\": recommendations,\n            \"method\": \"crewai_existing_agents_quality\",\n            \"digest_type\": digest_type\n        }\n    \n    def _log_crewai_collaboration(self, scenario: str, result: Dict[str, Any]):\n        \"\"\"–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ CrewAI –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\"\"\"\n        logger.info(f\"ü§ù CREWAI –ö–û–õ–õ–ê–ë–û–†–ê–¶–ò–Ø –° –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú–ò –ê–ì–ï–ù–¢–ê–ú–ò –ó–ê–í–ï–†–®–ï–ù–ê ({scenario}):\")\n        logger.info(f\"   üìä –°—Ç–∞—Ç—É—Å: {result.get('status', 'unknown')}\")\n        logger.info(f\"   üîß –ú–µ—Ç–æ–¥: {result.get('method', 'unknown')}\")\n        \n        if scenario == \"difficult_categorization\":\n            logger.info(f\"   üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {result.get('final_category', 'unknown')}\")\n            logger.info(f\"   üìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.get('final_confidence', 0):.1f}/5\")\n            logger.info(f\"   üîÑ –ò–∑–º–µ–Ω–µ–Ω–∏—è: –∫–∞—Ç–µ–≥–æ—Ä–∏—è={'–î–∞' if result.get('category_changed') else '–ù–µ—Ç'}, \"\n                       f\"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={'–î–∞' if result.get('confidence_improved') else '–ù–µ—Ç'}\")\n        \n        elif scenario == \"quality_assurance\":\n            logger.info(f\"   üìä –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {result.get('overall_score', 0):.1f}/5\")\n            logger.info(f\"   üìã –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(result.get('recommendations', []))}\")\n        \n        logger.info(\"   \" + \"=\" * 50)\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é\n        self.collaboration_history.append({\n            \"timestamp\": datetime.now(),\n            \"scenario\": scenario,\n            \"result\": result,\n            \"method\": \"crewai_existing_agents\"\n        })\n\n\n# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\nTrueCrewAICollaboration = CollaborativeCrew\n\n=== critic.py ===\n\"\"\"\n–ê–≥–µ–Ω—Ç-–∫—Ä–∏—Ç–∏–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π\n\"\"\"\nimport logging\nimport json\nimport os\nfrom datetime import datetime\nfrom crewai import Agent\nfrom langchain.tools import Tool\nfrom utils.learning_manager import LearningExamplesManager\nfrom config.settings_cop2 import CATEGORIES\nfrom concurrent.futures import ThreadPoolExecutor\nimport concurrent.futures\n\nlogger = logging.getLogger(__name__)\n\nclass CriticAgent:\n    def __init__(self, db_manager, llm_model=None):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\n        \n        Args:\n            db_manager (DatabaseManager): –ú–µ–Ω–µ–¥–∂–µ—Ä –ë–î\n            llm_model (GemmaLLM, optional): –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞\n        \"\"\"\n        self.db_manager = db_manager\n        \n        # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤\n        from llm.gemma_model import GemmaLLM # Changed to lazy import\n        \n        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n        self.learning_manager = LearningExamplesManager()\n        \n        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n        review_tool = Tool(\n            name=\"review_categorization\",\n            func=self.review_recent_categorizations,\n            description=\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\"\n        )\n        \n        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ CrewAI\n        self.agent = Agent(\n            name=\"Critic\",\n            role=\"–ö—Ä–∏—Ç–∏–∫-–∞–Ω–∞–ª–∏—Ç–∏–∫\",\n            goal=\"–ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏ —É–ª—É—á—à–∞—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞\",\n            backstory=\"–Ø –ø—Ä–æ–≤–µ—Ä—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞.\",\n            verbose=True,\n            tools=[review_tool]\n        )\n        self.llm_model = llm_model or GemmaLLM() # Initialize after lazy import\n    def _save_learning_example(self, text, category, justification):\n        \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞\"\"\"\n        try:\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤\n            success = self.learning_manager.save_example(text, category, justification)\n            if success:\n                logger.info(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n            return success\n        except Exception as e:\n            logger.error(f\"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–∞—é—â–∏–π –ø—Ä–∏–º–µ—Ä: {str(e)}\")\n            return False\n        \n    def get_message_by_id(self, message_id):\n        \"\"\"\n        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ ID —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä –ë–î\n        \n        Args:\n            message_id (int): ID —Å–æ–æ–±—â–µ–Ω–∏—è\n            \n        Returns:\n            Message: –û–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ None\n        \"\"\"\n        return self.db_manager.get_message_by_id(message_id)\n    \n    # –í agents/critic.py - —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ review_categorization\n# –ó–∞–º–µ–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –Ω–∞ —ç—Ç–æ—Ç\n\n    # –í agents/critic.py - —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ review_categorization\n# –ó–∞–º–µ–Ω–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ –Ω–∞ —ç—Ç–æ—Ç\n\n    def review_categorization(self, message_id, original_category):\n        \"\"\"\n        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è\n        —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\n        \n        Args:\n            message_id (int): ID —Å–æ–æ–±—â–µ–Ω–∏—è\n            original_category (str): –¢–µ–∫—É—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n            \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏\n        \"\"\"\n        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n        message = self.get_message_by_id(message_id)\n        if not message:\n            logger.warning(f\"–°–æ–æ–±—â–µ–Ω–∏–µ —Å ID {message_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\")\n            return {\"status\": \"error\", \"message\": \"–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\"}\n        \n        logger.info(f\"–ù–∞—á–∏–Ω–∞—é –º–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}\")\n        \n        # –≠–¢–ê–ü 1: –ü–†–ê–í–û–í–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê\n        legal_analysis = self._perform_legal_accuracy_review(message.text, original_category)\n        logger.debug(f\"–ü—Ä–∞–≤–æ–≤–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞: {legal_analysis}\")\n        \n        # –≠–¢–ê–ü 2: –õ–û–ì–ò–ß–ï–°–ö–ê–Ø –ö–û–ù–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨\n        consistency_analysis = self._perform_consistency_review(message.text, original_category)\n        logger.debug(f\"–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: {consistency_analysis}\")\n        \n        # –≠–¢–ê–ü 3: –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó\n        context_analysis = self._perform_context_review(message.text, message.channel, original_category)\n        logger.debug(f\"–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {context_analysis}\")\n        \n        # –≠–¢–ê–ü 4: –°–ò–ù–¢–ï–ó –ò –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï\n        final_decision = self._synthesize_multi_perspective_decision(\n            message.text, original_category, \n            legal_analysis, consistency_analysis, context_analysis\n        )\n        \n        # –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –ú–ù–û–ì–û–ü–ï–†–°–ü–ï–ö–¢–ò–í–ù–û–ì–û REASONING\n        self._log_multi_perspective_reasoning(\n            message_id, message.text, original_category,\n            legal_analysis, consistency_analysis, context_analysis, final_decision\n        )\n        \n        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—à–µ–Ω–∏–µ\n        return self._apply_review_decision(message_id, message, original_category, final_decision)\n\n    def _perform_legal_accuracy_review(self, message_text, current_category):\n        \"\"\"–≠–¢–ê–ü 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–æ–≤–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏\"\"\"\n        \n        legal_prompt = f\"\"\"\n    –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–∞–≤–æ–≤–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º—É –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É.\n\n    –ó–ê–î–ê–ß–ê: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∞–≤–æ–≤—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è.\n\n    –°–û–û–ë–©–ï–ù–ò–ï: {message_text}\n    –¢–ï–ö–£–©–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø: {current_category}\n\n    –ü–†–ê–í–û–í–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\n\n    1. –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó:\n    - –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø—Ä–∞–≤–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã?\n    - –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–π –ø—Ä–∞–≤–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ?\n    - –ù–µ—Ç –ª–∏ –æ—à–∏–±–æ–∫ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ –ø—Ä–∞–≤–æ–≤—ã—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä?\n\n    2. –ü–†–û–¶–ï–î–£–†–ù–´–ô –ê–ù–ê–õ–ò–ó:\n    - –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã: –ø—Ä–æ–µ–∫—Ç—ã, –≤–Ω–µ—Å–µ–Ω–∏–µ, —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ\n    - –ù–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã: –ø—Ä–∏–Ω—è—Ç–∏–µ, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∏–µ, –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ –≤ —Å–∏–ª—É\n    - –ü–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º: –∏–∑–º–µ–Ω–µ–Ω–∏—è, –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∞–∫—Ç–æ–≤\n    - –°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞: —Ä–µ—à–µ–Ω–∏—è, –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è, —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è —Å—É–¥–æ–≤\n\n    3. –ü–†–ê–í–û–í–ê–Ø –û–¶–ï–ù–ö–ê:\n    –ù–∞ –∫–∞–∫–æ–π —Å—Ç–∞–¥–∏–∏ –ø—Ä–∞–≤–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ–ø–∏—Å—ã–≤–∞–µ–º–æ–µ —Å–æ–±—ã—Ç–∏–µ?\n    –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —ç—Ç–æ–π —Å—Ç–∞–¥–∏–∏?\n\n    –û–¢–í–ï–¢ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:"
  },
  {
    "chunk_id": 24,
    "context_type": "business_logic",
    "size_tokens": 1491,
    "content": "    –ü—Ä–∞–≤–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: [–ø—Ä–∞–≤–∏–ª—å–Ω–æ/–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ/—Å–ø–æ—Ä–Ω–æ]\n    –°—Ç–∞–¥–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞: [–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–∞–¥–∏–∏]\n    –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: [–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –¥—Ä—É–≥—É—é]\n    \"\"\"\n        \n        try:\n            response = self.llm_model.generate(legal_prompt, max_tokens=300, temperature=0.2)\n            return self._parse_review_response(response, \"legal\")\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤ –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–µ: {str(e)}\")\n            return {\"status\": \"error\", \"recommendation\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"}\n\n    def _perform_consistency_review(self, message_text, current_category):\n        \"\"\"–≠–¢–ê–ü 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–æ–π –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏\"\"\"\n        \n        consistency_prompt = f\"\"\"\n    –¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n\n    –ó–ê–î–ê–ß–ê: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –ª–æ–≥–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏.\n\n    –°–û–û–ë–©–ï–ù–ò–ï: {message_text}\n    –¢–ï–ö–£–©–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø: {current_category}\n\n    –ê–ù–ê–õ–ò–ó –ö–û–ù–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–ò:\n\n    1. –õ–û–ì–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê:\n    - –ï—Å—Ç—å –ª–∏ —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏?\n    - –ù–µ—Ç –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥—Ä—É–≥–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π?\n    - –õ–æ–≥–∏—á–Ω–æ –ª–∏ —Ä–µ—à–µ–Ω–∏–µ –æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏?\n\n    2. –ü–†–ò–ó–ù–ê–ö–ò –ö–ê–¢–ï–ì–û–†–ò–ô:\n    –ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã: \"–ø—Ä–æ–µ–∫—Ç\", \"–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\", \"—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ\", \"–≤–Ω–µ—Å–µ–Ω\"\n    –ù–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã: \"–ø—Ä–∏–Ω—è—Ç\", \"–ø–æ–¥–ø–∏—Å–∞–Ω\", \"–≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É\", \"—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω ‚Ññ\"\n    –ü–æ–ø—Ä–∞–≤–∫–∏: \"–∏–∑–º–µ–Ω–µ–Ω–∏—è\", \"–≤–Ω–µ—Å–µ–Ω—ã –≤\", \"–¥–æ–ø–æ–ª–Ω–µ–Ω\", —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∑–∞–∫–æ–Ω\n    –°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞: \"—Å—É–¥\", \"—Ä–µ—à–µ–Ω–∏–µ\", \"–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ\", \"—Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏–µ\"\n\n    3. –ê–õ–¨–¢–ï–†–ù–ê–¢–ò–í–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò:\n    –ú–æ–≥–ª–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∫ –¥—Ä—É–≥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏?\n    –ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞ —ç—Ç–æ –≥–æ–≤–æ—Ä—è—Ç?\n\n    –û–¢–í–ï–¢ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n    –õ–æ–≥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞: [–ª–æ–≥–∏—á–Ω–æ/–Ω–µ–ª–æ–≥–∏—á–Ω–æ/—Å–ø–æ—Ä–Ω–æ]\n    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: [–¥—Ä—É–≥–∞—è –≤–æ–∑–º–æ–∂–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–ª–∏ \"–Ω–µ—Ç\"]\n    –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [1-5]\n    \"\"\"\n        \n        try:\n            response = self.llm_model.generate(consistency_prompt, max_tokens=300, temperature=0.2)\n            return self._parse_review_response(response, \"consistency\")\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏: {str(e)}\")\n            return {\"status\": \"error\", \"recommendation\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"}\n\n    def _perform_context_review(self, message_text, channel, current_category):\n        \"\"\"–≠–¢–ê–ü 3: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑\"\"\"\n        \n        context_prompt = f\"\"\"\n    –¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –∏ –º–µ–¥–∏–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º.\n\n    –ó–ê–î–ê–ß–ê: –£—á–µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏.\n\n    –°–û–û–ë–©–ï–ù–ò–ï: {message_text}\n    –ò–°–¢–û–ß–ù–ò–ö: {channel}\n    –¢–ï–ö–£–©–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø: {current_category}\n\n    –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó:\n\n    1. –ê–ù–ê–õ–ò–ó –ò–°–¢–û–ß–ù–ò–ö–ê:\n    @dumainfo ‚Üí —á–∞—Å—Ç–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã –∏ –ø—Ä–∏–Ω—è—Ç—ã–µ –∑–∞–∫–æ–Ω—ã\n    @sovfedinfo ‚Üí —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–æ–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ, –æ–¥–æ–±—Ä–µ–Ω–∏—è –°–§\n    @vsrf_ru ‚Üí —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞, —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è –í–°\n    @kremlininfo ‚Üí –ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–æ–º –∑–∞–∫–æ–Ω—ã\n    @governmentru ‚Üí –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è\n\n    2. –¢–ò–ü–ò–ß–ù–û–°–¢–¨ –î–õ–Ø –ò–°–¢–û–ß–ù–ò–ö–ê:\n    –¢–∏–ø–∏—á–Ω–æ –ª–∏ —Ç–∞–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞?\n    –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞?\n\n    3. –í–†–ï–ú–ï–ù–ù–´–ï –ú–ê–†–ö–ï–†–´:\n    –ï—Å—Ç—å –ª–∏ —É–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –≤—Ä–µ–º—è (–ø—Ä–æ—à–ª–æ–µ/–Ω–∞—Å—Ç–æ—è—â–µ–µ/–±—É–¥—É—â–µ–µ)?\n    –ö–∞–∫ —ç—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é?\n\n    –û–¢–í–ï–¢ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n    –ö–æ–Ω—Ç–µ–∫—Å—Ç: [—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç/–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫—É]\n    –¢–∏–ø–∏—á–Ω–æ—Å—Ç—å: [—Ç–∏–ø–∏—á–Ω–æ/–Ω–µ—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –∫–∞–Ω–∞–ª–∞]\n    –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞—Å–ø–µ–∫—Ç: [–∞–∫—Ç—É–∞–ª—å–Ω–æ–µ/–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ/–ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ]\n    \"\"\"\n        \n        try:\n            response = self.llm_model.generate(context_prompt, max_tokens=250, temperature=0.2)\n            return self._parse_review_response(response, \"context\")\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {str(e)}\")\n            return {\"status\": \"error\", \"recommendation\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"}\n\n    def _synthesize_multi_perspective_decision(self, message_text, original_category, \n                                            legal_analysis, consistency_analysis, context_analysis):\n        \"\"\"–≠–¢–ê–ü 4: –°–∏–Ω—Ç–µ–∑ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –∏ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è\"\"\"\n        \n        synthesis_prompt = f\"\"\"\n    –¢—ã - —Å—Ç–∞—Ä—à–∏–π —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫, –ø—Ä–∏–Ω–∏–º–∞—é—â–∏–π —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ.\n\n    –°–û–û–ë–©–ï–ù–ò–ï: {message_text}\n    –¢–ï–ö–£–©–ê–Ø –ö–ê–¢–ï–ì–û–†–ò–Ø: {original_category}\n\n    –†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–¢–ò–ó:\n    1. –ü—Ä–∞–≤–æ–≤–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞: {legal_analysis}\n    2. –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å: {consistency_analysis}  \n    3. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {context_analysis}\n\n    –ü–†–ò–ù–Ø–¢–ò–ï –†–ï–®–ï–ù–ò–Ø:\n\n    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –≤—Å–µ —Ç—Ä–∏ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∏ –ø—Ä–∏–º–∏ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ:\n\n    1. –ï—Å–ª–∏ 2+ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–µ ‚Üí –ò–ó–ú–ï–ù–ò–¢–¨\n    2. –ï—Å–ª–∏ 2+ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é ‚Üí –ü–û–î–¢–í–ï–†–î–ò–¢–¨\n    3. –ï—Å–ª–∏ –º–Ω–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏–ª–∏—Å—å ‚Üí —É—á–µ—Å—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑\n\n    –ö–ê–¢–ï–ì–û–†–ò–ò –ù–ê –í–´–ë–û–†:\n    - –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã\n    - –Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã  \n    - –ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º\n    - –Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞\n    - –¥—Ä—É–≥–æ–µ\n\n    –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n    –†–µ—à–µ–Ω–∏–µ: [–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å]\n    –ù–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: [–µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å - —É–∫–∞–∂–∏ –∫–∞–∫—É—é]\n    –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [1-5]\n    –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: [–∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è]\n    \"\"\"\n        \n        try:\n            response = self.llm_model.generate(synthesis_prompt, max_tokens=400, temperature=0.3)\n            return self._parse_final_decision(response)\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤ —Å–∏–Ω—Ç–µ–∑–µ —Ä–µ—à–µ–Ω–∏—è: {str(e)}\")\n            return {\n                \"action\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\",\n                \"category\": original_category,\n                \"confidence\": 3,\n                \"reasoning\": f\"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}\"\n            }\n\n    def _parse_review_response(self, response, review_type):\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–∏–∑\"\"\"\n        result = {\n            \"response\": response,\n            \"recommendation\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\",  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n            \"confidence\": 3\n        }\n        \n        response_lower = response.lower()\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\n        if any(word in response_lower for word in [\"–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ\", \"–Ω–µ–ª–æ–≥–∏—á–Ω–æ\", \"–Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç\", \"–∏–∑–º–µ–Ω–∏—Ç—å\"]):\n            result[\"recommendation\"] = \"–∏–∑–º–µ–Ω–∏—Ç—å\"\n        elif any(word in response_lower for word in [\"–ø—Ä–∞–≤–∏–ª—å–Ω–æ\", \"–ª–æ–≥–∏—á–Ω–æ\", \"—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç\", \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"]):"
  },
  {
    "chunk_id": 25,
    "context_type": "business_logic",
    "size_tokens": 1493,
    "content": "            result[\"recommendation\"] = \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"\n        elif any(word in response_lower for word in [\"—Å–ø–æ—Ä–Ω–æ\", \"–Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ\"]):\n            result[\"recommendation\"] = \"—Å–ø–æ—Ä–Ω–æ\"\n        \n        # –ò—â–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å\n        import re\n        confidence_match = re.search(r'—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å[:\\s]*(\\d+)', response_lower)\n        if confidence_match:\n            result[\"confidence\"] = min(5, max(1, int(confidence_match.group(1))))\n        \n        return result\n\n    def _parse_final_decision(self, response):\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è\"\"\"\n        result = {\n            \"action\": \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\",\n            \"category\": None,\n            \"confidence\": 3,\n            \"reasoning\": \"\"\n        }\n        \n        lines = response.strip().split('\\n')\n        \n        for line in lines:\n            line_clean = line.strip().lower()\n            \n            if line_clean.startswith(\"—Ä–µ—à–µ–Ω–∏–µ:\"):\n                if \"–∏–∑–º–µ–Ω–∏—Ç—å\" in line_clean:\n                    result[\"action\"] = \"–∏–∑–º–µ–Ω–∏—Ç—å\"\n                else:\n                    result[\"action\"] = \"–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å\"\n            \n            elif line_clean.startswith(\"–Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è:\"):\n                category_text = line.split(\":\", 1)[1].strip()\n                # –ù–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n                from config.settings_cop2 import CATEGORIES\n                for cat in CATEGORIES + [\"–¥—Ä—É–≥–æ–µ\"]:\n                    if cat.lower() in category_text.lower():\n                        result[\"category\"] = cat\n                        break\n            \n            elif line_clean.startswith(\"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:\"):\n                import re\n                conf_match = re.search(r'\\d+', line)\n                if conf_match:\n                    result[\"confidence\"] = min(5, max(1, int(conf_match.group())))\n            \n            elif line_clean.startswith(\"–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ:\"):\n                result[\"reasoning\"] = line.split(\":\", 1)[1].strip()\n        \n        return result\n\n    def _apply_review_decision(self, message_id, message, original_category, decision):\n        \"\"\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è –º–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\"\"\"\n        \n        if decision[\"action\"] == \"–∏–∑–º–µ–Ω–∏—Ç—å\" and decision[\"category\"]:\n            new_category = decision[\"category\"]\n            confidence = decision[\"confidence\"]\n            reasoning = decision[\"reasoning\"]\n            \n            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ –ë–î\n            success = self.db_manager.update_message_category(message_id, new_category, confidence)\n            \n            if success:\n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n                self._save_learning_example(message.text, new_category, reasoning)\n                \n                logger.info(f\"–ú–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id} \"\n                        f\"–∏–∑–º–µ–Ω–µ–Ω–∞ —Å '{original_category}' –Ω–∞ '{new_category}' \"\n                        f\"—Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é {confidence}\")\n                \n                return {\n                    \"status\": \"updated\",\n                    \"original_category\": original_category,\n                    \"new_category\": new_category,\n                    \"confidence\": confidence,\n                    \"reasoning\": reasoning,\n                    \"method\": \"multi_perspective_analysis\"\n                }\n            else:\n                logger.error(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}\")\n                return {\"status\": \"error\", \"message\": \"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î\"}\n        \n        else:\n            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n            logger.info(f\"–ú–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑: –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{original_category}' \"\n                    f\"–¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {message_id} –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞\")\n            \n            return {\n                \"status\": \"confirmed\",\n                \"category\": original_category,\n                \"confidence\": decision[\"confidence\"],\n                \"reasoning\": decision[\"reasoning\"],\n                \"method\": \"multi_perspective_analysis\"\n            }\n    \n    def review_recent_categorizations(self, confidence_threshold=3, limit=30, batch_size=5, max_workers=3, start_date=None, end_date=None):\n        \"\"\"\n        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n        \n        Args:\n            confidence_threshold (int): –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é <= —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è\n            limit (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n            batch_size (int): –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n            max_workers (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤\n            \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏\n        \"\"\"\n        logger.info(f\"–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é <= {confidence_threshold}\")\n        \n        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n        messages = self.db_manager.get_messages_with_low_confidence(\n        confidence_threshold=confidence_threshold, \n        limit=limit,\n        start_date=start_date,\n        end_date=end_date\n        )\n        \n        if not messages:\n            logger.info(\"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\")\n            return {\n                \"status\": \"success\",\n                \"total\": 0,\n                \"details\": []\n            }\n        \n        logger.info(f\"–ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\")\n        \n        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞–∫–µ—Ç—ã –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n        batches = [messages[i:i+batch_size] for i in range(0, len(messages), batch_size)]\n        \n        all_results = []\n        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n            future_to_message = {executor.submit(self.review_categorization, msg.id, msg.category): msg for msg_batch in batches for msg in msg_batch}\n            \n            for future in concurrent.futures.as_completed(future_to_message):\n                message = future_to_message[future] # –≠—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∞ –Ω–µ –ø–∞–∫–µ—Ç\n                try:\n                    result = future.result()"
  },
  {
    "chunk_id": 26,
    "context_type": "business_logic",
    "size_tokens": 2295,
    "content": "                    all_results.append(result)\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {message.id}: {str(e)}\")\n        \n        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n        updated = sum(1 for r in all_results if r.get(\"status\") == \"updated\")\n        unchanged = sum(1 for r in all_results if r.get(\"status\") == \"unchanged\")\n        errors = sum(1 for r in all_results if r.get(\"status\") == \"error\")\n        \n        logger.info(f\"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ: {len(messages)}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated}, \"\n                f\"–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {unchanged}, –æ—à–∏–±–æ–∫: {errors}\")\n        \n        return {\n            \"status\": \"success\",\n            \"total\": len(messages),\n            \"updated\": updated,\n            \"unchanged\": unchanged,\n            \"errors\": errors,\n            \"details\": all_results\n        }\n    def _log_multi_perspective_reasoning(self, message_id, message_text, original_category, \n                                   legal_analysis, consistency_analysis, context_analysis, final_decision):\n        \"\"\"–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–Ω–æ–≥–æ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–≥–æ reasoning –∫—Ä–∏—Ç–∏–∫–∞\"\"\"\n        \n        logger.info(\"üîç MULTI-PERSPECTIVE REASONING –ö–†–ò–¢–ò–ö–ê:\")\n        logger.info(f\"   üìù –°–æ–æ–±—â–µ–Ω–∏–µ ID: {message_id}\")\n        logger.info(f\"   üìÑ –¢–µ–∫—Å—Ç: {message_text[:100]}{'...' if len(message_text) > 100 else ''}\")\n        logger.info(f\"   üìÇ –ò—Å—Ö–æ–¥–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {original_category}\")\n        logger.info(\"\")\n        \n        # –≠–¢–ê–ü 1: –ü—Ä–∞–≤–æ–≤–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞\n        logger.info(\"   üèõÔ∏è –≠–¢–ê–ü 1 - –ü–†–ê–í–û–í–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê:\")\n        legal_rec = legal_analysis.get('recommendation', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        legal_conf = legal_analysis.get('confidence', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        logger.info(f\"     –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {legal_rec}\")\n        logger.info(f\"     –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {legal_conf}\")\n        \n        # –≠–¢–ê–ü 2: –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å\n        logger.info(\"   üß† –≠–¢–ê–ü 2 - –õ–û–ì–ò–ß–ï–°–ö–ê–Ø –ö–û–ù–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–¨:\")\n        consistency_rec = consistency_analysis.get('recommendation', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        consistency_conf = consistency_analysis.get('confidence', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        logger.info(f\"     –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {consistency_rec}\")\n        logger.info(f\"     –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {consistency_conf}\")\n        \n        # –≠–¢–ê–ü 3: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n        logger.info(\"   üåê –≠–¢–ê–ü 3 - –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó:\")\n        context_rec = context_analysis.get('recommendation', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        context_conf = context_analysis.get('confidence', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        logger.info(f\"     –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {context_rec}\")\n        logger.info(f\"     –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {context_conf}\")\n        \n        # –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï\n        logger.info(\"   ‚öñÔ∏è –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï:\")\n        action = final_decision.get('action', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        new_category = final_decision.get('category', original_category)\n        final_conf = final_decision.get('confidence', '–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')\n        reasoning = final_decision.get('reasoning', '–Ω–µ—Ç –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è')\n        \n        logger.info(f\"     –î–µ–π—Å—Ç–≤–∏–µ: {action}\")\n        if action == \"–∏–∑–º–µ–Ω–∏—Ç—å\":\n            logger.info(f\"     –ù–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {new_category}\")\n        logger.info(f\"     –§–∏–Ω–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {final_conf}\")\n        logger.info(f\"     –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {reasoning}\")\n        \n        logger.info(\"   \" + \"‚ïê\" * 60)\n    \n\n=== period_command.py ===\n\"\"\"\n–£–ª—É—á—à–µ–Ω–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /period –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥,\n–≤–∫–ª—é—á–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ \"—Å–µ–≥–æ–¥–Ω—è\" –∏ \"–≤—á–µ—Ä–∞\"\n\"\"\"\nimport logging\nimport re\nfrom datetime import time, datetime, timedelta\nimport asyncio\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import ContextTypes\n\nfrom agents.data_collector import DataCollectorAgent # Already imported\nfrom agents.analyzer import AnalyzerAgent # Already imported\nfrom agents.critic import CriticAgent # Already imported\nfrom agents.digester import DigesterAgent # Already imported\nfrom llm.qwen_model import QwenLLM # Added missing import\nfrom llm.gemma_model import GemmaLLM # Added missing import\nfrom utils.text_utils import TextUtils # Added missing import\n\nlogger = logging.getLogger(__name__)\n\n# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º\nutils = TextUtils() # Instantiate TextUtils\n\nasync def period_command(update: Update, context: ContextTypes.DEFAULT_TYPE, db_manager):\n    \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /period - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥\"\"\"\n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã\n    if not context.args:\n        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –∫–æ–º–∞–Ω–¥—ã\n        await update.message.reply_text(\n            \"–ö–æ–º–∞–Ω–¥–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\\n\\n\"\n            \"–§–æ—Ä–º–∞—Ç—ã:\\n\"\n            \"‚Ä¢ /period —Å–µ–≥–æ–¥–Ω—è - –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —Å–µ–≥–æ–¥–Ω—è\\n\"\n            \"‚Ä¢ /period –≤—á–µ—Ä–∞ - –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å\\n\"\n            \"‚Ä¢ /period YYYY-MM-DD - –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É\\n\"\n            \"‚Ä¢ /period YYYY-MM-DD YYYY-MM-DD - –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –ø–µ—Ä–∏–æ–¥\\n\\n\"\n            \"–£–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):\\n\"\n            \"‚Ä¢ /period —Å–µ–≥–æ–¥–Ω—è brief - –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)\\n\"\n            \"‚Ä¢ /period –≤—á–µ—Ä–∞ detailed - –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\\n\"\n            \"‚Ä¢ /period 2025-04-01 both - –æ–±–∞ —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\\n\"\n            \"‚Ä¢ /period 2025-04-01 2025-04-10 both - –æ–±–∞ —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\n        )\n        return\n    \n    # –†–∞–∑–±–∏—Ä–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã\n    digest_type = \"brief\"  # –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n    force_update = False   # –§–ª–∞–≥ –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n    today = datetime.now().date()\n    is_today_request = False  # –§–ª–∞–≥ –∑–∞–ø—Ä–æ—Å–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞\n    if context.args[0].lower() in [\"—Å–µ–≥–æ–¥–Ω—è\", \"today\"]:\n        start_date = datetime.combine(today, time.min)\n        end_date = datetime.now()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n        start_date_str = today.strftime(\"%Y-%m-%d\")\n        end_date_str = end_date.strftime(\"%Y-%m-%d %H:%M\")\n        period_description = f\"–∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–æ {end_date.strftime('%H:%M')})\"\n        is_today_request = True\n        force_update = True  # –í—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        if len(context.args) > 1:\n            digest_type_arg = context.args[1].lower()\n            if digest_type_arg in [\"detailed\", \"full\", \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\", \"–ø–æ–ª–Ω—ã–π\"]:\n                digest_type = \"detailed\"\n            elif digest_type_arg in [\"both\", \"–æ–±–∞\"]:\n                digest_type = \"both\"\n    \n    elif context.args[0].lower() in [\"–≤—á–µ—Ä–∞\", \"yesterday\"]:\n        yesterday = today - timedelta(days=1)\n        start_date = datetime.combine(yesterday, time.min)\n        end_date = datetime.combine(yesterday, time.max)\n        start_date_str = end_date_str = yesterday.strftime(\"%Y-%m-%d\")\n        period_description = \"–∑–∞ –≤—á–µ—Ä–∞\"\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∫–∞–∑–∞–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        if len(context.args) > 1:\n            digest_type_arg = context.args[1].lower()\n            if digest_type_arg in [\"detailed\", \"full\", \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\", \"–ø–æ–ª–Ω—ã–π\"]:\n                digest_type = \"detailed\"\n            elif digest_type_arg in [\"both\", \"–æ–±–∞\"]:\n                digest_type = \"both\"\n    \n    else:\n        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤–≤–æ–¥–∞ —Å –¥–∞—Ç–∞–º–∏\n        if len(context.args) == 1:\n            # –û–¥–∏–Ω –∞—Ä–≥—É–º–µ–Ω—Ç - —Ç–æ–ª—å–∫–æ –¥–∞—Ç–∞\n            try:\n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ç–æ –ø–µ—Ä–∏–æ–¥ –≤ –æ–¥–Ω–æ–º –∞—Ä–≥—É–º–µ–Ω—Ç–µ —á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å\n                if \"-\" in context.args[0] and len(context.args[0].split(\"-\")) > 3:\n                    # –§–æ—Ä–º–∞—Ç: 2025-04-01-2025-04-10\n                    date_parts = context.args[0].split(\"-\")\n                    if len(date_parts) >= 6:\n                        start_date_str = f\"{date_parts[0]}-{date_parts[1]}-{date_parts[2]}\"\n                        end_date_str = f\"{date_parts[3]}-{date_parts[4]}-{date_parts[5]}\"\n                        start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n                        end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n                        period_description = f\"–∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {start_date_str} –ø–æ {end_date_str}\"\n                    else:\n                        raise ValueError(\"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–µ—Ä–∏–æ–¥–∞\")\n                else:\n                    # –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –¥–∞—Ç–∞\n                    start_date_str = end_date_str = context.args[0]\n                    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n                    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n                    period_description = f\"–∑–∞ {start_date_str}\"\n                    \n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ \"—Å–µ–≥–æ–¥–Ω—è\" –ª–∏ —ç—Ç–æ\n                    if start_date.date() == today:\n                        is_today_request = True\n                        end_date = datetime.now()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n                        period_description = f\"–∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–æ {end_date.strftime('%H:%M')})\"\n                        force_update = True\n            except Exception as e:\n                await update.message.reply_text(\n                    f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ –¥–∞—Ç—ã: {str(e)}\\n\"\n                    f\"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ '—Å–µ–≥–æ–¥–Ω—è'/'–≤—á–µ—Ä–∞'\"\n                )\n                return\n        elif len(context.args) == 2:"
  },
  {
    "chunk_id": 27,
    "context_type": "business_logic",
    "size_tokens": 1491,
    "content": "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—Ç–æ—Ä–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç —ç—Ç–æ —Ç–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            if context.args[1].lower() in [\"brief\", \"detailed\", \"both\", \"–∫—Ä–∞—Ç–∫–∏–π\", \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\", \"–æ–±–∞\"]:\n                start_date_str = end_date_str = context.args[0]\n                start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n                end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n                period_description = f\"–∑–∞ {start_date_str}\"\n                \n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ \"—Å–µ–≥–æ–¥–Ω—è\" –ª–∏ —ç—Ç–æ\n                if start_date.date() == today:\n                    is_today_request = True\n                    end_date = datetime.now()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n                    period_description = f\"–∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–æ {end_date.strftime('%H:%M')})\"\n                    force_update = True\n                \n                digest_type_arg = context.args[1].lower()\n                if digest_type_arg in [\"detailed\", \"full\", \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\", \"–ø–æ–ª–Ω—ã–π\"]:\n                    digest_type = \"detailed\"\n                elif digest_type_arg in [\"both\", \"–æ–±–∞\"]:\n                    digest_type = \"both\"\n            else:\n                # –î–≤–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ - –Ω–∞—á–∞–ª—å–Ω–∞—è –∏ –∫–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç—ã\n                start_date_str = context.args[0]\n                end_date_str = context.args[1]\n                start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n                end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n                period_description = f\"–∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {start_date_str} –ø–æ {end_date_str}\"\n                \n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–µ—Ä–∏–æ–¥ —Ç–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å\n                if start_date.date() == today and end_date.date() == today:\n                    is_today_request = True\n                    end_date = datetime.now()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n                    period_description = f\"–∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–æ {end_date.strftime('%H:%M')})\"\n                    force_update = True\n        elif len(context.args) >= 3:\n            # –¢—Ä–∏ –∏ –±–æ–ª–µ–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ - –¥–∞—Ç—ã –∏ —Ç–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            start_date_str = context.args[0]\n            end_date_str = context.args[1]\n            start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n            end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n            period_description = f\"–∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {start_date_str} –ø–æ {end_date_str}\"\n            \n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–µ—Ä–∏–æ–¥ —Ç–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å\n            if start_date.date() == today and end_date.date() == today:\n                is_today_request = True\n                end_date = datetime.now()  # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n                period_description = f\"–∑–∞ —Å–µ–≥–æ–¥–Ω—è (–¥–æ {end_date.strftime('%H:%M')})\"\n                force_update = True\n            \n            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            digest_type_arg = context.args[2].lower()\n            if digest_type_arg in [\"detailed\", \"full\", \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\", \"–ø–æ–ª–Ω—ã–π\"]:\n                digest_type = \"detailed\"\n            elif digest_type_arg in [\"both\", \"–æ–±–∞\"]:\n                digest_type = \"both\"\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç\n        try:\n            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤—ã—à–µ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É\n            if not isinstance(start_date, datetime) or not isinstance(end_date, datetime):\n                raise ValueError(\"–î–∞—Ç—ã –Ω–µ –±—ã–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã\")\n        except ValueError:\n            await update.message.reply_text(\n                \"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2025-04-01) \"\n                \"–∏–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ '—Å–µ–≥–æ–¥–Ω—è'/'–≤—á–µ—Ä–∞'.\"\n            )\n            return\n    \n    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –Ω–µ –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π\n    if start_date > end_date:\n        await update.message.reply_text(\n            \"–û—à–∏–±–∫–∞: –Ω–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥.\"\n        )\n        return\n    \n    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –≤ –ø–µ—Ä–∏–æ–¥–µ\n    days_in_period = (end_date.date() - start_date.date()).days + 1\n    \n    if days_in_period > 60:\n        await update.message.reply_text(\n            f\"–£–∫–∞–∑–∞–Ω —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ ({days_in_period} –¥–Ω–µ–π). \"\n            f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ - 60 –¥–Ω–µ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥.\"\n        )\n        return\n    \n    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n    status_message = await update.message.reply_text(\n        f\"–ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ {get_digest_type_name(digest_type)} –¥–∞–π–¥–∂–µ—Å—Ç–∞ {period_description}.\\n\\n\"\n        f\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö... ‚è≥\"\n    )\n    \n    # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥\n    try:\n        existing_digests = None\n        # –î–ª—è –∑–∞–ø—Ä–æ—Å–∞ \"–∑–∞ —Å–µ–≥–æ–¥–Ω—è\" –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–æ–±—É—é –ª–æ–≥–∏–∫—É\n        # –î–ª—è –∑–∞–ø—Ä–æ—Å–∞ \"–∑–∞ —Å–µ–≥–æ–¥–Ω—è\" –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–æ–±—É—é –ª–æ–≥–∏–∫—É\n        if is_today_request:\n            # –ò—â–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —Å–µ–≥–æ–¥–Ω—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ —Å is_today=True\n            today_digests = db_manager.find_digests_by_parameters(\n                is_today=True,\n                limit=10\n            )\n            \n            if not today_digests:\n                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ is_today, –∏—â–µ–º –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω—É –¥–∞—Ç\n                today_start = datetime.combine(today, time.min)\n                today_end = datetime.combine(today, time.max)\n                \n                today_digests = db_manager.find_digests_by_parameters(\n                    date_range_start=today_start,\n                    date_range_end=today_end,\n                    digest_type=digest_type if digest_type != \"both\" else None,\n                    limit=10\n                )\n            \n            if today_digests:\n                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –∏ –Ω–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ —Ä–∞–Ω–Ω–∏–µ\n                unique_digests = {}\n                for d in today_digests:\n                    d_type = d[\"digest_type\"]\n                    if d_type not in unique_digests or d[\"id\"] < unique_digests[d_type][\"id\"]:"
  },
  {
    "chunk_id": 28,
    "context_type": "business_logic",
    "size_tokens": 1491,
    "content": "                        unique_digests[d_type] = d\n                \n                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç\n                target_digest = None\n                target_id = None\n                \n                if digest_type == \"both\":\n                    # –î–ª—è —Ç–∏–ø–∞ \"both\" –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞ —Ç–∏–ø–∞, –Ω–∞—á–∏–Ω–∞—è —Å \"brief\"\n                    if \"brief\" in unique_digests:\n                        target_digest = unique_digests[\"brief\"]\n                        target_id = target_digest[\"id\"]\n                    elif \"detailed\" in unique_digests:\n                        target_digest = unique_digests[\"detailed\"]\n                        target_id = target_digest[\"id\"]\n                elif digest_type in unique_digests:\n                    target_digest = unique_digests[digest_type]\n                    target_id = target_digest[\"id\"]\n                \n                if target_digest and target_id:\n                    digest = db_manager.get_digest_by_id_with_sections(target_id)\n                    \n                    if digest:\n                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                        last_updated = digest.get(\"last_updated\", today_start)\n                        current_time = datetime.now()\n                        \n                        # –ï—Å–ª–∏ –ø—Ä–æ—à–ª–æ –º–µ–Ω–µ–µ 5 –º–∏–Ω—É—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç\n                        if (current_time - last_updated).total_seconds() < 300:  # 5 –º–∏–Ω—É—Ç\n                            await status_message.edit_text(\n                                f\"{status_message.text}\\n\"\n                                f\"‚úÖ –ù–∞–π–¥–µ–Ω –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç {period_description}. –û—Ç–ø—Ä–∞–≤–ª—è—é...\"\n                            )\n                            \n                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\n                            safe_text = utils.clean_markdown_text(digest[\"text\"])\n                            chunks = utils.split_text(safe_text)\n                            \n                            for i, chunk in enumerate(chunks):\n                                if i == 0:\n                                    text_html = utils.convert_to_html(chunk)\n                                    await update.message.reply_text(\n                                        f\"{get_digest_type_name(digest['digest_type']).capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç {period_description}:\\n\\n{text_html}\",\n                                        parse_mode='HTML'\n                                    )\n                                else:\n                                    await update.message.reply_text(utils.convert_to_html(chunk), parse_mode='HTML')\n                            \n                            return\n                        else:\n                            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å –¥–∞–Ω–Ω—ã–º–∏ —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                            await status_message.edit_text(\n                                f\"{status_message.text}\\n\"\n                                f\"üîÑ –û–±–Ω–æ–≤–ª—è—é —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —Å–µ–≥–æ–¥–Ω—è (ID: {target_id}, –ø–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {last_updated.strftime('%H:%M')})...\"\n                            )\n                            \n                            # –ú–µ–Ω—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –¥–∞—Ç—É –¥–ª—è —Å–±–æ—Ä–∞ —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n                            start_date = last_updated\n                            force_update = True  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º\n                            \n                            # –í–∞–∂–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                            digest_id = target_id\n                else:\n                    # –ï—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–π\n                    await status_message.edit_text(\n                        f\"{status_message.text}\\n\"\n                        f\"üÜï –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç {period_description}...\"\n                    )\n            else:\n                # –ï—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–π\n                await status_message.edit_text(\n                    f\"{status_message.text}\\n\"\n                    f\"üÜï –°–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –¥–∞–π–¥–∂–µ—Å—Ç {period_description}...\"\n                )\n        else:\n            # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ª–æ–≥–∏–∫—É\n            existing_digests = db_manager.find_digests_by_parameters(\n                date_range_start=start_date,\n                date_range_end=end_date,\n                digest_type=digest_type if digest_type != \"both\" else None,\n                limit=1\n            )\n            \n            if existing_digests:\n                digest_id = existing_digests[0]['id']\n                digest = db_manager.get_digest_by_id_with_sections(digest_id)\n                \n                if digest and not force_update:\n                    await status_message.edit_text(\n                        f\"{status_message.text}\\n\"\n                        f\"‚úÖ –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç {period_description}. –û—Ç–ø—Ä–∞–≤–ª—è—é...\"\n                    )\n                    \n                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\n                    safe_text = utils.clean_markdown_text(digest[\"text\"])\n                    chunks = utils.split_text(safe_text)\n                    \n                    for i, chunk in enumerate(chunks):\n                        if i == 0:\n                            text_html = utils.convert_to_html(chunk)\n                            await update.message.reply_text(\n                                f\"{get_digest_type_name(digest['digest_type']).capitalize()} –¥–∞–π–¥–∂–µ—Å—Ç {period_description}:\\n\\n{text_html}\",\n                                parse_mode='HTML'\n                            )\n                        else:\n                            await update.message.reply_text(utils.convert_to_html(chunk), parse_mode='HTML')\n                    \n                    return\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {str(e)}\")\n    \n    # –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥\n    try:\n        collector = DataCollectorAgent(db_manager)\n        "
  },
  {
    "chunk_id": 29,
    "context_type": "business_logic",
    "size_tokens": 1492,
    "content": "        days_back_value = (end_date.date() - start_date.date()).days + 1\n         # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º\n        collect_result = await collector.collect_data(\n            days_back=days_back_value,\n            force_update=True,  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n            start_date=start_date,\n            end_date=end_date\n        )\n        \n        total_messages = collect_result.get(\"total_new_messages\", 0)\n        \n        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å\n        await status_message.edit_text(\n            f\"{status_message.text}\\n\"\n            f\"‚úÖ –°–æ–±—Ä–∞–Ω–æ {total_messages} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–æ–≤\"\n        )\n        \n        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ —Å –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–º –ø–æ–∏—Å–∫–æ–º\n        if total_messages == 0:\n            existing_messages = db_manager.get_messages_by_date_range(\n                start_date=start_date,\n                end_date=end_date\n            )\n            \n            if not existing_messages:\n                # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∑–∞ —Å–µ–≥–æ–¥–Ω—è –∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ –∏—Ö –ø—Ä–æ—Å—Ç–æ –Ω–µ –±—ã–ª–æ —Å –ø—Ä–æ—à–ª–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                if is_today_request:\n                    # –†–∞—Å—à–∏—Ä—è–µ–º –ø–µ—Ä–∏–æ–¥ –¥–æ –Ω–∞—á–∞–ª–∞ –¥–Ω—è\n                    day_start = datetime.combine(today, time.min)\n                    await status_message.edit_text(\n                        f\"{status_message.text}\\n\"\n                        f\"üìÖ –†–∞—Å—à–∏—Ä—è—é –ø–æ–∏—Å–∫ –Ω–∞ –≤–µ—Å—å —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å...\"\n                    )\n                    \n                    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n                    all_today_messages = db_manager.get_messages_by_date_range(\n                        start_date=day_start,\n                        end_date=end_date\n                    )\n                    \n                    if all_today_messages:\n                        await status_message.edit_text(\n                            f\"{status_message.text}\\n\"\n                            f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_today_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è\"\n                        )\n                        start_date = day_start\n                        existing_messages = all_today_messages\n                    else:\n                        await status_message.edit_text(\n                            f\"{status_message.text}\\n\"\n                            f\"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è. –í—ã–ø–æ–ª–Ω—è—é –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫... üîç\"\n                        )\n                        \n                        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫ –¥–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è\n                        for channel in collect_result.get(\"channels_stats\", {}).keys():\n                            deep_result = await collector.collect_deep_history(\n                                channel,\n                                day_start,\n                                end_date\n                            )\n                            \n                            if deep_result.get(\"status\") == \"success\":\n                                saved_count = deep_result.get(\"saved_count\", 0)\n                                total_messages += saved_count\n                                await status_message.edit_text(\n                                    f\"{status_message.text}\\n\"\n                                    f\"üì• –ö–∞–Ω–∞–ª {channel}: —Å–æ–±—Ä–∞–Ω–æ {saved_count} —Å–æ–æ–±—â–µ–Ω–∏–π –≥–ª—É–±–æ–∫–∏–º –ø–æ–∏—Å–∫–æ–º\"\n                                )\n                        \n                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞\n                        existing_messages = db_manager.get_messages_by_date_range(\n                            start_date=day_start,\n                            end_date=end_date\n                        )\n                else:\n                    await status_message.edit_text(\n                        f\"{status_message.text}\\n\"\n                        f\"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π {period_description}. –í—ã–ø–æ–ª–Ω—è—é –≥–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫... üîç\"\n                    )\n                    \n                    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –≥–ª—É–±–æ–∫–∏–π —Å–±–æ—Ä\n                    for channel in collect_result.get(\"channels_stats\", {}).keys():\n                        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª—É–±–æ–∫–∏–π —Å–±–æ—Ä –∏—Å—Ç–æ—Ä–∏–∏\n                        deep_result = await collector.collect_deep_history(\n                            channel,\n                            start_date,\n                            end_date\n                        )\n                        \n                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É\n                        if deep_result.get(\"status\") == \"success\":\n                            saved_count = deep_result.get(\"saved_count\", 0)\n                            total_messages += saved_count\n                            await status_message.edit_text(\n                                f\"{status_message.text}\\n\"\n                                f\"üì• –ö–∞–Ω–∞–ª {channel}: —Å–æ–±—Ä–∞–Ω–æ {saved_count} —Å–æ–æ–±—â–µ–Ω–∏–π –≥–ª—É–±–æ–∫–∏–º –ø–æ–∏—Å–∫–æ–º\"\n                            )\n                \n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –Ω–∞–ª–∏—á–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π\n                if not existing_messages:\n                    existing_messages = db_manager.get_messages_by_date_range(\n                        start_date=start_date,\n                        end_date=end_date\n                    )\n                    \n                    if not existing_messages:\n                        await status_message.edit_text(\n                            f\"{status_message.text}\\n\"\n                            f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {period_description} –¥–∞–∂–µ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º –ø–æ–∏—Å–∫–µ.\"\n                        )\n                        return\n            else:\n                total_messages = len(existing_messages)\n                await status_message.edit_text(\n                    f\"{status_message.text}\\n\"\n                    f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {total_messages} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π {period_description}\"\n                )\n        \n        # –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π\n        await status_message.edit_text(\n            f\"{status_message.text}\\n\"\n            f\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É—é —Å–æ–æ–±—â–µ–Ω–∏—è... üß†\"\n        )\n        \n        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ–∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"
  },
  {
    "chunk_id": 30,
    "context_type": "business_logic",
    "size_tokens": 1449,
    "content": "        unanalyzed_messages = db_manager.get_unanalyzed_messages(limit=total_messages)\n        \n        if unanalyzed_messages:\n            # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é\n            analyzer = AnalyzerAgent(db_manager, QwenLLM())\n            analyzer.fast_check = True  # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏\n            \n            analyze_result = analyzer.analyze_messages( # Changed to analyze_messages\n                limit=len(unanalyzed_messages),\n                batch_size=10\n            )\n            \n            analyzed_count = analyze_result.get(\"analyzed_count\", 0)\n            \n            await status_message.edit_text(\n                f\"{status_message.text}\\n\"\n                f\"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {analyzed_count} —Å–æ–æ–±—â–µ–Ω–∏–π\"\n            )\n            \n            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n            critic = CriticAgent(db_manager)\n            review_result = critic.review_recent_categorizations(\n                confidence_threshold=2,\n                limit=min(30, analyzed_count),\n                start_date=start_date,\n                end_date=end_date\n            )\n            \n            if review_result.get(\"updated\", 0) > 0:\n                await status_message.edit_text(\n                    f\"{status_message.text}\\n\"\n                    f\"‚úÖ –£–ª—É—á—à–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è {review_result.get('updated', 0)} —Å–æ–æ–±—â–µ–Ω–∏–π\"\n                )\n        \n        # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        await status_message.edit_text(\n            f\"{status_message.text}\\n\"\n            f\"–§–æ—Ä–º–∏—Ä—É—é –¥–∞–π–¥–∂–µ—Å—Ç... üìù\"\n        )\n        \n        # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        digester = DigesterAgent(db_manager, GemmaLLM())\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π digest_id –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n        digest_id = None\n        if existing_digests:\n            digest_id = existing_digests[0]['id']\n            \n        # –°–æ–∑–¥–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º digest_id –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ\n        digest_result = digester.create_digest(\n            date=end_date,\n            days_back=days_in_period,\n            digest_type=digest_type,\n            update_existing=True,\n            digest_id=digest_id\n        )\n        \n        # –ü–æ–ª—É—á–∞–µ–º ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞\n        digest_ids = []\n        messages = []\n\n        if digest_type == \"brief\" and \"brief_digest_id\" in digest_result:\n            digest_ids.append((\"brief\", digest_result[\"brief_digest_id\"]))\n            messages.append(f\"–ö—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (ID: {digest_result['brief_digest_id']})\")\n\n        elif digest_type == \"detailed\" and \"detailed_digest_id\" in digest_result:\n            digest_ids.append((\"detailed\", digest_result[\"detailed_digest_id\"]))\n            messages.append(f\"–ü–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç (ID: {digest_result['detailed_digest_id']})\")\n\n        elif digest_type == \"both\":\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ç–∏–ø—ã –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã\n            if \"brief_digest_id\" in digest_result:\n                digest_ids.append((\"brief\", digest_result[\"brief_digest_id\"]))\n                messages.append(f\"–ö—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (ID: {digest_result['brief_digest_id']})\")\n            \n            if \"detailed_digest_id\" in digest_result:\n                digest_ids.append((\"detailed\", digest_result[\"detailed_digest_id\"]))\n                messages.append(f\"–ü–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç (ID: {digest_result['detailed_digest_id']})\")\n\n        if not digest_ids:\n            await status_message.edit_text(\n                f\"{status_message.text}\\n\"\n                f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç —Ç–∏–ø–∞ {digest_type} {period_description}.\"\n            )\n            return\n\n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –ë–î\n        db_ids = {}\n        for dtype, did in digest_ids:\n            db_ids[dtype] = did\n\n        db_manager.save_digest_generation(\n            source=\"bot\",\n            user_id=update.effective_user.id,\n            channels=list(collect_result.get(\"channels_stats\", {}).keys()), # Convert dict_keys to list\n            messages_count=total_messages,\n            digest_ids=db_ids,\n            start_date=start_date,\n            end_date=end_date,\n            focus_category=None  # Assuming focus_category is not defined in the current context\n        )\n\n        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å —É—Å–ø–µ—à–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º\n        status_text = f\"{status_message.text}\\n‚úÖ –î–∞–π–¥–∂–µ—Å—Ç(—ã) —É—Å–ø–µ—à–Ω–æ\"\n        if is_today_request and existing_digests:\n            status_text += \" –æ–±–Ω–æ–≤–ª–µ–Ω(—ã)!\"\n        else:\n            status_text += \" —Å–æ–∑–¥–∞–Ω(—ã)!\"\n\n        status_text += f\"\\n\\n–°–æ–∑–¥–∞–Ω–æ: {', '.join(messages)}\"\n        await status_message.edit_text(status_text)\n\n        # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        keyboard = []\n        for dtype, did in digest_ids:\n            label = \"üìã –ö—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç\" if dtype == \"brief\" else \"üìö –ü–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç\"\n            keyboard.append([InlineKeyboardButton(label, callback_data=f\"view_digest_{did}\")])\n\n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        keyboard.append([InlineKeyboardButton(\"üìã –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\", callback_data=\"show_digests_list\")])\n\n        reply_markup = InlineKeyboardMarkup(keyboard)\n    except Exception as e:\n        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ {period_description}: {str(e)}\", exc_info=True)\n        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏\n        await update.message.reply_text(\n            f\"–î–∞–π–¥–∂–µ—Å—Ç {period_description} –≥–æ—Ç–æ–≤ –∫ –ø—Ä–æ—Å–º–æ—Ç—Ä—É. –í—ã–±–µ—Ä–∏—Ç–µ –æ–ø—Ü–∏—é:\",\n            reply_markup=reply_markup\n        )\ndef get_digest_type_name(digest_type):\n    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\"\"\"\n    if digest_type == \"brief\":\n        return \"–∫—Ä–∞—Ç–∫–∏–π\"\n    elif digest_type == \"detailed\":\n        return \"–ø–æ–¥—Ä–æ–±–Ω—ã–π\"\n    elif digest_type == \"both\":\n        return \"–ø–æ–ª–Ω—ã–π\"\n    else:\n        return digest_type\n"
  },
  {
    "chunk_id": 31,
    "context_type": "business_logic",
    "size_tokens": 1497,
    "content": "=== data_collector.py ===\n\"\"\"\n–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram-–∫–∞–Ω–∞–ª–æ–≤\n—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–ª—É–±–æ–∫–æ–≥–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ —Å–±–æ—Ä–∞\n\"\"\"\nimport logging\nimport asyncio\nfrom datetime import datetime, timedelta\nimport random\nimport time\nfrom telethon import TelegramClient\nfrom telethon.tl.functions.messages import GetHistoryRequest\nfrom telethon.errors import FloodWaitError, SlowModeWaitError\nfrom langchain.tools import Tool\nfrom crewai import Agent, Task\n\nfrom config.settings_cop2 import TELEGRAM_API_ID, TELEGRAM_API_HASH, TELEGRAM_CHANNELS\nfrom utils.telegram_session_manager import TelegramSessionManager\n\nlogger = logging.getLogger(__name__) # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç datetime\n\nclass DataCollectorAgent:\n    \"\"\"–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram-–∫–∞–Ω–∞–ª–æ–≤\"\"\"\n    \n    def __init__(self, db_manager, api_id=None, api_hash=None):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\n        \n        Args:\n            db_manager (DatabaseManager): –ú–µ–Ω–µ–¥–∂–µ—Ä –ë–î\n            api_id (str, optional): Telegram API ID\n            api_hash (str, optional): Telegram API Hash\n        \"\"\"\n        self.db_manager = db_manager\n        self.api_id = api_id or TELEGRAM_API_ID\n        self.api_hash = api_hash or TELEGRAM_API_HASH\n        self.client = None\n        \n        # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        collect_data_tool = Tool(\n            name=\"collect_data\",\n            func=self.collect_data,\n            description=\"–°–æ–±–∏—Ä–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã—Ö Telegram-–∫–∞–Ω–∞–ª–æ–≤\"\n        )\n        \n        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ CrewAI\n        self.agent = Agent(\n            name=\"Data Collector\",\n            role=\"–°–±–æ—Ä—â–∏–∫ –¥–∞–Ω–Ω—ã—Ö\",\n            goal=\"–°–æ–±–∏—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã—Ö Telegram-–∫–∞–Ω–∞–ª–æ–≤\",\n            backstory=\"–Ø —Å–æ–±–∏—Ä–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞.\",\n            verbose=True,\n            tools=[collect_data_tool]\n        )\n    \n    async def _init_client(self):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Telegram —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–µ—Å—Å–∏–π\"\"\"\n        if not self.client:\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞\n            session_manager = TelegramSessionManager(self.api_id, self.api_hash)\n            self.client = await session_manager.get_client()\n            self.session_manager = session_manager  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –º–µ–Ω–µ–¥–∂–µ—Ä\n    \n    async def _release_client(self):\n        \"\"\"–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\"\"\"\n        if hasattr(self, 'session_manager') and hasattr(self, 'client') and self.client:\n            await self.session_manager.release_client(self.client)\n            self.client = None\n\n    async def get_historical_messages(self, client, channel, start_date, end_date, max_messages=1000):\n        \"\"\"\n        –£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–±–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞—Ç-—è–∫–æ—Ä–µ–π\n        –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø–∞–≥–∏–Ω–∞—Ü–∏–∏\n        \n        Args:\n            client (TelegramClient): –ö–ª–∏–µ–Ω—Ç Telegram\n            channel (str): –ò–º—è –∫–∞–Ω–∞–ª–∞\n            start_date (datetime): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)\n            end_date (datetime): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)\n            max_messages (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–±–æ—Ä–∞\n            \n        Returns:\n            list: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π\n        \"\"\"\n        try:\n            entity = await client.get_entity(channel)\n            logger.info(f\"–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ {channel} —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}\")\n            \n            # –î–ª—è –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ø–æ–¥–ø–µ—Ä–∏–æ–¥—ã\n            total_days = (end_date - start_date).days\n            \n            if total_days > 30:\n                logger.info(f\"–î–ª–∏–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ ({total_days} –¥–Ω–µ–π), —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–æ–¥–ø–µ—Ä–∏–æ–¥—ã\")\n                return await self._get_messages_by_chunks(client, entity, channel, start_date, end_date, max_messages)\n            \n            # –î–ª—è –ø–µ—Ä–∏–æ–¥–æ–≤ —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏–Ω—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å —Å–º–µ—â–µ–Ω–∏–µ–º –¥–∞—Ç\n            all_messages = []\n            offset_id = 0\n            limit = 100  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n            \n            # –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–æ–Ω—Ü–∞ –ø–µ—Ä–∏–æ–¥–∞ –∏ –¥–≤–∏–≥–∞–µ–º—Å—è –Ω–∞–∑–∞–¥\n            current_offset_date = end_date\n            \n            # –î–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤\n            max_iterations = 50  # –£–≤–µ–ª–∏—á–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\n            \n            for iteration in range(max_iterations):\n                try:\n                    logger.debug(f\"–ó–∞–ø—Ä–æ—Å #{iteration+1}: channel={channel}, offset_date={current_offset_date.strftime('%Y-%m-%d %H:%M')}, offset_id={offset_id}\")\n                    \n                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º GetHistoryRequest –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —Å–º–µ—â–µ–Ω–∏–µ–º\n                    messages = await client(GetHistoryRequest(\n                        peer=entity,\n                        limit=limit,\n                        offset_date=current_offset_date,\n                        offset_id=offset_id,\n                        max_id=0,\n                        min_id=0,\n                        add_offset=0,\n                        hash=0\n                    ))\n                    \n                    if not messages.messages:\n                        logger.debug(f\"–ë–æ–ª—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ—Ç, –∑–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä\")\n                        break\n                    \n                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–∞—Ç–∞–º\n                    filtered_batch = []\n                    reached_start_date = False\n                    \n                    for msg in messages.messages:\n                        msg_date = msg.date.replace(tzinfo=None)\n                        \n                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Ö–æ–¥–∏—Ç –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –Ω–∞—à –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç\n                        if start_date <= msg_date <= end_date:\n                            filtered_batch.append(msg)\n                        \n                        # –ï—Å–ª–∏ –¥–∞—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Ä–∞–Ω—å—à–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã, –æ—Ç–º–µ—á–∞–µ–º —ç—Ç–æ"
  },
  {
    "chunk_id": 32,
    "context_type": "business_logic",
    "size_tokens": 1493,
    "content": "                        if msg_date < start_date:\n                            reached_start_date = True\n                    \n                    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n                    if messages.messages:\n                        first_date = messages.messages[0].date.replace(tzinfo=None)\n                        last_date = messages.messages[-1].date.replace(tzinfo=None)\n                        logger.debug(f\"–ü–æ–ª—É—á–µ–Ω–æ {len(messages.messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, –¥–∞—Ç—ã: {first_date.strftime('%Y-%m-%d')} - {last_date.strftime('%Y-%m-%d')}\")\n                        logger.debug(f\"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(filtered_batch)} —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–∞—Ç\")\n                    \n                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫ –æ–±—â–µ–º—É —Å–ø–∏—Å–∫—É\n                    all_messages.extend(filtered_batch)\n                    \n                    # –ï—Å–ª–∏ –º—ã –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–∞—á–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã –∏–ª–∏ —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π, –∑–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä\n                    if reached_start_date or len(all_messages) >= max_messages:\n                        logger.info(f\"–ó–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä: reached_start_date={reached_start_date}, total_messages={len(all_messages)}\")\n                        break\n                    \n                    # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π, —á–µ–º –∑–∞–ø—Ä–æ—Å–∏–ª–∏, –∑–Ω–∞—á–∏—Ç –¥–æ—Å—Ç–∏–≥–ª–∏ –∫–æ–Ω—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏\n                    if len(messages.messages) < limit:\n                        logger.debug(f\"–ü–æ–ª—É—á–µ–Ω–æ –º–µ–Ω—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π ({len(messages.messages)}) —á–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–æ ({limit}), –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü –∏—Å—Ç–æ—Ä–∏–∏\")\n                        break\n                    \n                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    if messages.messages:\n                        current_offset_date = messages.messages[-1].date\n                        offset_id = messages.messages[-1].id\n                    else:\n                        break\n                    \n                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –ø–∞—É–∑—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API\n                    delay = 1 + random.random()  # 1-2 —Å–µ–∫—É–Ω–¥—ã\n                    await asyncio.sleep(delay)\n                    \n                except FloodWaitError as e:\n                    wait_time = e.seconds\n                    logger.warning(f\"–ü–æ–ª—É—á–µ–Ω FloodWaitError, –æ–∂–∏–¥–∞–µ–º {wait_time} —Å–µ–∫—É–Ω–¥\")\n                    await asyncio.sleep(wait_time + 1)  # +1 –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏\n                except SlowModeWaitError as e:\n                    wait_time = e.seconds\n                    logger.warning(f\"–ü–æ–ª—É—á–µ–Ω SlowModeWaitError, –æ–∂–∏–¥–∞–µ–º {wait_time} —Å–µ–∫—É–Ω–¥\")\n                    await asyncio.sleep(wait_time + 1)\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}: {str(e)}\")\n                    # –î–µ–ª–∞–µ–º –ø–∞—É–∑—É –≤ —Å–ª—É—á–∞–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –æ—à–∏–±–∫–∏\n                    await asyncio.sleep(3)\n            \n            logger.info(f\"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n            return all_messages\n        \n        except Exception as e:\n            logger.error(f\"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}: {str(e)}\")\n            return []\n\n    async def _get_messages_by_chunks(self, client, entity, channel, start_date, end_date, max_messages):\n        \"\"\"\n        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –ø—É—Ç–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —á–∞–Ω–∫–∏\n        \"\"\"\n        all_messages = []\n        total_days = (end_date - start_date).days\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–ª–∏–Ω—ã –ø–µ—Ä–∏–æ–¥–∞\n        chunk_size_days = 7  # –ù–µ–¥–µ–ª—è - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤\n        \n        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–∞—Ç-—è–∫–æ—Ä–µ–π\n        anchor_dates = []\n        current_date = start_date\n        while current_date <= end_date:\n            anchor_dates.append(current_date)\n            current_date += timedelta(days=chunk_size_days)\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É, –µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞\n        if anchor_dates[-1] < end_date:\n            anchor_dates.append(end_date)\n        \n        logger.info(f\"–†–∞–∑–±–∏–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥ –Ω–∞ {len(anchor_dates) - 1} —á–∞–Ω–∫–æ–≤ —Å —è–∫–æ—Ä–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏\")\n        \n        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫\n        for i in range(len(anchor_dates) - 1):\n            chunk_start = anchor_dates[i]\n            chunk_end = anchor_dates[i + 1]\n            logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {i+1}/{len(anchor_dates)-1}: {chunk_start.strftime('%Y-%m-%d')} - {chunk_end.strftime('%Y-%m-%d')}\")\n            \n            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞\n            chunk_messages = []\n            offset_id = 0\n            limit = 100\n            \n            # –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–æ–Ω—Ü–∞ —á–∞–Ω–∫–∞\n            current_offset_date = chunk_end\n            \n            # –î–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞\n            max_iterations = 20\n            \n            for iteration in range(max_iterations):\n                try:\n                    logger.debug(f\"–ó–∞–ø—Ä–æ—Å #{iteration+1} –¥–ª—è —á–∞–Ω–∫–∞ {i+1}: offset_date={current_offset_date.strftime('%Y-%m-%d')}\")\n                    \n                    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è\n                    messages = await client(GetHistoryRequest(\n                        peer=entity,\n                        limit=limit,\n                        offset_date=current_offset_date,\n                        offset_id=offset_id,\n                        max_id=0,\n                        min_id=0,\n                        add_offset=0,\n                        hash=0\n                    ))\n                    \n                    if not messages.messages:\n                        break\n                    \n                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è, –≤—Ö–æ–¥—è—â–∏–µ –≤ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫\n                    filtered_messages = []\n                    reached_chunk_start = False\n                    \n                    for msg in messages.messages:\n                        msg_date = msg.date.replace(tzinfo=None)\n                        \n                        if chunk_start <= msg_date <= chunk_end:"
  },
  {
    "chunk_id": 33,
    "context_type": "business_logic",
    "size_tokens": 1477,
    "content": "                            filtered_messages.append(msg)\n                        \n                        if msg_date < chunk_start:\n                            reached_chunk_start = True\n                    \n                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    chunk_messages.extend(filtered_messages)\n                    \n                    # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –Ω–∞—á–∞–ª–∞ —á–∞–Ω–∫–∞ –∏–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–∞–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–π, –∑–∞–≤–µ—Ä—à–∞–µ–º\n                    if reached_chunk_start or len(messages.messages) < limit:\n                        break\n                    \n                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–º–µ—â–µ–Ω–∏–µ\n                    if messages.messages:\n                        current_offset_date = messages.messages[-1].date\n                        offset_id = messages.messages[-1].id\n                    else:\n                        break\n                    \n                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏\n                    await asyncio.sleep(1 + random.random())\n                    \n                except FloodWaitError as e:\n                    wait_time = e.seconds\n                    logger.warning(f\"–ü–æ–ª—É—á–µ–Ω FloodWaitError, –æ–∂–∏–¥–∞–µ–º {wait_time} —Å–µ–∫—É–Ω–¥\")\n                    await asyncio.sleep(wait_time + 1)\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {i+1}: {str(e)}\")\n                    await asyncio.sleep(3)\n            \n            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —á–∞–Ω–∫–∞ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫\n            all_messages.extend(chunk_messages)\n            logger.info(f\"–°–æ–±—Ä–∞–Ω–æ {len(chunk_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —á–∞–Ω–∫–∞ {i+1}\")\n            \n            # –î–µ–ª–∞–µ–º –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—É—é –ø–∞—É–∑—É –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏\n            await asyncio.sleep(3 + random.random() * 2)\n        \n        # –û–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π\n        if len(all_messages) > max_messages:\n            logger.info(f\"–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ {max_messages} (—Å–æ–±—Ä–∞–Ω–æ {len(all_messages)})\")\n            all_messages = all_messages[:max_messages]\n        \n        logger.info(f\"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel} –º–µ—Ç–æ–¥–æ–º —á–∞–Ω–∫–æ–≤\")\n        return all_messages\n\n    async def collect_with_smart_filtering(self, client, channel, start_date, end_date):\n        \"\"\"\n        –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ë–î\n        \n        Args:\n            client (TelegramClient): –ö–ª–∏–µ–Ω—Ç Telegram\n            channel (str): –ò–º—è –∫–∞–Ω–∞–ª–∞\n            start_date (datetime): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞\n            end_date (datetime): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞\n            \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π\n        \"\"\"\n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–±–æ—Ä–∞\n        try:\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –Ω–∞—Å —É–∂–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —ç—Ç–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥\n            existing_messages = self.db_manager.get_messages_by_date_range(\n                start_date=start_date,\n                end_date=end_date,\n                channels=[channel]\n            )\n            \n            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö\n            logger.info(f\"–ù–∞–π–¥–µ–Ω–æ {len(existing_messages)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel} –∑–∞ –ø–µ—Ä–∏–æ–¥\")\n            \n            # –ï—Å–ª–∏ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –¥–∞–Ω–Ω—ã—Ö\n            if existing_messages:\n                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ\n                existing_messages.sort(key=lambda msg: msg.date)\n                \n                # –ù–∞—Ö–æ–¥–∏–º –¥–∞—Ç—ã –ø–µ—Ä–≤–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n                first_date = existing_messages[0].date\n                last_date = existing_messages[-1].date\n                \n                logger.info(f\"–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è: —Å {first_date.strftime('%Y-%m-%d')} –ø–æ {last_date.strftime('%Y-%m-%d')}\")\n                \n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–µ–ª –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞\n                if first_date > start_date:\n                    logger.info(f\"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä–æ–±–µ–ª –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞: —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {first_date.strftime('%Y-%m-%d')}\")\n                    \n                    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ —ç—Ç–æ—Ç –ø—Ä–æ–±–µ–ª\n                    messages = await self.get_historical_messages(client, channel, start_date, first_date)\n                    \n                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    new_count = 0\n                    for msg in messages:\n                        if msg.message:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç\n                            if self.db_manager.save_message(\n                                channel=channel,\n                                message_id=msg.id,\n                                text=msg.message,\n                                date=msg.date.replace(tzinfo=None)\n                            ):\n                                new_count += 1\n                    \n                    logger.info(f\"–ó–∞–ø–æ–ª–Ω–µ–Ω –ø—Ä–æ–±–µ–ª –≤ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–∏–æ–¥–∞: –¥–æ–±–∞–≤–ª–µ–Ω–æ {new_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                \n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–µ–ª –≤ –∫–æ–Ω—Ü–µ –ø–µ—Ä–∏–æ–¥–∞\n                if last_date < end_date:\n                    logger.info(f\"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä–æ–±–µ–ª –≤ –∫–æ–Ω—Ü–µ –ø–µ—Ä–∏–æ–¥–∞: —Å {last_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}\")\n                    \n                    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ —ç—Ç–æ—Ç –ø—Ä–æ–±–µ–ª\n                    messages = await self.get_historical_messages(client, channel, last_date, end_date)\n                    \n                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    new_count = 0\n                    for msg in messages:\n                        if msg.message:\n                            if self.db_manager.save_message(\n                                channel=channel,\n                                message_id=msg.id,\n                                text=msg.message,\n                                date=msg.date.replace(tzinfo=None)\n                            ):\n                                new_count += 1\n                    "
  },
  {
    "chunk_id": 34,
    "context_type": "business_logic",
    "size_tokens": 1495,
    "content": "                    logger.info(f\"–ó–∞–ø–æ–ª–Ω–µ–Ω –ø—Ä–æ–±–µ–ª –≤ –∫–æ–Ω—Ü–µ –ø–µ—Ä–∏–æ–¥–∞: –¥–æ–±–∞–≤–ª–µ–Ω–æ {new_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                \n                # –ò—â–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–Ω—É—Ç—Ä–∏ –ø–µ—Ä–∏–æ–¥–∞ (–±–æ–ª–µ–µ 1 –¥–Ω—è –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏)\n                gaps = []\n                for i in range(1, len(existing_messages)):\n                    prev_date = existing_messages[i-1].date\n                    curr_date = existing_messages[i].date\n                    \n                    # –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –±–æ–ª–µ–µ 1 –¥–Ω—è, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –ø—Ä–æ–±–µ–ª–æ–º\n                    if (curr_date - prev_date).days > 1:\n                        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª —Å –∑–∞–ø–∞—Å–æ–º –≤ 1 —á–∞—Å\n                        gap_start = prev_date + timedelta(hours=1)\n                        gap_end = curr_date - timedelta(hours=1)\n                        \n                        if gap_start < gap_end:  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ–±–µ–ª–∞\n                            gaps.append((gap_start, gap_end))\n                \n                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã\n                for gap_idx, (gap_start, gap_end) in enumerate(gaps):\n                    logger.info(f\"–û–±–Ω–∞—Ä—É–∂–µ–Ω –ø—Ä–æ–±–µ–ª #{gap_idx+1}: —Å {gap_start.strftime('%Y-%m-%d %H:%M')} \"\n                              f\"–ø–æ {gap_end.strftime('%Y-%m-%d %H:%M')} ({(gap_end-gap_start).days} –¥–Ω–µ–π)\")\n                    \n                    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ —ç—Ç–æ—Ç –ø—Ä–æ–±–µ–ª\n                    messages = await self.get_historical_messages(client, channel, gap_start, gap_end)\n                    \n                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    new_count = 0\n                    for msg in messages:\n                        if msg.message:\n                            if self.db_manager.save_message(\n                                channel=channel,\n                                message_id=msg.id,\n                                text=msg.message,\n                                date=msg.date.replace(tzinfo=None)\n                            ):\n                                new_count += 1\n                    \n                    logger.info(f\"–ó–∞–ø–æ–ª–Ω–µ–Ω –ø—Ä–æ–±–µ–ª #{gap_idx+1}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {new_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                \n                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–∞—Ö\n                return {\n                    \"status\": \"filled_gaps\",\n                    \"existing_count\": len(existing_messages),\n                    \"gaps_filled\": len(gaps) + (1 if first_date > start_date else 0) + (1 if last_date < end_date else 0)\n                }\n            else:\n                # –ï—Å–ª–∏ –Ω–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–∞–Ω–æ–≤–æ\n                logger.info(f\"–ù–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel} –∑–∞ –ø–µ—Ä–∏–æ–¥. –°–æ–±–∏—Ä–∞–µ–º –≤—Å—ë –∑–∞–Ω–æ–≤–æ.\")\n                \n                # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥\n                messages = await self.get_historical_messages(client, channel, start_date, end_date)\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                new_count = 0\n                for msg in messages:\n                    if msg.message:\n                        if self.db_manager.save_message(\n                            channel=channel,\n                            message_id=msg.id,\n                            text=msg.message,\n                            date=msg.date.replace(tzinfo=None)\n                        ):\n                            new_count += 1\n                \n                logger.info(f\"–°–æ–±—Ä–∞–Ω–æ —Å –Ω—É–ª—è {new_count} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n                \n                return {\n                    \"status\": \"collected_all\",\n                    \"new_count\": new_count\n                }\n        \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–º —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": str(e)\n            }\n\n    async def collect_deep_history(self, channel, start_date, end_date, force_update=False):\n        \"\"\"\n        –ú–µ—Ç–æ–¥ –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ —Å–±–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n        \n        Args:\n            channel (str): –ò–º—è –∫–∞–Ω–∞–ª–∞\n            start_date (datetime): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞\n            end_date (datetime): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞\n            force_update (bool): –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n            \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞\n        \"\"\"\n        logger.info(f\"–ì–ª—É–±–æ–∫–∏–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel} –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}\")\n        \n        try:\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞\n            session_manager = TelegramSessionManager(self.api_id, self.api_hash)\n            client = await session_manager.get_client()\n            \n            try:\n                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–∏–æ–¥–∞\n                period_days = (end_date - start_date).days + 1\n                \n                # –í—ã–±–∏—Ä–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ —Å–±–æ—Ä–∞\n                if period_days > 30:\n                    # –î–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π —Å–±–æ—Ä —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–æ–±–µ–ª–æ–≤\n                    result = await self.collect_with_smart_filtering(\n                        client, channel, start_date, end_date\n                    )\n                else:\n                    # –î–ª—è –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π —Å–±–æ—Ä\n                    messages = await self.get_historical_messages(\n                        client, channel, start_date, end_date\n                    )\n                    \n                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    saved_count = 0\n                    for msg in messages:\n                        if msg.message:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç\n                            if self.db_manager.save_message(\n                                channel=channel,\n                                message_id=msg.id,\n                                text=msg.message,\n                                date=msg.date.replace(tzinfo=None)\n                            ):\n                                saved_count += 1"
  },
  {
    "chunk_id": 35,
    "context_type": "business_logic",
    "size_tokens": 1496,
    "content": "                    \n                    result = {\n                        \"status\": \"success\",\n                        \"saved_count\": saved_count,\n                        \"total_messages\": len(messages)\n                    }\n                \n                logger.info(f\"–ó–∞–≤–µ—Ä—à–µ–Ω –≥–ª—É–±–æ–∫–∏–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}: {result}\")\n                return result\n                \n            finally:\n                # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞\n                await session_manager.release_client(client)\n        \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–ª—É–±–æ–∫–æ–º —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": str(e)\n            }\n\n    async def collect_data(self, days_back=1, force_update=False, start_date=None, end_date=None):\n        \"\"\"\n        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–∞–Ω–∞–ª–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤\n        \n        Args:\n            days_back (int): –ó–∞ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ —Å–æ–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ\n            force_update (bool): –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n            start_date (datetime, optional): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è —Å–±–æ—Ä–∞\n            end_date (datetime, optional): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è —Å–±–æ—Ä–∞\n                    \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        \"\"\"\n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –¥–∞—Ç—ã —Å–±–æ—Ä–∞\n        use_date_range = start_date is not None and end_date is not None\n        \n        if use_date_range:\n            logger.info(f\"–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥: —Å {start_date.strftime('%Y-%m-%d')} \"\n                      f\"–ø–æ {end_date.strftime('%Y-%m-%d')}\")\n        else:\n            logger.info(f\"–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_back} –¥–Ω–µ–π: {', '.join(TELEGRAM_CHANNELS)}\")\n            # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∞—Ç—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã —è–≤–Ω–æ, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã\n            end_date = datetime.now()\n            start_date = end_date - timedelta(days=days_back-1)\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–∏–æ–¥–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å–±–æ—Ä–∞\n        period_days = (end_date - start_date).days + 1\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º error handling —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        max_attempts = 3\n        attempt = 0\n        backoff_delay = 2  # –Ω–∞—á–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö\n        \n        try:\n            while attempt < max_attempts:\n                try:\n                    # –°–æ–∑–¥–∞–µ–º –æ–¥–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–µ—Å—Å–∏–π –Ω–∞ –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å\n                    session_manager = TelegramSessionManager(self.api_id, self.api_hash)\n                    \n                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –∏–ª–∏ –±–µ—Ä–µ–º –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫\n                    channels_to_process = TELEGRAM_CHANNELS\n                    results = {}\n                    total_messages = 0\n                    \n                    # –î–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ —Å–±–æ—Ä–∞\n                    if period_days > 7:\n                        logger.info(f\"–û–±–Ω–∞—Ä—É–∂–µ–Ω –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö ({period_days} –¥–Ω–µ–π). –ò—Å–ø–æ–ª—å–∑—É—é –≥–ª—É–±–æ–∫–∏–π —Å–±–æ—Ä.\")\n                        \n                        for channel in channels_to_process:\n                            channel_result = await self.collect_deep_history(\n                                channel, \n                                start_date, \n                                end_date, \n                                force_update\n                            )\n                            \n                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞\n                            if channel_result[\"status\"] == \"success\":\n                                saved_count = channel_result.get(\"saved_count\", 0)\n                                results[channel] = saved_count\n                                total_messages += saved_count\n                                logger.info(f\"–ö–∞–Ω–∞–ª {channel}: —Å–æ–±—Ä–∞–Ω–æ {saved_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                            elif channel_result[\"status\"] == \"filled_gaps\":\n                                # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                                existing_count = channel_result.get(\"existing_count\", 0)\n                                results[channel] = existing_count\n                                total_messages += existing_count\n                                logger.info(f\"–ö–∞–Ω–∞–ª {channel}: –Ω–∞–π–¥–µ–Ω–æ {existing_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                            elif channel_result[\"status\"] == \"collected_all\":\n                                new_count = channel_result.get(\"new_count\", 0)\n                                results[channel] = new_count\n                                total_messages += new_count\n                                logger.info(f\"–ö–∞–Ω–∞–ª {channel}: —Å–æ–±—Ä–∞–Ω–æ {new_count} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                            else:\n                                results[channel] = 0\n                                logger.warning(f\"–ö–∞–Ω–∞–ª {channel}: –æ—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ - {channel_result.get('error', 'unknown')}\")\n                            \n                            # –î–µ–ª–∞–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏\n                            await asyncio.sleep(2)\n                    else:\n                        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–±–æ—Ä\n                        client = await session_manager.get_client()\n                        \n                        try:\n                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ\n                            for channel in channels_to_process:\n                                try:\n                                    logger.info(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–∞ {channel}...\")\n                                    \n                                    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–±–æ—Ä–∞\n                                    messages = await self.get_historical_messages(\n                                        client, \n                                        channel, \n                                        start_date, \n                                        end_date\n                                    )"
  },
  {
    "chunk_id": 36,
    "context_type": "business_logic",
    "size_tokens": 1497,
    "content": "                                    \n                                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                                    today = datetime.now().date()\n                                    if end_date.date() >= today:\n                                        logger.info(f\"–í—ã–ø–æ–ª–Ω—è—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n                                        \n                                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö\n                                        latest_messages = await self._get_newest_messages(client, channel, 20)\n                                        \n                                        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º\n                                        if latest_messages:\n                                            added_count = 0\n                                            for msg in latest_messages:\n                                                msg_date = msg.date.replace(tzinfo=None)\n                                                if start_date <= msg_date <= end_date and msg.id not in [m.id for m in messages]:\n                                                    logger.info(f\"–ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–∞–Ω–∞–ª–µ {channel} –æ—Ç {msg_date.strftime('%Y-%m-%d %H:%M:%S')}\")\n                                                    messages.append(msg)\n                                                    added_count += 1\n                                            \n                                            if added_count > 0:\n                                                logger.info(f\"–î–æ–±–∞–≤–ª–µ–Ω–æ {added_count} —Å–≤–µ–∂–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n                                    \n                                    # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è, —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                                    existing_ids = []\n                                    if not force_update:\n                                        for msg in messages:\n                                            existing = self.db_manager.get_message_by_channel_and_id(channel, msg.id)\n                                            if existing:\n                                                existing_ids.append(msg.id)\n                                    \n                                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –∏–ª–∏ –≤—Å–µ –ø—Ä–∏ force_update\n                                    filtered_messages = [msg for msg in messages if force_update or msg.id not in existing_ids]\n                                    \n                                    logger.info(f\"–ö–∞–Ω–∞–ª {channel}: –ø–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π, \"\n                                            f\"–¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–æ–±—Ä–∞–Ω–æ {len(filtered_messages)} (—Ä–µ–∂–∏–º force_update={force_update})\")\n                                    \n                                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n                                    messages_to_save = []\n                                    for message in filtered_messages:\n                                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ —Ç–µ–∫—Å—Ç–∞\n                                        if not message.message:\n                                            continue\n                                        \n                                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞—Ç—É\n                                        message_date = message.date\n                                        if message_date.tzinfo is not None:\n                                            message_date = message_date.replace(tzinfo=None)\n                                        \n                                        messages_to_save.append({\n                                            'channel': channel,\n                                            'message_id': message.id,\n                                            'text': message.message,\n                                            'date': message_date\n                                        })\n                                    \n                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è - –ª–∏–±–æ –ø–∞–∫–µ—Ç–Ω–æ, –ª–∏–±–æ –ø–æ –æ–¥–Ω–æ–º—É\n                                    new_messages_count = 0\n                                    \n                                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–∫–µ—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–µ—Ç–æ–¥ –¥–æ—Å—Ç—É–ø–µ–Ω\n                                    if hasattr(self.db_manager, 'batch_save_messages'):\n                                        if messages_to_save:\n                                            try:\n                                                new_messages_count = self.db_manager.batch_save_messages(messages_to_save)\n                                            except Exception as e:\n                                                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {str(e)}\")\n                                                new_messages_count = self._save_messages_one_by_one(messages_to_save, channel)\n                                    else:\n                                        # –ï—Å–ª–∏ –º–µ—Ç–æ–¥–∞ batch_save_messages –Ω–µ—Ç, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ –æ–¥–Ω–æ–º—É\n                                        new_messages_count = self._save_messages_one_by_one(messages_to_save, channel)\n                                    \n                                    logger.info(f\"–ö–∞–Ω–∞–ª {channel}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {new_messages_count} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                                    results[channel] = new_messages_count\n                                    total_messages += new_messages_count\n                                    \n                                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ —Ä–∞–∑–Ω—ã–º –∫–∞–Ω–∞–ª–∞–º\n                                    await asyncio.sleep(1)\n                                    \n                                except Exception as e:\n                                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel}: {str(e)}\")\n                                    results[channel] = 0\n                        finally:"
  },
  {
    "chunk_id": 37,
    "context_type": "business_logic",
    "size_tokens": 1499,
    "content": "                            # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç\n                            await session_manager.release_client(client)\n                    \n                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞\n                    logger.info(f\"–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {total_messages} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\")\n                    \n                    # –í—ã–∑—ã–≤–∞–µ–º —Ö—É–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ—Ä–∞\n                    if total_messages > 0:\n                        update_result = await self.after_collect_hook({\n                            \"status\": \"success\",\n                            \"total_new_messages\": total_messages,\n                            \"channels_stats\": results\n                        })\n                        \n                        return {\n                            \"status\": \"success\",\n                            \"total_new_messages\": total_messages,\n                            \"channels_stats\": results,\n                            \"update_result\": update_result\n                        }\n                    \n                    return {\n                        \"status\": \"success\",\n                        \"total_new_messages\": total_messages,\n                        \"channels_stats\": results\n                    }\n                    \n                except Exception as e:\n                    attempt += 1\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–≤—è–∑–∞–Ω–∞ –ª–∏ –æ—à–∏–±–∫–∞ —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n                    if \"database is locked\" in str(e).lower():\n                        if attempt < max_attempts:\n                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏\n                            delay = backoff_delay * (2 ** (attempt - 1))\n                            logger.warning(f\"–û—à–∏–±–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ë–î –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts} —á–µ—Ä–µ–∑ {delay}—Å: {str(e)}\")\n                            await asyncio.sleep(delay)\n                            \n                            # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π\n                            self.client = None\n                        else:\n                            logger.error(f\"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫ –∏–∑-–∑–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ë–î: {str(e)}\")\n                            return {\n                                \"status\": \"error\",\n                                \"error\": f\"–û—à–∏–±–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}\",\n                                \"total_new_messages\": 0,\n                                \"channels_stats\": {}\n                            }\n                    else:\n                        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –Ω–µ —Å–≤—è–∑–∞–Ω–∞ —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n                        logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}\")\n                        return {\n                            \"status\": \"error\",\n                            \"error\": str(e),\n                            \"total_new_messages\": 0,\n                            \"channels_stats\": {}\n                        }\n            \n            # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å\n            return {\n                \"status\": \"error\",\n                \"error\": \"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\",\n                \"total_new_messages\": 0,\n                \"channels_stats\": {}\n            }\n        finally:\n            # –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å –∫–ª–∏–µ–Ω—Ç–æ–º, –µ—Å–ª–∏ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω\n            if hasattr(self, 'client') and self.client:\n                try:\n                    await self._release_client()\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ Telegram: {str(e)}\")\n    \n    async def _get_newest_messages(self, client, channel, limit=20):\n        \"\"\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∞–º—ã—Ö –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞\"\"\"\n        try:\n            entity = await client.get_entity(channel)\n            messages = await client(GetHistoryRequest(\n                peer=entity,\n                limit=limit,\n                offset_date=None,  # –ë–µ–∑ —Å–º–µ—â–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∞–º—ã—Ö –Ω–æ–≤—ã—Ö\n                offset_id=0,\n                max_id=0,\n                min_id=0,\n                add_offset=0,\n                hash=0\n            ))\n            \n            if not messages or not messages.messages:\n                return []\n                \n            logger.info(f\"–ü–æ–ª—É—á–µ–Ω–æ {len(messages.messages)} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ –∫–∞–Ω–∞–ª–∞ {channel}\")\n            return messages.messages\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {str(e)}\")\n            return []\n\n    async def after_collect_hook(self, collect_result):\n        \"\"\"\n        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ö—É–∫, –≤—ã–∑—ã–≤–∞–µ–º—ã–π –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        \n        Args:\n            collect_result (dict): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        \"\"\"\n        if collect_result.get(\"total_new_messages\", 0) > 0:\n            # –ï—Å–ª–∏ —Å–æ–±—Ä–∞–Ω—ã –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n            logger.info(f\"–°–æ–±—Ä–∞–Ω–æ {collect_result['total_new_messages']} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\")\n            try:\n                from agents.digester import DigesterAgent # –ü–µ—Ä–µ–º–µ—â–µ–Ω –∏–º–ø–æ—Ä—Ç —Å—é–¥–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–≥–æ\n                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É\n                today = datetime.now()\n                \n                digester = DigesterAgent(self.db_manager)\n                update_result = digester.update_digests_for_date(today)\n                \n                logger.info(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {update_result}\")\n                return update_result\n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ—Å–ª–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {str(e)}\")\n                return {\"status\": \"error\", \"error\": str(e)}\n        \n        return {\"status\": \"no_update_needed\"}\n        \n    async def collect_for_specific_period(self, start_date_str, end_date_str, channels=None):\n        \"\"\"\n        –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ (—Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç YYYY-MM-DD)\n        \n        Args:\n            start_date_str (str): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"
  },
  {
    "chunk_id": 38,
    "context_type": "business_logic",
    "size_tokens": 2012,
    "content": "            end_date_str (str): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD\n            channels (list, optional): –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –∫–∞–Ω–∞–ª—ã)\n            \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞\n        \"\"\"\n        try:\n            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç –≤ datetime –æ–±—ä–µ–∫—Ç—ã\n            start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n            # –î–ª—è –∫–æ–Ω–µ—á–Ω–æ–π –¥–∞—Ç—ã —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Ä–µ–º—è 23:59:59\n            end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").replace(hour=23, minute=59, second=59)\n            \n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–Ω–∞–ª—ã –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –∏–ª–∏ –≤—Å–µ –∫–∞–Ω–∞–ª—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n            target_channels = channels or TELEGRAM_CHANNELS\n            \n            logger.info(f\"–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ {start_date_str} - {end_date_str} –∏–∑ –∫–∞–Ω–∞–ª–æ–≤: {target_channels}\")\n            \n            # –í—ã–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–±–æ—Ä–∞ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –¥–∞—Ç–∞–º–∏\n            result = await self.collect_data(\n                start_date=start_date,\n                end_date=end_date,\n                force_update=False  # –ù–µ –æ–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n            )\n            \n            return result\n            \n        except ValueError as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": f\"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {str(e)}\",\n                \"total_new_messages\": 0\n            }\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": str(e),\n                \"total_new_messages\": 0\n            }\n    \n    def create_task(self):\n        \"\"\"\n        –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n        \n        Returns:\n            Task: –ó–∞–¥–∞—á–∞ CrewAI\n        \"\"\"\n        return Task(\n            description=\"–°–æ–±—Ä–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—ã—Ö Telegram-–∫–∞–Ω–∞–ª–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1-3 –¥–Ω—è\",\n            agent=self.agent,\n            expected_output=\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\"\n        )\n\n\n=== orchestrator.py ===\n\"\"\"\nOrchestrator Agents - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ intelligent –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä—ã\n\n–°–æ–¥–µ—Ä–∂–∏—Ç:\nIntelligent Orchestrator Agent - –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º CrewAI –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π\n\"\"\"\nimport logging\nimport asyncio\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Any\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom crewai import Agent, Task, Crew\n\nlogger = logging.getLogger(__name__)\n\nclass TaskType(Enum):\n    \"\"\"–¢–∏–ø—ã –∑–∞–¥–∞—á –≤ —Å–∏—Å—Ç–µ–º–µ\"\"\"\n    DATA_COLLECTION = \"data_collection\"\n    MESSAGE_ANALYSIS = \"message_analysis\"\n    CATEGORIZATION_REVIEW = \"categorization_review\"\n    DIGEST_CREATION = \"digest_creation\"\n    DIGEST_UPDATE = \"digest_update\"\n\nclass TaskPriority(Enum):\n    \"\"\"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–¥–∞—á\"\"\"\n    LOW = 1\n    NORMAL = 2\n    HIGH = 3\n    CRITICAL = 4\n\nclass TaskStatus(Enum):\n    \"\"\"–°—Ç–∞—Ç—É—Å—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á\"\"\"\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n    CANCELLED = \"cancelled\"\n\n@dataclass\nclass TaskRequest:\n    \"\"\"–ó–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏\"\"\"\n    task_type: TaskType\n    priority: TaskPriority = TaskPriority.NORMAL\n    params: Dict[str, Any] = None\n    dependencies: List[str] = None\n    timeout: int = 300\n    retry_count: int = 3\n    created_at: datetime = None\n    reasoning: str = \"\"  # –û–±—ä—è—Å–Ω–µ–Ω–∏–µ, –ø–æ—á–µ–º—É –∑–∞–¥–∞—á–∞ –Ω—É–∂–Ω–∞\n    \n    def __post_init__(self):\n        if self.created_at is None:\n            self.created_at = datetime.now()\n        if self.params is None:\n            self.params = {}\n        if self.dependencies is None:\n            self.dependencies = []\n\n@dataclass\nclass TaskResult:\n    \"\"\"–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏\"\"\"\n    task_id: str\n    task_type: TaskType\n    status: TaskStatus\n    result: Any = None\n    error: str = None\n    execution_time: float = 0.0\n    completed_at: datetime = None\nclass OrchestratorAgent:\n    \"\"\"\n    –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∞–≥–µ–Ω—Ç-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n    \"\"\"\n    \n    def __init__(self, db_manager, agent_registry=None):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\"\"\"\n        self.db_manager = db_manager\n        self.agent_registry = agent_registry\n        self.task_queue = []\n        self.active_tasks = {}\n        self.completed_tasks = []\n        self.context = {}\n        \n        # –°–æ–∑–¥–∞–µ–º CrewAI –∞–≥–µ–Ω—Ç–∞\n        self.agent = Agent(\n            name=\"Orchestrator\",\n            role=\"–ì–ª–∞–≤–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫\",\n            goal=\"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã\",\n            backstory=\"–Ø —è–≤–ª—è—é—Å—å –≥–ª–∞–≤–Ω—ã–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–æ–º —Å–∏—Å—Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é, \"\n                     \"–ø–ª–∞–Ω–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –∏ —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –∑–∞–¥–∞—á.\",\n            verbose=True\n        )\n        \n        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤\n        self.execution_strategies = {\n            \"daily_workflow\": self._create_daily_workflow_strategy,\n            \"urgent_update\": self._create_urgent_update_strategy,\n            \"full_analysis\": self._create_full_analysis_strategy,\n            \"digest_only\": self._create_digest_only_strategy\n        }\n        \n        logger.info(\"Orchestrator Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n    \n    async def plan_and_execute(self, scenario: str = \"daily_workflow\", **kwargs) -> Dict[str, Any]:\n        \"\"\"–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\"\"\"\n        logger.info(f\"–ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è: {scenario}\")\n        \n        try:\n            # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\n            context = await self._analyze_current_state(**kwargs)\n            execution_plan = await self._create_execution_plan(scenario, context, **kwargs)\n            results = await self._execute_plan(execution_plan)\n            final_result = await self._analyze_results_and_decide(results, scenario)\n            \n            return final_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario}: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": str(e),\n                \"scenario\": scenario\n            }\n    \n    async def _analyze_current_state(self, **kwargs) -> Dict[str, Any]:\n        \"\"\"–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)\"\"\"\n        context = {\n            \"timestamp\": datetime.now(),\n            \"scenario_params\": kwargs,\n            \"unanalyzed_count\": 0,\n            \"low_confidence_count\": 0,\n            \"today_digests_count\": 0,\n            \"needs_data_collection\": True\n        }\n        \n        try:\n            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\n            unanalyzed_messages = self.db_manager.get_unanalyzed_messages(limit=100)\n            context[\"unanalyzed_count\"] = len(unanalyzed_messages)\n            \n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n            today_digests = self.db_manager.find_digests_by_parameters(is_today=True)\n            context[\"today_digests_count\"] = len(today_digests)\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {str(e)}\")\n        \n        return context\n    \n    async def _create_execution_plan(self, scenario: str, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)\"\"\"\n        if scenario not in self.execution_strategies:\n            logger.warning(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π {scenario}, –∏—Å–ø–æ–ª—å–∑—É–µ–º daily_workflow\")\n            scenario = \"daily_workflow\"\n        \n        strategy_func = self.execution_strategies[scenario]\n        return await strategy_func(context, **kwargs)\n    \n    async def _create_daily_workflow_strategy(self, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)\"\"\"\n        tasks = []\n        \n        # –ë–∞–∑–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è daily_workflow\n        tasks.append(TaskRequest(\n            task_type=TaskType.DATA_COLLECTION,\n            priority=TaskPriority.HIGH,"
  },
  {
    "chunk_id": 39,
    "context_type": "business_logic",
    "size_tokens": 1496,
    "content": "            params={\"days_back\": kwargs.get(\"days_back\", 1),\n                    \"force_update\": True\n                    },\n        reasoning=\"–ù–µ–æ–±—Ö–æ–¥–∏–º —Å–±–æ—Ä —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤\"\n        ))\n        \n        tasks.append(TaskRequest(\n            task_type=TaskType.MESSAGE_ANALYSIS,\n            priority=TaskPriority.NORMAL,\n            params={\"limit\": 100},\n            dependencies=[\"data_collection\"]\n        ))\n        \n        tasks.append(TaskRequest(\n            task_type=TaskType.DIGEST_CREATION,\n            priority=TaskPriority.HIGH,\n            params={\"days_back\": kwargs.get(\"days_back\", 1)},\n            dependencies=[\"message_analysis\"]\n        ))\n        \n        return tasks\n    \n    async def _create_urgent_update_strategy(self, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è —Å—Ä–æ—á–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\"\"\"\n        return await self._create_daily_workflow_strategy(context, **kwargs)\n    \n    async def _create_full_analysis_strategy(self, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞\"\"\"\n        return await self._create_daily_workflow_strategy(context, **kwargs)\n    \n    async def _create_digest_only_strategy(self, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n        tasks = []\n        tasks.append(TaskRequest(\n            task_type=TaskType.DIGEST_CREATION,\n            priority=TaskPriority.HIGH,\n            params={\"days_back\": kwargs.get(\"days_back\", 1)}\n        ))\n        return tasks\n    \n    async def _execute_plan(self, execution_plan: List[TaskRequest]) -> List[TaskResult]:\n        \"\"\"–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞\"\"\"\n        results = []\n        \n        for task in execution_plan:\n            try:\n                start_time = datetime.now()\n                result = await self._execute_single_task(task)\n                execution_time = (datetime.now() - start_time).total_seconds()\n                \n                task_result = TaskResult(\n                    task_id=task.task_type.value,\n                    task_type=task.task_type,\n                    status=TaskStatus.COMPLETED,\n                    result=result,\n                    execution_time=execution_time,\n                    completed_at=datetime.now()\n                )\n                \n                results.append(task_result)\n                \n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ {task.task_type.value}: {str(e)}\")\n                \n                task_result = TaskResult(\n                    task_id=task.task_type.value,\n                    task_type=task.task_type,\n                    status=TaskStatus.FAILED,\n                    error=str(e),\n                    execution_time=0,\n                    completed_at=datetime.now()\n                )\n                \n                results.append(task_result)\n        \n        return results\n    \n    async def _execute_single_task(self, task: TaskRequest) -> Any:\n        \"\"\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ)\"\"\"\n        if not self.agent_registry:\n            raise Exception(\"Agent registry –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n        \n        if task.task_type == TaskType.DATA_COLLECTION:\n            collector = self.agent_registry.get_agent(\"data_collector\")\n            return await collector.collect_data(**task.params)\n            \n        elif task.task_type == TaskType.MESSAGE_ANALYSIS:\n            analyzer = self.agent_registry.get_agent(\"analyzer\")\n            return await analyzer.analyze_messages(**task.params)\n            \n        elif task.task_type == TaskType.DIGEST_CREATION:\n            digester = self.agent_registry.get_agent(\"digester\")\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –≤ executor\n            loop = asyncio.get_event_loop()\n            return await loop.run_in_executor(None, lambda: digester.create_digest(**task.params))\n            \n        else:\n            raise Exception(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task.task_type}\")\n    \n    async def _analyze_results_and_decide(self, results: List[TaskResult], scenario: str) -> Dict[str, Any]:\n        \"\"\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)\"\"\"\n        successful_tasks = [r for r in results if r.status == TaskStatus.COMPLETED]\n        failed_tasks = [r for r in results if r.status == TaskStatus.FAILED]\n        \n        total_execution_time = sum(r.execution_time for r in results)\n        success_rate = len(successful_tasks) / len(results) if results else 0\n        \n        summary = {\n            \"collected_messages\": 0,\n            \"analyzed_messages\": 0,\n            \"created_digests\": []\n        }\n        \n        metrics = {\n            \"total_tasks\": len(results),\n            \"successful_tasks\": len(successful_tasks),\n            \"failed_tasks\": len(failed_tasks),\n            \"success_rate\": success_rate,\n            \"total_execution_time\": total_execution_time,\n            \"scenario\": scenario\n        }\n        \n        return {\n            \"status\": \"success\" if not failed_tasks else \"partial_success\",\n            \"metrics\": metrics,\n            \"summary\": summary,\n            \"recommendations\": []\n        }\n    \n    def create_task(self) -> Task:\n        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ CrewAI –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏\"\"\"\n        return Task(\n            description=\"–°–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ —Å–∫–æ–æ—Ä–¥–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–∏—Å—Ç–µ–º—ã\",\n            agent=self.agent,\n            expected_output=\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\"\n        )\n\nclass IntelligentOrchestratorAgent:\n    \"\"\"\n    Intelligent –∞–≥–µ–Ω—Ç-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π CrewAI –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π\n    \"\"\"\n    \n    def __init__(self, db_manager, agent_registry=None):\n        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞\"\"\"\n        self.db_manager = db_manager\n        self.agent_registry = agent_registry\n        self.task_queue = []\n        self.active_tasks = {}\n        self.completed_tasks = []\n        self.context = {}\n        "
  },
  {
    "chunk_id": 40,
    "context_type": "business_logic",
    "size_tokens": 1490,
    "content": "        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é LLM –∫–∞–∫ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã\n        from llm.gemma_model import GemmaLLM\n        self.llm_model = GemmaLLM()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ LLM —á—Ç–æ –∏ –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã\n        \n        # –°–æ–∑–¥–∞–µ–º CrewAI –∞–≥–µ–Ω—Ç–∞ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM\n        try:\n            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Ñ—É–Ω–∫—Ü–∏—é-wrapper –¥–ª—è LLM\n            def llm_generate(prompt):\n                return self.llm_model.generate(prompt, max_tokens=1000, temperature=0.7)\n            \n            self.planning_agent = Agent(\n                name=\"IntelligentPlanner\",\n                role=\"Intelligent —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫\",\n                goal=\"–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∏ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–µ—à–µ–Ω–∏—è\",\n                backstory=\"\"\"–Ø ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ò–ò-–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–∏—Å—Ç–µ–º—ã \n                            –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç intelligent —Ä–µ—à–µ–Ω–∏—è.\"\"\",\n                verbose=True,\n                allow_delegation=False,\n                llm=None  # –ü–æ–∫–∞ –æ—Ç–∫–ª—é—á–∞–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–æ–π llm_model\n            )\n            \n            self.planning_task = Task(\n                description=\"–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –∏ —Å–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\",\n                agent=self.planning_agent,\n                expected_output=\"JSON –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å –∑–∞–¥–∞—á–∞–º–∏ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º\"\n            )\n            \n            self.planning_crew = None  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º Crew\n            \n        except Exception as e:\n            logger.warning(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ CrewAI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}\")\n            self.planning_agent = None\n            self.planning_crew = None\n        \n        logger.info(\"Intelligent Orchestrator Agent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n        try:\n            from agents.collaborative_crew import CollaborativeCrew\n            self.collaborative_crew = CollaborativeCrew(agent_registry)\n            logger.info(\"‚úÖ –°–∏—Å—Ç–µ–º–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –≤ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä\")\n        except Exception as e:\n            logger.warning(f\"–ö–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}\")\n            self.collaborative_crew = None\n    \n    async def plan_and_execute(self, scenario: str = \"daily_workflow\", **kwargs) -> Dict[str, Any]:\n        \"\"\"\n        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        \n        Args:\n            scenario: –°—Ü–µ–Ω–∞—Ä–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n            \n        Returns:\n            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        \"\"\"\n        logger.info(f\"–ó–∞–ø—É—Å–∫ intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è: {scenario}\")\n        \n        try:\n            # –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –û–¢–õ–ê–î–ö–£:\n            logger.info(\"–®–∞–≥ 1: –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞\")\n\n            # –≠—Ç–∞–ø 1: –°–±–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏\n            context = await self._gather_system_context(**kwargs)\n            logger.info(f\"–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–±—Ä–∞–Ω: {len(context.get('unanalyzed_messages', []))} –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\")\n            \n            # –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –û–¢–õ–ê–î–ö–£:\n            logger.info(\"–®–∞–≥ 2: –ù–∞—á–∏–Ω–∞–µ–º intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\")\n\n            # –≠—Ç–∞–ø 2: Intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ CrewAI\n            execution_plan = await self._intelligent_planning(scenario, context, **kwargs)\n            logger.info(f\"Intelligent –ø–ª–∞–Ω —Å–æ–∑–¥–∞–Ω: {len(execution_plan)} –∑–∞–¥–∞—á\")\n            \n             # –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –û–¢–õ–ê–î–ö–£:\n            logger.info(\"–®–∞–≥ 3: –ù–∞—á–∏–Ω–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞\")\n\n            # –≠—Ç–∞–ø 3: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞\n            results = await self._execute_intelligent_plan(execution_plan)\n            logger.info(f\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n            \n            # –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –û–¢–õ–ê–î–ö–£:\n            logger.info(\"–®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n\n            # –≠—Ç–∞–ø 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n            final_result = await self._analyze_execution_results(results, scenario, context)\n            \n            return final_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ intelligent –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏—è {scenario}: {str(e)}\")\n            return {\n                \"status\": \"error\",\n                \"error\": str(e),\n                \"scenario\": scenario\n            }\n    \n    async def _gather_system_context(self, **kwargs) -> Dict[str, Any]:\n        \"\"\"–°–±–æ—Ä –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–∏—Å—Ç–µ–º—ã\"\"\"\n        context = {\n            \"timestamp\": datetime.now(),\n            \"scenario_params\": kwargs\n        }\n        \n        try:\n            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\n            unanalyzed_messages = self.db_manager.get_unanalyzed_messages(limit=1000)\n            context[\"unanalyzed_count\"] = len(unanalyzed_messages)\n            context[\"unanalyzed_messages\"] = unanalyzed_messages[:5]  # –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n            \n            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\n            \n            try:\n                low_confidence_messages = self.db_manager.get_messages_with_low_confidence(confidence_threshold=2)\n                context[\"low_confidence_count\"] = len(low_confidence_messages)\n            except (AttributeError, TypeError):\n                # Fallback –µ—Å–ª–∏ –º–µ—Ç–æ–¥ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ\n                context[\"low_confidence_count\"] = 0\n            \n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n            today_digests = self.db_manager.find_digests_by_parameters(is_today=True)\n            context[\"today_digests_count\"] = len(today_digests)\n            context[\"has_brief_digest\"] = any(d.digest_type == \"brief\" for d in today_digests)\n            context[\"has_detailed_digest\"] = any(d.digest_type == \"detailed\" for d in today_digests)\n            \n            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n            category_stats = {}\n            if unanalyzed_messages:\n                for msg in unanalyzed_messages[:20]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã–±–æ—Ä–∫—É\n                    cat = getattr(msg, 'category', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')\n                    conf = getattr(msg, 'confidence', 0)\n                    category_stats[cat] = category_stats.get(cat, {'count': 0, 'avg_confidence': 0})"
  },
  {
    "chunk_id": 41,
    "context_type": "business_logic",
    "size_tokens": 1497,
    "content": "                    category_stats[cat]['count'] += 1\n                    category_stats[cat]['avg_confidence'] = (category_stats[cat]['avg_confidence'] + conf) / 2\n            \n            context[\"category_statistics\"] = category_stats\n            \n            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–∞–º–∫–∞—Ö\n            days_back = kwargs.get(\"days_back\", 1)\n            force_update = kwargs.get(\"force_update\", False)\n            context[\"days_back\"] = days_back\n            context[\"force_update\"] = force_update\n            \n            # –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö\n            last_collection_time = getattr(self.db_manager, '_last_collection_time', None)\n            if last_collection_time:\n                time_since_collection = (datetime.now() - last_collection_time).total_seconds() / 3600\n                context[\"hours_since_last_collection\"] = time_since_collection\n                context[\"needs_data_collection\"] = time_since_collection > 2 or force_update\n            else:\n                context[\"needs_data_collection\"] = True\n                context[\"hours_since_last_collection\"] = 999\n            \n            logger.info(f\"–°–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç: –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö={context['unanalyzed_count']}, \"\n                       f\"–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={context['low_confidence_count']}, \"\n                       f\"–¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ —Å–µ–≥–æ–¥–Ω—è={context['today_digests_count']}\")\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)}\")\n            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n            context.update({\n                \"unanalyzed_count\": 0,\n                \"low_confidence_count\": 0,\n                \"today_digests_count\": 0,\n                \"needs_data_collection\": True,\n                \"error\": str(e)\n            })\n        \n        return context\n    \n    async def _intelligent_planning(self, scenario: str, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"Intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–π LLM\"\"\"\n        \n        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç\n        planning_context = f\"\"\"\n        –ê–ù–ê–õ–ò–ó –¢–ï–ö–£–©–ï–ô –°–ò–¢–£–ê–¶–ò–ò:\n        \n        –°—Ü–µ–Ω–∞—Ä–∏–π: {scenario}\n        –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞: {context['timestamp']}\n        \n        –°–û–°–¢–û–Ø–ù–ò–ï –î–ê–ù–ù–´–•:\n        - –ù–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {context.get('unanalyzed_count', 0)}\n        - –°–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {context.get('low_confidence_count', 0)}\n        - –î–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è: {context.get('today_digests_count', 0)}\n        - –ï—Å—Ç—å –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç: {context.get('has_brief_digest', False)}\n        - –ï—Å—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç: {context.get('has_detailed_digest', False)}\n        \n        –ü–ê–†–ê–ú–ï–¢–†–´ –°–ë–û–†–ê:\n        - –î–Ω–µ–π –Ω–∞–∑–∞–¥: {context.get('days_back', 1)}\n        - –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {context.get('force_update', False)}\n        - –ß–∞—Å–æ–≤ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–±–æ—Ä–∞: {context.get('hours_since_last_collection', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n        - –ù—É–∂–µ–Ω —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö: {context.get('needs_data_collection', True)}\n        \n        –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–ê–¢–ï–ì–û–†–ò–ô:\n        {context.get('category_statistics', {})}\n        \n        –î–û–°–¢–£–ü–ù–´–ï –¢–ò–ü–´ –ó–ê–î–ê–ß:\n        1. DATA_COLLECTION - —Å–±–æ—Ä –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤\n        2. MESSAGE_ANALYSIS - –∞–Ω–∞–ª–∏–∑ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π\n        3. CATEGORIZATION_REVIEW - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏–∫–æ–º\n        4. DIGEST_CREATION - —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        5. DIGEST_UPDATE - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n        \n        –¢–í–û–Ø –ó–ê–î–ê–ß–ê:\n        –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–∏—Ç—É–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–π optimal –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è \"{scenario}\".\n        –î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ –æ–±—ä—è—Å–Ω–∏ WHY –æ–Ω–∞ –Ω—É–∂–Ω–∞ –∏ –≤ –∫–∞–∫–æ–º –ü–û–†–Ø–î–ö–ï –¥–æ–ª–∂–Ω–∞ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è.\n        \n        –û–°–û–ë–ï–ù–ù–û–°–¢–ò –°–¶–ï–ù–ê–†–ò–ï–í:\n        - daily_workflow: –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª (—Å–±–æ—Ä ‚Üí –∞–Ω–∞–ª–∏–∑ ‚Üí –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Üí –¥–∞–π–¥–∂–µ—Å—Ç)\n        - urgent_update: –±—ã—Å—Ç—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏\n        - full_analysis: –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ\n        - digest_only: —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n        \n        –í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:\n        1. –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ‚Üí –Ω—É–∂–µ–Ω MESSAGE_ANALYSIS\n        2. –ï—Å–ª–∏ –º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é ‚Üí –Ω—É–∂–µ–Ω CATEGORIZATION_REVIEW\n        3. –í—Å–µ–≥–¥–∞ –æ–±—ä—è—Å–Ω—è–π —Å–≤–æ–∏ —Ä–µ—à–µ–Ω–∏—è\n        4. –£—á–∏—Ç—ã–≤–∞–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏\n        5. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è\n        \n        –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –ó–ê–î–ê–ß–ê_1: reasoning, –ó–ê–î–ê–ß–ê_2: reasoning, –∏ —Ç.–¥.\n        \"\"\"\n        \n        try:\n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –ª–æ–∫–∞–ª—å–Ω—É—é LLM –¥–ª—è intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n            logger.info(\"–ù–∞—á–∏–Ω–∞—é intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM...\")\n            \n            response = self.llm_model.generate(\n                planning_context, \n                max_tokens=800,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞\n                temperature=0.3   # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –ª–æ–≥–∏—á–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π\n            )\n            \n            logger.info(f\"LLM –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç: {response}\")\n            \n            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –∏ —Å–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω\n            tasks = await self._parse_llm_planning_result(response, context, **kwargs)\n            \n            return tasks\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ LLM –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}\")\n            # Fallback –Ω–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\n            return await self._fallback_planning(scenario, context, **kwargs)\n    \n    async def _parse_llm_planning_result(self, llm_response: str, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM –≤ –ø–ª–∞–Ω –∑–∞–¥–∞—á\"\"\"\n        tasks = []\n        dependencies = []\n        \n        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM\n        response_lower = llm_response.lower()\n        from datetime import datetime, timedelta\n\n        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∞—Ç—ã\n        days_back = kwargs.get(\"days_back\", 1)\n        end_date = datetime.now()\n        start_date = end_date - timedelta(days=days_back-1)\n        start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)\n\n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ç–≤–µ—Ç–∞ LLM –∏ –ª–æ–≥–∏–∫–∏"
  },
  {
    "chunk_id": 42,
    "context_type": "business_logic",
    "size_tokens": 1497,
    "content": "        if \"data_collection\" in response_lower or context.get('needs_data_collection', True):\n            tasks.append(TaskRequest(\n                task_type=TaskType.DATA_COLLECTION,\n                priority=TaskPriority.HIGH,\n                params={\n                    \"days_back\": kwargs.get(\"days_back\", 1),\n                    \"force_update\": True,\n                    \"start_date\": start_date,\n                    \"end_date\": end_date\n                    },\n                reasoning=\"LLM: –ù–µ–æ–±—Ö–æ–¥–∏–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\"\n            ))\n            dependencies.append(\"data_collection\")\n        \n        if context.get('unanalyzed_count', 0) > 0 or \"message_analysis\" in response_lower:\n            tasks.append(TaskRequest(\n                task_type=TaskType.MESSAGE_ANALYSIS,\n                priority=TaskPriority.NORMAL,\n                params={\"limit\": 100},\n                dependencies=dependencies.copy(),\n                reasoning=\"LLM: –ê–Ω–∞–ª–∏–∑ –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\"\n            ))\n            dependencies.append(\"message_analysis\")\n        \n        if context.get('low_confidence_count', 0) > 0 or \"categorization_review\" in response_lower:\n            tasks.append(TaskRequest(\n                task_type=TaskType.CATEGORIZATION_REVIEW,\n                priority=TaskPriority.NORMAL,\n                params={\"confidence_threshold\": 3},\n                dependencies=dependencies.copy(),\n                reasoning=\"LLM: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\"\n            ))\n            dependencies.append(\"categorization_review\")\n        \n        if \"digest\" in response_lower:\n            tasks.append(TaskRequest(\n                task_type=TaskType.DIGEST_CREATION,\n                priority=TaskPriority.HIGH,\n                params={\n                    \"days_back\": kwargs.get(\"days_back\", 1)\n                    },\n                dependencies=dependencies.copy(),\n                reasoning=\"LLM: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\"\n            ))\n        \n        return tasks\n\n    async def _parse_planning_result(self, planning_result: str, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è CrewAI –≤ —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á\"\"\"\n        tasks = []\n        \n        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n        planning_text = str(planning_result).lower()\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞\n        dependencies = []\n        \n        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n        if (\"data_collection\" in planning_text or \n            \"—Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\" in planning_text or \n            context.get('needs_data_collection', True) or\n            context.get('unanalyzed_count', 0) == 0):\n            \n            from datetime import datetime, timedelta\n\n            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∞—Ç—ã\n            days_back = kwargs.get(\"days_back\", 1)\n            end_date = datetime.now()\n            start_date = end_date - timedelta(days=days_back-1)\n            start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)\n\n            tasks.append(TaskRequest(\n                task_type=TaskType.DATA_COLLECTION,\n                priority=TaskPriority.HIGH,\n                params={\n                    \"days_back\": kwargs.get(\"days_back\", 1),\n                    \"force_update\": True,\n                    \"start_date\": start_date, \n                    \"end_date\": end_date \n                },\n                reasoning=\"–ù–µ–æ–±—Ö–æ–¥–∏–º —Å–±–æ—Ä —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤\"\n            ))\n            dependencies.append(\"data_collection\")\n        \n        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞\n        if (context.get('unanalyzed_count', 0) > 0 or \n            \"message_analysis\" in planning_text or\n            \"–∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π\" in planning_text):\n            \n            tasks.append(TaskRequest(\n                task_type=TaskType.MESSAGE_ANALYSIS,\n                priority=TaskPriority.NORMAL,\n                params={\n                    \"limit\": min(context.get('unanalyzed_count', 100), 1500),\n                    \"batch_size\": 40\n                },\n                dependencies=dependencies.copy(),\n                reasoning=f\"–ù—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {context.get('unanalyzed_count', 0)} –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\"\n            ))\n            dependencies.append(\"message_analysis\")\n        \n        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\n        if (context.get('low_confidence_count', 0) > 0 or\n            \"categorization_review\" in planning_text or\n            \"–ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏\" in planning_text or\n            \"–∫—Ä–∏—Ç–∏–∫\" in planning_text):\n            \n            tasks.append(TaskRequest(\n                task_type=TaskType.CATEGORIZATION_REVIEW,\n                priority=TaskPriority.NORMAL,\n                params={\n                    \"confidence_threshold\": 3,\n                    \"limit\": min(context.get('low_confidence_count', 50), 100)\n                },\n                dependencies=dependencies.copy(),\n                reasoning=f\"–ù—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é {context.get('low_confidence_count', 0)} —Å–æ–æ–±—â–µ–Ω–∏–π —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é\"\n            ))\n            dependencies.append(\"categorization_review\")\n        \n        # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á–∏ –ø–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞–º\n        today = datetime.now().date()\n        has_digests = context.get('today_digests_count', 0) > 0\n        \n        if has_digests and (\"digest_update\" in planning_text or \"–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞\" in planning_text):\n            tasks.append(TaskRequest(\n                task_type=TaskType.DIGEST_UPDATE,\n                priority=TaskPriority.HIGH,\n                params={\n                    \"date\": today,\n                    \"digest_type\": \"both\"\n                },\n                dependencies=dependencies.copy(),\n                reasoning=\"–û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã –Ω–æ–≤—ã–º–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\"\n            ))\n        else:\n            tasks.append(TaskRequest(\n                task_type=TaskType.DIGEST_CREATION,\n                priority=TaskPriority.HIGH,\n                params={"
  },
  {
    "chunk_id": 43,
    "context_type": "business_logic",
    "size_tokens": 1492,
    "content": "                    \"date\": today,\n                    \"days_back\": kwargs.get(\"days_back\", 1),\n                    \"digest_type\": \"both\"\n                },\n                dependencies=dependencies.copy(),\n                reasoning=\"–°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"\n            ))\n        \n        logger.info(f\"Intelligent –ø–ª–∞–Ω —Å–æ–∑–¥–∞–Ω: {len(tasks)} –∑–∞–¥–∞—á\")\n        for i, task in enumerate(tasks, 1):\n            deps_str = f\" (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç: {', '.join(task.dependencies)})\" if task.dependencies else \"\"\n            logger.info(f\"  {i}. {task.task_type.value}{deps_str} - {task.reasoning}\")\n        \n        return tasks\n    \n    async def _fallback_planning(self, scenario: str, context: Dict[str, Any], **kwargs) -> List[TaskRequest]:\n        \"\"\"Fallback –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑ CrewAI\"\"\"\n        logger.info(\"–ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\")\n        \n        tasks = []\n        dependencies = []\n        \n        # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è daily_workflow\n        if scenario == \"daily_workflow\":\n            # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n            tasks.append(TaskRequest(\n                task_type=TaskType.DATA_COLLECTION,\n                priority=TaskPriority.HIGH,\n                params={\"days_back\": kwargs.get(\"days_back\", 1),\n                        \"force_update\": True\n                        },\n                reasoning=\"Fallback: —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è daily_workflow\"\n            ))\n            dependencies.append(\"data_collection\")\n            \n            # –ê–Ω–∞–ª–∏–∑ (–≤—Å–µ–≥–¥–∞, —Ç–∞–∫ –∫–∞–∫ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å confidence)\n            tasks.append(TaskRequest(\n                task_type=TaskType.MESSAGE_ANALYSIS,\n                priority=TaskPriority.NORMAL,\n                params={\"limit\": 100, \"batch_size\": 10},\n                dependencies=dependencies.copy(),\n                reasoning=\"Fallback: –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π (fix –¥–ª—è –Ω—É–ª–µ–≤–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏)\"\n            ))\n            dependencies.append(\"message_analysis\")\n            \n            # –ö—Ä–∏—Ç–∏–∫ (–≤—Å–µ–≥–¥–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞)\n            tasks.append(TaskRequest(\n                task_type=TaskType.CATEGORIZATION_REVIEW,\n                priority=TaskPriority.NORMAL,\n                params={\"confidence_threshold\": 3, \"limit\": 50},\n                dependencies=dependencies.copy(),\n                reasoning=\"Fallback: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏ –∫—Ä–∏—Ç–∏–∫–æ–º\"\n            ))\n            dependencies.append(\"categorization_review\")\n            \n            # –î–∞–π–¥–∂–µ—Å—Ç\n            tasks.append(TaskRequest(\n                task_type=TaskType.DIGEST_CREATION,\n                priority=TaskPriority.HIGH,\n                params={\n                    \"date\": datetime.now().date(),\n                    \"days_back\": kwargs.get(\"days_back\", 1),\n                    \"digest_type\": \"both\"\n                },\n                dependencies=dependencies.copy(),\n                reasoning=\"Fallback: —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\"\n            ))\n        \n        return tasks\n    \n    async def _execute_intelligent_plan(self, execution_plan: List[TaskRequest]) -> List[TaskResult]:\n        \"\"\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ intelligent –ø–ª–∞–Ω–∞ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º\"\"\"\n        results = []\n        completed_tasks = set()\n        failed_tasks = set()\n        \n        logger.info(f\"–ù–∞—á–∏–Ω–∞—é –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ intelligent –ø–ª–∞–Ω–∞ –∏–∑ {len(execution_plan)} –∑–∞–¥–∞—á\")\n        \n        # –í—ã–≤–æ–¥–∏–º –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n        for i, task in enumerate(execution_plan, 1):\n            deps_str = f\" (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç: {', '.join(task.dependencies)})\" if task.dependencies else \"\"\n            logger.info(f\"  –ü–ª–∞–Ω {i}: {task.task_type.value}{deps_str}\")\n            logger.info(f\"    –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {task.reasoning}\")\n        \n        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–¥–∞—á–∏ —Å —É—á–µ—Ç–æ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n        while len(completed_tasks) + len(failed_tasks) < len(execution_plan):\n            ready_tasks = []\n            \n            for task in execution_plan:\n                task_id = task.task_type.value\n                \n                if task_id in completed_tasks or task_id in failed_tasks:\n                    continue\n                \n                dependencies_met = all(dep in completed_tasks for dep in task.dependencies)\n                if dependencies_met:\n                    ready_tasks.append(task)\n            \n            if not ready_tasks:\n                remaining = [t.task_type.value for t in execution_plan \n                           if t.task_type.value not in completed_tasks and t.task_type.value not in failed_tasks]\n                logger.error(f\"Deadlock: –Ω–µ—Ç –≥–æ—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á. –û—Å—Ç–∞–≤—à–∏–µ—Å—è: {remaining}\")\n                break\n            \n            # –í—ã–ø–æ–ª–Ω—è–µ–º –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏\n            for task in ready_tasks:\n                logger.info(f\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏: {task.task_type.value}\")\n                logger.info(f\"  –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {task.reasoning}\")\n                \n                try:\n                    start_time = datetime.now()\n                    result = await self._execute_single_task(task)\n                    execution_time = (datetime.now() - start_time).total_seconds()\n                    \n                    task_result = TaskResult(\n                        task_id=task.task_type.value,\n                        task_type=task.task_type,\n                        status=TaskStatus.COMPLETED,\n                        result=result,\n                        execution_time=execution_time,\n                        completed_at=datetime.now()\n                    )\n                    \n                    results.append(task_result)\n                    completed_tasks.add(task.task_type.value)\n                    \n                    logger.info(f\"–ó–∞–¥–∞—á–∞ {task.task_type.value} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞ {execution_time:.2f}—Å\")\n                    \n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–¥–∞—á–∏ {task.task_type.value}: {str(e)}\")\n                    \n                    task_result = TaskResult(\n                        task_id=task.task_type.value,\n                        task_type=task.task_type,"
  },
  {
    "chunk_id": 44,
    "context_type": "business_logic",
    "size_tokens": 1480,
    "content": "                        status=TaskStatus.FAILED,\n                        error=str(e),\n                        execution_time=0,\n                        completed_at=datetime.now()\n                    )\n                    \n                    results.append(task_result)\n                    failed_tasks.add(task.task_type.value)\n        \n        logger.info(f\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø–µ—à–Ω–æ: {len(completed_tasks)}, —Å –æ—à–∏–±–∫–∞–º–∏: {len(failed_tasks)}\")\n        return results\n    \n    async def _execute_single_task(self, task: TaskRequest) -> Any:\n        \"\"\"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏\"\"\"\n        if not self.agent_registry:\n            raise Exception(\"Agent registry –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n        \n        if task.task_type == TaskType.DATA_COLLECTION:\n            collector = self.agent_registry.get_agent(\"data_collector\")\n            return await collector.collect_data(**task.params)\n            \n        elif task.task_type == TaskType.MESSAGE_ANALYSIS:\n            analyzer = self.agent_registry.get_agent(\"analyzer\")\n            return analyzer.analyze_messages(**task.params)\n            \n        elif task.task_type == TaskType.CATEGORIZATION_REVIEW:\n            critic = self.agent_registry.get_agent(\"critic\")\n            return critic.review_recent_categorizations(**task.params)\n            \n        elif task.task_type == TaskType.DIGEST_CREATION:\n            digester = self.agent_registry.get_agent(\"digester\")\n            return await self._execute_digest_creation_async(digester, task.params)\n            \n        elif task.task_type == TaskType.DIGEST_UPDATE:\n            digester = self.agent_registry.get_agent(\"digester\")\n            # DigesterAgent –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ update_digest, –∏—Å–ø–æ–ª—å–∑—É–µ–º create_digest —Å update_existing=True\n            task_params = task.params.copy()\n            task_params['update_existing'] = True\n            return await self._execute_digest_creation_async(digester, task_params)\n            \n        else:\n            raise Exception(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task.task_type}\")\n            \n    \n    async def _analyze_execution_results(self, results: List[TaskResult], scenario: str, context: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\"\"\"\n        successful_tasks = [r for r in results if r.status == TaskStatus.COMPLETED]\n        failed_tasks = [r for r in results if r.status == TaskStatus.FAILED]\n        \n        total_execution_time = sum(r.execution_time for r in results)\n        success_rate = len(successful_tasks) / len(results) if results else 0\n        \n        # –°–æ–±–∏—Ä–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É\n        summary = {\n            \"collected_messages\": 0,\n            \"analyzed_messages\": 0,\n            \"reviewed_messages\": 0,\n            \"created_digests\": [],\n            \"updated_digests\": []\n        }\n        \n        for result in successful_tasks:\n            if result.task_type == TaskType.DATA_COLLECTION and result.result:\n                summary[\"collected_messages\"] = result.result.get(\"total_new_messages\", 0)\n            elif result.task_type == TaskType.MESSAGE_ANALYSIS and result.result:\n                summary[\"analyzed_messages\"] = result.result.get(\"analyzed_count\", 0)\n            elif result.task_type == TaskType.CATEGORIZATION_REVIEW and result.result:\n                summary[\"reviewed_messages\"] = result.result.get(\"reviewed_count\", 0)\n            elif result.task_type == TaskType.DIGEST_CREATION and result.result:\n                if isinstance(result.result, dict) and \"brief_id\" in result.result:\n                    summary[\"created_digests\"].append(f\"brief (ID: {result.result['brief_id']})\")\n                if isinstance(result.result, dict) and \"detailed_id\" in result.result:\n                    summary[\"created_digests\"].append(f\"detailed (ID: {result.result['detailed_id']})\")\n            elif result.task_type == TaskType.DIGEST_UPDATE and result.result:\n                summary[\"updated_digests\"].append(str(result.result))\n        \n        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n        recommendations = []\n        \n        if failed_tasks:\n            recommendations.append({\n                \"type\": \"retry_failed\",\n                \"description\": f\"–ü–æ–≤—Ç–æ—Ä–∏—Ç—å {len(failed_tasks)} –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–¥–∞—á: {', '.join(t.task_type.value for t in failed_tasks)}\"\n            })\n        \n        if summary[\"collected_messages\"] > 50:\n            recommendations.append({\n                \"type\": \"high_volume\",\n                \"description\": f\"–°–æ–±—Ä–∞–Ω–æ {summary['collected_messages']} —Å–æ–æ–±—â–µ–Ω–∏–π - –º–Ω–æ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\"\n            })\n        \n        if summary[\"reviewed_messages\"] > 20:\n            recommendations.append({\n                \"type\": \"quality_issues\",\n                \"description\": f\"–ö—Ä–∏—Ç–∏–∫ –∏—Å–ø—Ä–∞–≤–∏–ª {summary['reviewed_messages']} —Å–æ–æ–±—â–µ–Ω–∏–π - –Ω—É–∂–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞\"\n            })\n        \n        if context.get('unanalyzed_count', 0) > 0 and summary[\"analyzed_messages\"] == 0:\n            recommendations.append({\n                \"type\": \"analysis_needed\",\n                \"description\": f\"–û—Å—Ç–∞–ª–∏—Å—å –Ω–µ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è ({context['unanalyzed_count']}) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑\"\n            })\n        \n        metrics = {\n            \"total_tasks\": len(results),\n            \"successful_tasks\": len(successful_tasks),\n            \"failed_tasks\": len(failed_tasks),\n            \"success_rate\": success_rate,\n            \"total_execution_time\": total_execution_time,\n            \"scenario\": scenario,\n            \"intelligent_planning\": True\n        }\n        \n        final_result = {\n            \"status\": \"success\" if not failed_tasks else \"partial_success\",\n            \"metrics\": metrics,\n            \"summary\": summary,\n            \"recommendations\": recommendations,\n            \"planning_context\": {\n                \"original_unanalyzed\": context.get('unanalyzed_count', 0),\n                \"original_low_confidence\": context.get('low_confidence_count', 0),"
  },
  {
    "chunk_id": 45,
    "context_type": "business_logic",
    "size_tokens": 1493,
    "content": "                \"original_digests_count\": context.get('today_digests_count', 0)\n            },\n            \"task_results\": [\n                {\n                    \"task\": r.task_type.value,\n                    \"status\": r.status.value,\n                    \"execution_time\": r.execution_time,\n                    \"error\": r.error\n                }\n                for r in results\n            ]\n        }\n        \n        logger.info(f\"–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω: {success_rate:.1%} —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏, \"\n                   f\"{total_execution_time:.1f}—Å –æ–±—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\")\n        \n        return final_result\n    async def _execute_digest_creation_async(self, agent, params: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n        try:\n            # create_digest - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                lambda: agent.create_digest(\n                    date=params.get(\"date\"),\n                    days_back=params.get(\"days_back\", 1),\n                    digest_type=params.get(\"digest_type\", \"both\"),\n                    update_existing=params.get(\"update_existing\", False),\n                    focus_category=params.get(\"focus_category\"),\n                    channels=params.get(\"channels\"),\n                    keywords=params.get(\"keywords\"),\n                    digest_id=params.get(\"digest_id\")\n                )\n            )\n            \n            digest_info = []\n            if result.get(\"brief_digest_id\"):\n                digest_info.append(f\"–∫—Ä–∞—Ç–∫–∏–π (ID: {result['brief_digest_id']})\")\n            if result.get(\"detailed_digest_id\"):\n                digest_info.append(f\"–ø–æ–¥—Ä–æ–±–Ω—ã–π (ID: {result['detailed_digest_id']})\")\n            \n            action = \"–æ–±–Ω–æ–≤–ª–µ–Ω\" if params.get(\"update_existing\") else \"—Å–æ–∑–¥–∞–Ω\"\n            logger.info(f\"–î–∞–π–¥–∂–µ—Å—Ç {action}: {', '.join(digest_info)}\")\n            return result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –¥–∞–π–¥–∂–µ—Å—Ç–æ–º: {str(e)}\")\n            return {\"status\": \"error\", \"error\": str(e)}\n        \n    def create_task(self) -> Task:\n        \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ CrewAI –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏\"\"\"\n        return Task(\n            description=\"–í—ã–ø–æ–ª–Ω–∏—Ç—å intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—é —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ —Å–∏—Å—Ç–µ–º—ã\",\n            agent=self.planning_agent,\n            expected_output=\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã intelligent –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\"\n        )\n    async def _perform_task_collaboration(self, task_type: TaskType, \n                                        standard_result: Any, context: Dict[str, Any]) -> Any:\n        \"\"\"\n        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∑–∞–¥–∞—á–∏\n        \n        Args:\n            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏\n            standard_result: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n            \n        Returns:\n            –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—é\n        \"\"\"\n        if not self.collaborative_crew:\n            return standard_result\n        \n        try:\n            logger.info(f\"ü§ù –ó–∞–ø—É—Å–∫ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –¥–ª—è {task_type.value}\")\n            \n            if task_type == TaskType.CATEGORIZATION_REVIEW:\n                # –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤\n                low_confidence_messages = context.get('low_confidence_messages', [])\n                \n                improved_results = []\n                for msg in low_confidence_messages[:3]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n                    collaboration_result = await self.collaborative_crew.collaborate_on_difficult_categorization(\n                        message_id=msg.get('id', 0),\n                        message_text=msg.get('text', ''),\n                        initial_category=msg.get('category', '–¥—Ä—É–≥–æ–µ'),\n                        confidence=msg.get('confidence', 1.0)\n                    )\n                    improved_results.append(collaboration_result)\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º\n                if hasattr(standard_result, 'collaborative_improvements'):\n                    standard_result.collaborative_improvements = improved_results\n                else:\n                    # –ï—Å–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å–ª–æ–≤–∞—Ä—å\n                    if isinstance(standard_result, dict):\n                        standard_result['collaborative_improvements'] = improved_results\n                \n                logger.info(f\"‚úÖ –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(improved_results)} —É–ª—É—á—à–µ–Ω–∏–π\")\n                \n            elif task_type == TaskType.DIGEST_CREATION:\n                # –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n                if isinstance(standard_result, dict) and 'content' in standard_result:\n                    quality_result = await self.collaborative_crew.collaborate_on_quality_assurance(\n                        digest_content=standard_result['content'],\n                        digest_type=standard_result.get('type', 'mixed'),\n                        categories_data=context.get('categories_data', {})\n                    )\n                    \n                    standard_result['quality_assessment'] = quality_result\n                    logger.info(f\"‚úÖ –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {quality_result.get('overall_score', 0):.1f}/5\")\n            \n            return standard_result\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏ –¥–ª—è {task_type.value}: {str(e)}\")\n            return standard_result\n    \n    async def _execute_task_with_collaboration(self, task_request: TaskRequest) -> TaskResult:\n        \"\"\"\n        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\n        \n        Args:\n            task_request: –ó–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏\n            \n        Returns:\n            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ (–≤–æ–∑–º–æ–∂–Ω–æ —É–ª—É—á—à–µ–Ω–Ω—ã–π —á–µ—Ä–µ–∑ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—é)\n        \"\"\""
  },
  {
    "chunk_id": 46,
    "context_type": "business_logic",
    "size_tokens": 2804,
    "content": "        start_time = datetime.now()\n        task_id = f\"{task_request.task_type.value}_{start_time.strftime('%H%M%S')}\"\n        \n        try:\n            logger.info(f\"üöÄ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ —Å –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–µ–π: {task_request.task_type.value}\")\n            \n            # –®–∞–≥ 1: –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∑–∞–¥–∞—á—É\n            standard_result = await self._execute_standard_task(task_request)\n            \n            # –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è\n            context = getattr(task_request, 'context', {})\n            should_collaborate = self._should_use_collaboration(task_request.task_type, context)\n            \n            # –®–∞–≥ 3: –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è - –≤—ã–ø–æ–ª–Ω—è–µ–º –µ—ë\n            final_result = standard_result\n            if should_collaborate:\n                final_result = await self._perform_task_collaboration(\n                    task_request.task_type, standard_result, context\n                )\n                logger.info(\"ü§ù –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ\")\n            \n            execution_time = (datetime.now() - start_time).total_seconds()\n            \n            return TaskResult(\n                task_id=task_id,\n                task_type=task_request.task_type,\n                status=TaskStatus.COMPLETED,\n                result=final_result,\n                execution_time=execution_time,\n                completed_at=datetime.now()\n            )\n            \n        except Exception as e:\n            execution_time = (datetime.now() - start_time).total_seconds()\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ {task_request.task_type.value}: {str(e)}\")\n            \n            return TaskResult(\n                task_id=task_id,\n                task_type=task_request.task_type,\n                status=TaskStatus.FAILED,\n                error=str(e),\n                execution_time=execution_time,\n                completed_at=datetime.now()\n            )\n    \n    async def _execute_standard_task(self, task_request: TaskRequest) -> Any:\n        \"\"\"\n        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∑–∞–¥–∞—á—É –±–µ–∑ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏–∏\n        \n        Args:\n            task_request: –ó–∞–ø—Ä–æ—Å –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏\n            \n        Returns:\n            –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏\n        \"\"\"\n        task_type = task_request.task_type\n        params = task_request.params or {}\n        \n        try:\n            if task_type == TaskType.DATA_COLLECTION:\n                collector = self.agent_registry.get_agent('data_collector')\n                if collector:\n                    return await collector.collect_data(**params)\n                else:\n                    raise Exception(\"Data collector –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n            \n            elif task_type == TaskType.MESSAGE_ANALYSIS:\n                analyzer = self.agent_registry.get_agent('analyzer')\n                if analyzer:\n                    return await analyzer.analyze_messages(**params)\n                else:\n                    raise Exception(\"Analyzer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n            \n            elif task_type == TaskType.CATEGORIZATION_REVIEW:\n                critic = self.agent_registry.get_agent('critic')\n                if critic:\n                    return await critic.review_recent_categorizations(**params)\n                else:\n                    raise Exception(\"Critic –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n            \n            elif task_type == TaskType.DIGEST_CREATION:\n                digester = self.agent_registry.get_agent('digester')\n                if digester:\n                    return await digester.create_digest(**params)\n                else:\n                    raise Exception(\"Digester –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n            \n            else:\n                raise Exception(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}\")\n                \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ {task_type.value}: {str(e)}\")\n            raise\n        # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤ –∫–ª–∞—Å—Å IntelligentOrchestratorAgent –≤ agents/orchestrator.py\n# (–µ—Å–ª–∏ –æ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n\n    def _should_use_collaboration(self, task_type: TaskType, context: Dict[str, Any]) -> bool:\n        \"\"\"\n        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–∞ –ª–∏ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏\n        \n        Args:\n            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏\n            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n            \n        Returns:\n            True –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è\n        \"\"\"\n        if not self.collaborative_crew:\n            return False\n        \n        collaboration_triggers = {\n            TaskType.CATEGORIZATION_REVIEW: (\n                context.get('low_confidence_messages', []) and\n                len(context.get('low_confidence_messages', [])) > 5\n            ),\n            TaskType.DIGEST_CREATION: (\n                context.get('categories_data', {}) and\n                len(context.get('categories_data', {})) > 10\n            ),\n            TaskType.MESSAGE_ANALYSIS: (\n                context.get('complex_messages', []) and\n                len(context.get('complex_messages', [])) > 3\n            )\n        }\n        \n        should_collaborate = collaboration_triggers.get(task_type, False)\n        \n        if should_collaborate:\n            logger.info(f\"ü§ù –ö–æ–ª–ª–∞–±–æ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ –¥–ª—è {task_type.value}\")\n        \n        return should_collaborate\n\n=== digester.py ===\n\"\"\"\n–ê–≥–µ–Ω—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\n\"\"\"\nimport logging\nimport re\nimport json\nfrom datetime import datetime, time, timedelta\nfrom crewai import Agent, Task\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom config.settings_cop2 import CATEGORIES, BOT_USERNAME\nfrom llm.gemma_model import GemmaLLM\nfrom langchain.tools import Tool\nlogger = logging.getLogger(__name__)\n\nclass DigesterAgent:\n    \"\"\"–ê–≥–µ–Ω—Ç –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n    \n    def __init__(self, db_manager, llm_model=None):\n        \"\"\"\n        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\n        \n        Args:\n            db_manager (DatabaseManager): –ú–µ–Ω–µ–¥–∂–µ—Ä –ë–î\n            llm_model (GemmaLLM, optional): –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n        \"\"\"\n        self.db_manager = db_manager\n        self.llm_model = llm_model or GemmaLLM()\n        \n        create_digest_tool = Tool(\n            name=\"create_digest\",\n            func=self.create_digest,\n            description=\"–§–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π\"\n        )\n\n        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞ CrewAI\n        self.agent = Agent(\n            name=\"Digester\",\n            role=\"–î–∞–π–¥–∂–µ—Å—Ç-–º–µ–π–∫–µ—Ä\",\n            goal=\"–§–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ –ø—Ä–∞–≤–æ–≤—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏—è–º\",\n            backstory=\"–Ø —Å–æ–∑–¥–∞—é –∫—Ä–∞—Ç–∫–∏–µ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –æ–±–∑–æ—Ä—ã –ø—Ä–∞–≤–æ–≤—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\",\n            verbose=True,\n            tools=[create_digest_tool]\n        )\n    def _extract_title_for_url(self, text, url):\n         \n        \"\"\"\n        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –¥–ª—è URL –∏–∑ @dumainfo\n        \"\"\"\n        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –∫–∞–Ω–∞–ª–∞ –¥—É–º—ã\n        if \"@dumainfo\" in url or \"dumainfo\" in text:\n            # –†–∞–∑–¥–µ–ª–∏–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ –Ω–∞–π–¥–µ–º –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫\n            lines = text.split('\\n')\n            for i, line in enumerate(lines):\n                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏\n                if len(line.strip()) < 10 or \"–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è –î—É–º–∞\" in line:\n                    continue\n                \n                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫\n                if len(line.strip()) > 15 and \"http\" not in line and \"@\" not in line:\n                    return line.strip()\n        # –†–∞–∑–¥–µ–ª–∏–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–æ –∏ –ø–æ—Å–ª–µ URL\n        parts = text.split(url)\n        \n        if len(parts) < 2:\n            return url[:50] + \"...\" if len(url) > 50 else url\n        \n        before_url = parts[0]\n        after_url = parts[1]\n        \n        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–µ—Ä–µ–¥ URL\n        before_paragraphs = before_url.split('\\n\\n')\n        last_paragraph = before_paragraphs[-1] if before_paragraphs else \"\"\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏\n        if \"–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è –î—É–º–∞\" in last_paragraph or \"VK\" in last_paragraph or len(last_paragraph.strip()) < 20:\n            # –ò—â–µ–º –±–æ–ª–µ–µ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–æ–∫–∞—Ö\n            lines = text.split('\\n')\n            for line in lines[1:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫\n                line = line.strip()\n                if len(line) > 30 and \"http\" not in line and \"Telegram\" not in line:\n                    return line[:100] + \"...\" if len(line) > 100 else line\n        \n        # –î–∞–ª–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞\n        sentences = last_paragraph.split('.')\n        candidate_title = sentences[-1].strip() if sentences else last_paragraph.strip()\n        \n        # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ—Å–ª–µ URL\n        if len(candidate_title) < 15:\n            after_paragraphs = after_url.split('\\n\\n')\n            first_paragraph = after_paragraphs[0] if after_paragraphs else \"\"\n            sentences = first_paragraph.split('.')\n            candidate_title = sentences[0].strip() if sentences else first_paragraph.strip()\n        \n        # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫\n        candidate_title = candidate_title.replace(\"\\n\", \" \").strip()\n        \n        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–≥–æ–ª–æ–≤–∫–∞\n        if len(candidate_title) > 80:\n            candidate_title = candidate_title[:77] + \"...\"\n        \n        return candidate_title\n    def _add_category_icon(self, category):\n        \"\"\"\n        –î–æ–±–∞–≤–ª—è–µ—Ç –∏–∫–æ–Ω–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \n        Args:\n            category (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            \n        Returns:\n            str: –ò–∫–æ–Ω–∫–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \"\"\"\n        icons = {\n            '–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã': 'üìù',\n            '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞': '‚öñÔ∏è',\n            '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã': 'üìú',\n            '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º': '‚úèÔ∏è',\n            '–¥—Ä—É–≥–æ–µ': 'üìå'\n        }\n        return icons.get(category, '‚Ä¢')\n\n    def _clean_text_with_links(self, text):\n        \"\"\"\n        –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è —Å—Å—ã–ª–æ–∫ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n        \"\"\"\n        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ URL –≤ —Ç–µ–∫—Å—Ç–µ\n        url_pattern = r'https?://[^\\s\\)\\]\\>]+'\n        urls = re.findall(url_pattern, text)\n        \n        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã URL, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ URL\n        for url in set(urls):\n            if urls.count(url) > 1:\n                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ —ç—Ç–æ–≥–æ URL\n                positions = [m.start() for m in re.finditer(re.escape(url), text)]\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ\n                for pos in positions[1:]:\n                    end_pos = pos + len(url)\n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å—é markdown —Å—Å—ã–ª–∫–∏\n                    if pos > 0 and text[pos-1:pos] == '(' and end_pos < len(text) and text[end_pos:end_pos+1] == ')':\n                        # –ù–∞—Ö–æ–¥–∏–º –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é —Å–∫–æ–±–∫—É –ø–µ—Ä–µ–¥ URL\n                        bracket_pos = text.rfind('[', 0, pos)\n                        if bracket_pos != -1:\n                            # –≠—Ç–æ —á–∞—Å—Ç—å markdown —Å—Å—ã–ª–∫–∏, –Ω–µ —É–¥–∞–ª—è–µ–º\n                            continue\n                    \n                    # –£–¥–∞–ª—è–µ–º URL\n                    text = text[:pos] + text[end_pos:]\n                    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–π\n                    positions = [p - len(url) if p > pos else p for p in positions]\n        "
  },
  {
    "chunk_id": 47,
    "context_type": "business_logic",
    "size_tokens": 1492,
    "content": "        # –ó–∞–º–µ–Ω—è–µ–º –æ–±—ã—á–Ω—ã–µ URL –Ω–∞ markdown —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é markdown\n        for url in set(urls):\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL —á–∞—Å—Ç—å—é markdown —Å—Å—ã–ª–∫–∏\n            if not re.search(r'\\[.*?\\]\\(' + re.escape(url) + r'\\)', text):\n                # –ó–¥–µ—Å—å –º—ã –ù–ï –±—É–¥–µ–º –¥–æ–±–∞–≤–ª—è—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏–π —Ç–µ–∫—Å—Ç\n                # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ URL –∫–∞–∫ –µ—Å—Ç—å –∏–ª–∏ –¥–µ–ª–∞–µ–º –ø—Ä–æ—Å—Ç—É—é —Å—Å—ã–ª–∫—É\n                # –ù–ï –¥–µ–ª–∞–µ–º: new_link = f\"[{url}]({url})\"\n                continue  # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –Ω–µ –º–µ–Ω—è–µ–º –æ–±—ã—á–Ω—ã–µ URL\n        \n        return text\n    def _extract_links_and_headlines(self, text):\n        \"\"\"\n        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è\n        \n        Args:\n            text (str): –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è\n            \n        Returns:\n            list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å—Å—ã–ª–∫–∞–º–∏\n        \"\"\"\n        results = []\n        \n        # –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ [—Ç–µ–∫—Å—Ç](—Å—Å—ã–ª–∫–∞)\n        markdown_pattern = r'\\[(.*?)\\]\\((https?://[^\\s\\)]+)\\)'\n        markdown_links = re.findall(markdown_pattern, text)\n        \n        for title, url in markdown_links:\n            # –£–¥–æ—Å—Ç–æ–≤–µ—Ä–∏–º—Å—è, —á—Ç–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ –ø—É—Å—Ç–æ–π –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π\n            if title and len(title.strip()) > 3:\n                results.append({\n                    \"title\": title.strip(),\n                    \"url\": url.strip(),\n                    \"is_markdown\": True\n                })\n        \n        # –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–±—ã—á–Ω—ã—Ö URL\n        url_pattern = r'https?://[^\\s\\)\\]\\>]+'\n        \n        # –ù–∞—Ö–æ–¥–∏–º URL, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ\n        all_urls = re.findall(url_pattern, text)\n        markdown_urls = [link[1] for link in markdown_links]\n        \n        for url in all_urls:\n            if url not in markdown_urls and url.strip():\n                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —ç—Ç–æ–≥–æ URL\n                title = self._extract_title_for_url(text, url)\n                \n                results.append({\n                    \"title\": title,\n                    \"url\": url.strip(),\n                    \"is_markdown\": False\n                })\n        \n        return results\n    \n    def _generate_brief_section(self, category, messages):\n        \"\"\"\n        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å—Å—ã–ª–∫–∞–º–∏\n        \"\"\"\n        logger.info(f\"–ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'. –ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π.\")\n\n        if not messages:\n            return f\"–ó–∞ –¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\"\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Å—ã–ª–∫–∞—Ö\n        all_items = []\n        \n        for msg in messages:\n            try:\n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ msg - —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞\n                if hasattr(msg, 'text'):\n                    # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏\n                    links = self._extract_links_and_headlines(msg.text)\n                    \n                    if links:\n                        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å—Å—ã–ª–∫–∏, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –∏–∑ –Ω–∏—Ö\n                        for link in links:\n                            all_items.append({\n                                \"title\": link[\"title\"],\n                                \"url\": link[\"url\"],\n                                \"channel\": msg.channel,\n                                \"date\": msg.date,\n                                \"message_id\": msg.id,\n                                \"has_url\": True\n                            })\n                    else:\n                        # –ï—Å–ª–∏ —Å—Å—ã–ª–æ–∫ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å–∞–º–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫\n                        first_line = msg.text.split('\\n')[0]\n                        title = first_line[:100] + \"...\" if len(first_line) > 100 else first_line\n                        \n                        all_items.append({\n                            \"title\": title,\n                            \"url\": f\"https://t.me/{BOT_USERNAME}?start=msg_{msg.id}\",\n                            \"channel\": msg.channel,\n                            \"date\": msg.date,\n                            \"message_id\": msg.id,\n                            \"has_url\": False  # –û—Ç–º–µ—á–∞–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–∞—è —Å—Å—ã–ª–∫–∞\n                        })\n                else:\n                    # –ï—Å–ª–∏ msg –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏—è, –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º\n                    logger.warning(f\"–≠–ª–µ–º–µ–Ω—Ç –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—ä–µ–∫—Ç–æ–º Message: {type(msg)}\")\n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {str(e)}\")\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n        if not all_items:\n            logger.warning(f\"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n            return f\"–ó–∞ –¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å.\"\n        \n        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–∞—Ç–µ (—Å–Ω–∞—á–∞–ª–∞ —Å–∞–º—ã–µ –Ω–æ–≤—ã–µ)\n        all_items.sort(key=lambda x: x[\"date\"], reverse=True)\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å–µ–∫—Ü–∏–∏\n        category_icon = self._add_category_icon(category)\n        section_text = f\"## {category_icon} {category.upper()}\\n\\n\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        category_descriptions = {\n            '–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã': \"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤—ã—Ö –∑–∞–∫–æ–Ω–æ–≤, –Ω–∞—Ö–æ–¥—è—â–∏–µ—Å—è –Ω–∞ —Å—Ç–∞–¥–∏–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è\",\n            '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞': \"–†–µ—à–µ–Ω–∏—è –∏ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è —Å—É–¥–æ–≤, —Å–æ–∑–¥–∞—é—â–∏–µ –ø—Ä–µ—Ü–µ–¥–µ–Ω—Ç—ã\",\n            '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã': \"–ù–µ–¥–∞–≤–Ω–æ –ø—Ä–∏–Ω—è—Ç—ã–µ –∏ –≤—Å—Ç—É–ø–∏–≤—à–∏–µ –≤ —Å–∏–ª—É –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∞–∫—Ç—ã\",\n            '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º': \"–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–∫–æ–Ω–∞—Ö\",\n            '–¥—Ä—É–≥–æ–µ': \"–î—Ä—É–≥–∏–µ –ø—Ä–∞–≤–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\"\n        }\n        \n        description = category_descriptions.get(category, \"\")\n        if description:\n            section_text += f\"{description}:\\n\\n\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è —Ç–µ, –≥–¥–µ –Ω–µ—Ç —Å—Å—ã–ª–æ–∫"
  },
  {
    "chunk_id": 48,
    "context_type": "business_logic",
    "size_tokens": 1485,
    "content": "        for idx, item in enumerate(all_items):\n            formatted_date = item[\"date\"].strftime(\"%d.%m.%Y\")\n            channel_name = item[\"channel\"]\n            \n            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é —Å–æ–æ–±—â–µ–Ω–∏—è\n            message = self.db_manager.get_message_by_id(item[\"message_id\"])\n            annotation = self._generate_short_annotation(message.text)\n\n            if item[\"has_url\"]:\n                # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞—Å—Ç–æ—è—â–∞—è —Å—Å—ã–ª–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º HTML-—Ñ–æ—Ä–º–∞—Ç\n                section_text += f\"<b>{idx+1}.</b> <a href='{item['url']}'>{item['title']}</a> - {channel_name}, {formatted_date}\\n<i>{annotation}</i>\\n\\n\"\n            else:\n                # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Å—ã–ª–∫–∏, –ø—Ä–æ—Å—Ç–æ –≤—ã–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç —Å HTML-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º\n                section_text += f\"<b>{idx+1}.</b> <b>{item['title']}</b> - {channel_name}, {formatted_date}\\n<i>{annotation}</i>\\n\\n\"\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä\n        section_text += f\"\\n[–û—Ç–∫—Ä—ã—Ç—å –ø–æ–ª–Ω—ã–π –æ–±–∑–æ—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'](/category/{category})\\n\"\n    \n        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ—á–µ–∫ –ø–æ—Å–ª–µ —Ü–∏—Ñ—Ä\n        section_text = re.sub(r'(\\d+)\\\\\\.\\s*', r'\\1. ', section_text)\n        return section_text\n\n    def _generate_short_annotation(self, text, max_length=150):\n        \"\"\"\n        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞\n        \"\"\"\n        # –£–¥–∞–ª—è–µ–º URL –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã\n        text = re.sub(r'https?://\\S+', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã\n        paragraphs = text.split('\\n\\n')\n        \n        # –ò—â–µ–º —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –∞–±–∑–∞—Ü, –æ—Ç–ª–∏—á–Ω—ã–π –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞\n        first_paragraph = paragraphs[0] if paragraphs else \"\"\n        content_paragraph = None\n        \n        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –Ω–µ—è–≤–ª—è—é—â–∏–π—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∞–±–∑–∞—Ü \n        for paragraph in paragraphs[1:]:\n            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –∞–±–∑–∞—Ü—ã\n            clean_paragraph = paragraph.strip()\n            if len(clean_paragraph) < 30 or clean_paragraph.startswith(\"http\") or \"@\" in clean_paragraph:\n                continue\n                \n            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ—Ç –∞–±–∑–∞—Ü –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n            content_paragraph = clean_paragraph\n            break\n        \n        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∞–±–∑–∞—Ü, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π\n        if not content_paragraph:\n            if len(paragraphs) > 1 and len(paragraphs[1].strip()) > 20:\n                content_paragraph = paragraphs[1].strip()\n            else:\n                content_paragraph = first_paragraph\n        \n        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n        sentences = re.split(r'(?<=[.!?])\\s+', content_paragraph)\n        annotation = sentences[0] if sentences else content_paragraph\n        \n        # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –æ–±—Ä–µ–∑–∞–µ–º\n        if len(annotation) > max_length:\n            # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–æ—á–∫—É –ø–µ—Ä–µ–¥ –ª–∏–º–∏—Ç–æ–º\n            last_period = annotation[:max_length].rfind('.')\n            if last_period > max_length // 2:  # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤–æ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ\n                annotation = annotation[:last_period+1]\n            else:\n                # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –≤ –Ω–∞—á–∞–ª–µ, –æ–±—Ä–µ–∑–∞–µ–º –ø–æ —Å–ª–æ–≤–∞–º\n                words = annotation[:max_length].split()\n                annotation = ' '.join(words[:-1]) + '...'\n        \n        return annotation\n    \n    def _generate_detailed_section(self, category, messages):\n        \"\"\"\n        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±–∑–æ—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \n        Args:\n            category (str): –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π\n            messages (list): –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            \n        Returns:\n            str: –¢–µ–∫—Å—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±–∑–æ—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \"\"\"\n        logger.info(f\"–ù–∞—á–∞–ª–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±–∑–æ—Ä–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'. –ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π.\")\n        \n        if not messages:\n            logger.warning(f\"–°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –ø—É—Å—Ç\")\n            return f\"–ó–∞ –¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\"\n        \n        # –õ–æ–≥–≥–∏—Ä—É–µ–º —Ç–∏–ø—ã –ø–µ—Ä–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n        logger.info(f\"–¢–∏–ø—ã –ø–µ—Ä–≤—ã—Ö 3 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}':\")\n        for i, msg in enumerate(messages[:3]):\n            logger.info(f\"  –≠–ª–µ–º–µ–Ω—Ç {i}: —Ç–∏–ø={type(msg)}, –∞—Ç—Ä–∏–±—É—Ç—ã={dir(msg) if hasattr(msg, '__dict__') else '–ù–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–æ–≤'}\")\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∫–æ–Ω–∫—É –∫ –Ω–∞–∑–≤–∞–Ω–∏—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        category_icon = self._add_category_icon(category)\n        category_display = f\"{category_icon} {category}\"\n        \n        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Ä–∞–∑–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞\n        MAX_MESSAGES = 5  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π\n        MAX_MESSAGE_LENGTH = 1500  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\n        \n        # –û—á–∏—â–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏–π\n        cleaned_messages = []\n        for i, msg in enumerate(messages[:MAX_MESSAGES]):\n            try:\n                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ msg - —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –∞ –Ω–µ —Å—Ç—Ä–æ–∫–∞\n                if hasattr(msg, 'text'):\n                    # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n                    message_text = msg.text\n                    logger.debug(f\"–°–æ–æ–±—â–µ–Ω–∏–µ {i} –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ = {len(message_text)}\")\n                    \n                    if len(message_text) > MAX_MESSAGE_LENGTH:\n                        message_text = message_text[:MAX_MESSAGE_LENGTH] + \"... (—Ç–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω)\"\n                        \n                    cleaned_text = self._clean_text_with_links(message_text)\n                    cleaned_messages.append(\n                        f\"–ö–∞–Ω–∞–ª: {msg.channel}\\n–î–∞—Ç–∞: {msg.date.strftime('%d.%m.%Y')}\\n\\n{cleaned_text}\"\n                    )\n                else:\n                    # –ï—Å–ª–∏ msg - –Ω–µ –æ–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è, –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n                    logger.error(f\"–°–æ–æ–±—â–µ–Ω–∏–µ {i} –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞ 'text'\")\n                    logger.error(f\"–¢–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è: {type(msg)}\")\n                    if isinstance(msg, dict):"
  },
  {
    "chunk_id": 49,
    "context_type": "business_logic",
    "size_tokens": 1485,
    "content": "                        logger.error(f\"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–ª–æ–≤–∞—Ä—è: {msg}\")\n                    elif isinstance(msg, str):\n                        logger.error(f\"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–æ–∫–∏: {msg[:100]}\")\n                    else:\n                        logger.error(f\"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã: {dir(msg)}\")\n                    \n                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞\n                    logger.error(f\"–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: {str(msg)}\")\n            except Exception as e:\n                logger.exception(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è {i} –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {str(e)}\")\n        \n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n        if not cleaned_messages:\n            logger.warning(f\"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n            return f\"–ó–∞ –¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å.\"\n        \n        logger.info(f\"–£—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(cleaned_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è LLM\n        messages_text = \"\\n\\n---\\n\\n\".join(cleaned_messages)\n        \n        try:\n            # –ë–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π –∏ —Ç–æ—á–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n            prompt = f\"\"\"\n            –°–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n            \n            {messages_text}\n            \n            –û–±–∑–æ—Ä –¥–æ–ª–∂–µ–Ω:\n            1. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è\n            2. –£–ø–æ–º—è–Ω—É—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–∫–∞–Ω–∞–ª—ã)\n            3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏\n            4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **–ø–æ–ª—É–∂–∏—Ä–Ω–æ–µ –≤—ã–¥–µ–ª–µ–Ω–∏–µ** –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤\n            5. –ë—ã—Ç—å 2-3 –∞–±–∑–∞—Ü–∞ –¥–ª–∏–Ω–æ–π\n            \"\"\"\n            \n            logger.info(f\"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n            response = self.llm_model.generate(prompt, max_tokens=1500, temperature=0.7)\n            \n            if not response or len(response.strip()) < 50:\n                logger.warning(f\"–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n                raise ValueError(\"–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç\")\n                \n            logger.info(f\"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}', –¥–ª–∏–Ω–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤\")\n            return response\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–±–∑–æ—Ä–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {str(e)}\", exc_info=True)\n            \n            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π –æ–±–∑–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ—é—â–∏—Ö—Å—è —Å–æ–æ–±—â–µ–Ω–∏–π\n            fallback_text = f\"–û–±–∑–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}':\\n\\n\"\n            for i, msg in enumerate(messages[:5]):\n                try:\n                    if hasattr(msg, 'channel') and hasattr(msg, 'date') and hasattr(msg, 'text'):\n                        channel_name = msg.channel\n                        date_str = msg.date.strftime(\"%d.%m.%Y\")\n                        \n                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É\n                        lines = msg.text.split('\\n')\n                        title = lines[0][:100]\n                        if len(title) == 100:\n                            title += \"...\"\n                            \n                        fallback_text += f\"**{i+1}.** {title} (–ò—Å—Ç–æ—á–Ω–∏–∫: {channel_name}, {date_str})\\n\\n\"\n                    else:\n                        logger.warning(f\"–ü—Ä–æ–ø—É—Å–∫ —Å–æ–æ–±—â–µ–Ω–∏—è {i} –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - –Ω–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤\")\n                except Exception as inner_e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è {i}: {str(inner_e)}\")\n            \n            logger.info(f\"–°–æ–∑–¥–∞–Ω —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}', –¥–ª–∏–Ω–∞: {len(fallback_text)} —Å–∏–º–≤–æ–ª–æ–≤\")\n            return fallback_text\n\n    def _generate_digest_intro(self, date, total_messages, categories_count, is_brief=True, days_back=1):\n        \"\"\"\n        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–≤–æ–¥–Ω–æ–π —á–∞—Å—Ç–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n    \n        Args:\n            date (datetime): –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            total_messages (int): –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π\n            categories_count (dict): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n            is_brief (bool): –ü—Ä–∏–∑–Ω–∞–∫ –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            days_back (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π, –∑–∞ –∫–æ—Ç–æ—Ä—ã–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –¥–∞–π–¥–∂–µ—Å—Ç\n            \n        Returns:\n            str: –¢–µ–∫—Å—Ç –≤–≤–æ–¥–Ω–æ–π —á–∞—Å—Ç–∏\n        \"\"\"\n        formatted_date = date.strftime(\"%d.%m.%Y\")\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –ø–µ—Ä–∏–æ–¥–æ–º\n        period_text = formatted_date\n        if days_back > 1:\n            start_date = (date - timedelta(days=days_back-1)).strftime(\"%d.%m.%Y\")\n            period_text = f\"–ø–µ—Ä–∏–æ–¥ —Å {start_date} –ø–æ {formatted_date}\"\n        \n        categories_info = \"\\n\".join([f\"- {cat}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π\" for cat, count in categories_count.items() if count > 0])\n        \n        prompt = f\"\"\"\n        –ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–µ –∫ {\"–∫—Ä–∞—Ç–∫–æ–º—É\" if is_brief else \"–ø–æ–¥—Ä–æ–±–Ω–æ–º—É\"} –¥–∞–π–¥–∂–µ—Å—Ç—É –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ {period_text}.\n        \n        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è:\n        - –ü–µ—Ä–∏–æ–¥: {period_text}\n        - –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}\n        - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n        {categories_info}\n        \n        –í—Å—Ç—É–ø–ª–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º (1-2 –∞–±–∑–∞—Ü–∞) –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–±—â—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥.\n        {\"–£–ø–æ–º—è–Ω–∏, —á—Ç–æ —ç—Ç–æ –∫—Ä–∞—Ç–∫–∞—è –≤–µ—Ä—Å–∏—è, –∏ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ —Å—Å—ã–ª–∫–∞–º.\" if is_brief else \"–£–ø–æ–º—è–Ω–∏, —á—Ç–æ —ç—Ç–æ –ø–æ–¥—Ä–æ–±–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞.\"}\n        \"\"\"\n        \n        try:\n            response = self.llm_model.generate(prompt, max_tokens=300)\n            return response\n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –∫ –¥–∞–π–¥–∂–µ—Å—Ç—É: {str(e)}\")\n            intro_text = f\"# –î–∞–π–¥–∂–µ—Å—Ç –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ {formatted_date}\"\n            if is_brief:\n                intro_text += \"\\n\\n*–ö—Ä–∞—Ç–∫–∞—è –≤–µ—Ä—Å–∏—è. –î–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–∞–º.*\"\n            else:\n                intro_text += \"\\n\\n*–ü–æ–¥—Ä–æ–±–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞.*\"\n            return intro_text\n    "
  },
  {
    "chunk_id": 50,
    "context_type": "business_logic",
    "size_tokens": 1496,
    "content": "    def _process_categories_parallel(self, categories_to_process, messages_by_category, digest_type):\n        \"\"\"\n        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–∫—Ü–∏–π –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        \"\"\"\n        results = {}\n        \n        logger.info(f\"–ù–∞—á–∞–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(categories_to_process)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è —Ç–∏–ø–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ '{digest_type}'\")\n        for category in categories_to_process:\n            logger.info(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': {len(messages_by_category[category])} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n        \n        with ThreadPoolExecutor(max_workers=min(4, len(categories_to_process))) as executor:\n            future_to_category = {}\n            \n            for category in categories_to_process:\n                logger.info(f\"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n                if digest_type == \"brief\":\n                    future = executor.submit(\n                        self._generate_brief_section, category, messages_by_category[category]\n                    )\n                else:\n                    future = executor.submit(\n                        self._generate_detailed_section, category, messages_by_category[category]\n                    )\n                future_to_category[future] = category\n            \n            for future in as_completed(future_to_category):\n                category = future_to_category[future]\n                try:\n                    logger.info(f\"–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'\")\n                    section_text = future.result()\n                    results[category] = section_text\n                    logger.info(f\"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{category}', –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(section_text)} —Å–∏–º–≤–æ–ª–æ–≤\")\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}': {str(e)}\", exc_info=True)\n        \n        logger.info(f\"–ó–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –∏–∑ {len(categories_to_process)}\")\n        return results\n\n    def create_digest(self, date=None, days_back=1, digest_type=\"both\", \n                update_existing=True, focus_category=None,\n                channels=None, keywords=None, digest_id=None):\n        \"\"\"\n        –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n        \n        Args:\n            date (datetime, optional): –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ–≥–æ–¥–Ω—è)\n            days_back (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è —Å–±–æ—Ä–∞ —Å–æ–æ–±—â–µ–Ω–∏–π\n            digest_type (str): –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞: \"brief\", \"detailed\", \"both\"\n            update_existing (bool): –û–±–Ω–æ–≤–ª—è—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π\n            focus_category (str, optional): –§–æ–∫—É—Å –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n            channels (list, optional): –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n            keywords (list, optional): –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n            digest_id (int, optional): ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        \"\"\"\n        logger.info(f\"–ó–∞–ø—Ä–æ—Å –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞: date={date}, days_back={days_back}, —Ç–∏–ø={digest_type}\")\n\n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—á–Ω—É—é –¥–∞—Ç—É\n        if date:\n            # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –¥–∞—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–µ—Ü —ç—Ç–æ–≥–æ –¥–Ω—è\n            end_date = datetime.combine(date.date() if isinstance(date, datetime) else date, \n                                    time(23, 59, 59))\n            \n            # –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ - —ç—Ç–æ –Ω–∞—á–∞–ª–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∞—Ç—ã –º–∏–Ω—É—Å (days_back-1) –¥–Ω–µ–π\n            if days_back == 1:\n                # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω 1 –¥–µ–Ω—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É\n                start_date = datetime.combine(end_date.date(), time(0, 0, 0))\n                logger.info(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É: —Å {start_date.strftime('%Y-%m-%d %H:%M')} \"\n                        f\"–ø–æ {end_date.strftime('%Y-%m-%d %H:%M')}\")\n            else:\n                # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –±–æ–ª—å—à–µ –¥–Ω–µ–π, –æ—Ç—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–∞–∑–∞–¥\n                start_date = (end_date - timedelta(days=days_back-1)).replace(hour=0, minute=0, second=0)\n                logger.info(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ {days_back} –¥–Ω–µ–π: —Å {start_date.strftime('%Y-%m-%d %H:%M')} \"\n                        f\"–ø–æ {end_date.strftime('%Y-%m-%d %H:%M')}\")\n        else:\n            # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ –∑–∞–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è\n            end_date = datetime.now()\n            \n            if days_back == 1:\n                # –î–ª—è –æ–¥–Ω–æ–≥–æ –¥–Ω—è - —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–µ —Å—É—Ç–∫–∏\n                start_date = datetime.combine(end_date.date(), time(0, 0, 0))\n                logger.info(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å: —Å {start_date.strftime('%Y-%m-%d %H:%M')} \"\n                        f\"–ø–æ {end_date.strftime('%Y-%m-%d %H:%M')}\")\n            else:\n                # –î–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–Ω–µ–π - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥\n                start_date = (end_date - timedelta(days=days_back-1)).replace(hour=0, minute=0, second=0)\n                logger.info(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–∏–æ–¥ –∏–∑ {days_back} –¥–Ω–µ–π –¥–æ —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞: \"\n                        f\"—Å {start_date.strftime('%Y-%m-%d %H:%M')} –ø–æ {end_date.strftime('%Y-%m-%d %H:%M')}\")\n        \n        logger.info(f\"–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}, —Ç–∏–ø: {digest_type}\")\n        \n        # –ë–õ–û–ö 1: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–ï–ì–û–î–ù–Ø–®–ù–ï–ì–û –î–ê–ô–î–ñ–ï–°–¢–ê\n        # –ë–ª–æ–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –≤ create_digest\n        today = datetime.now().date()\n        is_today_digest = end_date.date() == today\n\n        if is_today_digest:\n            logger.info(\"–°–æ–∑–¥–∞–µ—Ç—Å—è –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ —Å–µ–≥–æ–¥–Ω—è - –æ–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥–∏ is_today\")\n            try:\n                # –í—ã–∑—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–ª–∞–≥–æ–≤ –ü–ï–†–ï–î —Å–æ–∑–¥–∞–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n                update_result = self.db_manager.update_today_flags()\n                if \"error\" in update_result:\n                    logger.warning(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–ª–∞–≥–æ–≤ is_today: {update_result['error']}\")\n                else:\n                    logger.info(f\"–§–ª–∞–≥–∏ is_today –æ–±–Ω–æ–≤–ª–µ–Ω—ã: —Å–±—Ä–æ—à–µ–Ω–æ={update_result.get('updated', 0)} —Å—Ç–∞—Ä—ã—Ö —Ñ–ª–∞–≥–æ–≤\")\n            except Exception as e:"
  },
  {
    "chunk_id": 51,
    "context_type": "business_logic",
    "size_tokens": 1494,
    "content": "                logger.warning(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Ñ–ª–∞–≥–∏ is_today –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\")\n\n        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è ID —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º\n        digests_by_type = {}\n\n        if is_today_digest and update_existing:\n            # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ —Å–µ–≥–æ–¥–Ω—è\n            try:\n                # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n                if hasattr(self.db_manager, 'find_todays_digests'):\n                    today_digests = self.db_manager.find_todays_digests()\n                else:\n                    # –ï—Å–ª–∏ –º–µ—Ç–æ–¥–∞ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫\n                    today_digests = self.db_manager.find_digests_by_parameters(\n                        date=today,\n                        limit=10\n                    )\n                    \n                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç—ã –ø–æ —Ç–∏–ø—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                for d in today_digests:\n                    d_type = d[\"digest_type\"]\n                    if d_type not in digests_by_type or d[\"id\"] < digests_by_type[d_type][\"id\"]:\n                        digests_by_type[d_type] = d\n                \n                # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ –Ω–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–∞–π–¥–∂–µ—Å—Ç\n                if digest_type == \"brief\" and \"brief\" in digests_by_type:\n                    digest_id = digests_by_type[\"brief\"][\"id\"]\n                    logger.info(f\"–ù–∞–π–¥–µ–Ω —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç ID={digest_id}, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω\")\n                elif digest_type == \"detailed\" and \"detailed\" in digests_by_type:\n                    digest_id = digests_by_type[\"detailed\"][\"id\"]\n                    logger.info(f\"–ù–∞–π–¥–µ–Ω —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç ID={digest_id}, –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω\")\n                elif digest_type == \"both\":\n                    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω—ã –æ–±–∞ —Ç–∏–ø–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è –æ–±–æ–∏—Ö\n                    brief_id = digests_by_type.get(\"brief\", {}).get(\"id\")\n                    detailed_id = digests_by_type.get(\"detailed\", {}).get(\"id\")\n                    logger.info(f\"–ù–∞–π–¥–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ —Å–µ–≥–æ–¥–Ω—è: brief_id={brief_id}, detailed_id={detailed_id}\")\n            except Exception as e:\n                logger.warning(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {str(e)}\")\n\n        # –ë–õ–û–ö 2: –ü–û–õ–£–ß–ï–ù–ò–ï –°–û–û–ë–©–ï–ù–ò–ô\n        filter_result = self.db_manager.get_filtered_messages(\n            start_date=start_date,\n            end_date=end_date,\n            category=focus_category,\n            channels=channels,\n            keywords=keywords\n        )\n        \n        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n        if isinstance(filter_result, dict) and \"messages\" in filter_result:\n            messages = filter_result[\"messages\"]\n            logger.info(f\"–ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {filter_result.get('total', 0)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö\")\n        else:\n            messages = filter_result  # –ù–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏–∑–º–µ–Ω–∏—Ç—Å—è\n            logger.info(f\"–ü–æ–ª—É—á–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π (–ø—Ä—è–º–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)\")\n        \n        # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä–∏–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤\n        if not messages:\n            logger.warning(\"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥\")\n            \n            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –ª—é–±—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥ —á–µ—Ä–µ–∑ get_filtered_messages –¥–ª—è –ø–æ–ª–Ω–æ—Ç—ã\n            all_messages_result = self.db_manager.get_filtered_messages(start_date, end_date)\n            \n            if all_messages_result and all_messages_result.get(\"messages\"):\n                logger.info(f\"–ù–∞–π–¥–µ–Ω–æ {len(all_messages_result['messages'])} —Å–æ–æ–±—â–µ–Ω–∏–π –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤\")\n                messages = all_messages_result['messages']\n            else:\n                logger.info(\"–°–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä –∏–∑ Telegram...\")\n                from agents.data_collector import DataCollectorAgent\n                import asyncio\n                \n                collector = DataCollectorAgent(self.db_manager)\n                \n                # –°–æ–∑–¥–∞–µ–º —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏\n                loop = asyncio.new_event_loop()\n                asyncio.set_event_loop(loop)\n                \n                try:\n                    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–±–æ—Ä —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º start_date –∏ end_date\n                    collect_result = loop.run_until_complete(collector.collect_data(\n                        days_back=days_back,\n                        force_update=True,\n                        start_date=start_date,\n                        end_date=end_date\n                    ))\n                    \n                    logger.info(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {collect_result}\")\n                    \n                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞ –ø–æ—Å–ª–µ —Å–±–æ—Ä–∞\n                    messages = self.db_manager.get_messages_by_date_range(start_date, end_date)\n                finally:\n                    loop.close()\n                    \n                if not messages:\n                    logger.error(\"–°–æ–æ–±—â–µ–Ω–∏—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–∂–µ –ø–æ—Å–ª–µ —Å–±–æ—Ä–∞ –∏–∑ Telegram\")\n                    return {\n                        \"status\": \"no_messages\",\n                        \"message\": \"–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\"\n                    }\n        \n        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n        messages_by_category = {}\n        categories_count = {category: 0 for category in CATEGORIES}\n        categories_count[\"–¥—Ä—É–≥–æ–µ\"] = 0\n        total_messages = 0\n        \n        for msg in messages:\n            if not hasattr(msg, 'category') or not hasattr(msg, 'text'):\n                logger.warning(f\"–ü—Ä–æ–ø—É—Å–∫ –æ–±—ä–µ–∫—Ç–∞, –Ω–µ —è–≤–ª—è—é—â–µ–≥–æ—Å—è —Å–æ–æ–±—â–µ–Ω–∏–µ–º: {type(msg)}\")\n                continue\n                \n            category = msg.category if msg.category else \"–¥—Ä—É–≥–æ–µ\"\n            if category not in messages_by_category:\n                messages_by_category[category] = []\n            messages_by_category[category].append(msg)\n            \n            if category in categories_count:"
  },
  {
    "chunk_id": 52,
    "context_type": "business_logic",
    "size_tokens": 1494,
    "content": "                categories_count[category] += 1\n            else:\n                categories_count[\"–¥—Ä—É–≥–æ–µ\"] += 1\n            \n            total_messages += 1\n        \n        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–æ–æ–±—â–µ–Ω–∏–π\n        if total_messages == 0:\n            logger.error(\"–ü–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\")\n            return {\n                \"status\": \"no_messages\",\n                \"message\": \"–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\n            }\n\n        logger.info(f\"–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(messages_by_category)}\")\n        for category, msgs in messages_by_category.items():\n            logger.info(f\"–ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}': {len(msgs)} —Å–æ–æ–±—â–µ–Ω–∏–π\")\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –ø–µ—Ä–≤—ã—Ö —Ç—Ä–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n            for i, msg in enumerate(msgs[:3]):\n                logger.info(f\"  –°–æ–æ–±—â–µ–Ω–∏–µ {i} –¥–ª—è '{category}': —Ç–∏–ø={type(msg)}, –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç 'text'={hasattr(msg, 'text')}\")\n\n        # ========== –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–û–ï –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï (–ù–û–í–û–ï) ==========\n        brief_strategy = None\n        detailed_strategy = None\n        \n        if digest_type in [\"brief\", \"both\"]:\n            try:\n                brief_strategy = self._plan_digest_strategy(\n                    messages_by_category, \"brief\", end_date, days_back, focus_category\n                )\n                logger.info(\"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞\")\n            except Exception as e:\n                logger.warning(f\"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {e}\")\n                brief_strategy = None\n        \n        if digest_type in [\"detailed\", \"both\"]:\n            try:\n                detailed_strategy = self._plan_digest_strategy(\n                    messages_by_category, \"detailed\", end_date, days_back, focus_category\n                )\n                logger.info(\"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞\")\n            except Exception as e:\n                logger.warning(f\"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {e}\")\n                detailed_strategy = None\n        # ========== –ö–û–ù–ï–¶ –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–û–ì–û –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–Ø ==========\n\n        if brief_strategy or detailed_strategy:\n            logger.info(\"üéØ –î–∞–π–¥–∂–µ—Å—Ç —Å–æ–∑–¥–∞–µ—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\")\n            if brief_strategy:\n                logger.info(\"   üìã –ö—Ä–∞—Ç–∫–∏–π: –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞\")\n            if detailed_strategy:\n                logger.info(\"   üìñ –ü–æ–¥—Ä–æ–±–Ω—ã–π: —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ\")\n\n        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞\n        brief_sections = {}\n        detailed_sections = {}\n        \n        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n        categories_to_process_brief = [category for category in CATEGORIES if category in messages_by_category]\n        if \"–¥—Ä—É–≥–æ–µ\" in messages_by_category:\n            categories_to_process_brief.append(\"–¥—Ä—É–≥–æ–µ\")\n\n        if digest_type == \"brief\" and brief_strategy and brief_strategy.get(\"category_order\"):\n            strategic_order = brief_strategy[\"category_order\"]\n            # –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\n            ordered_categories = []\n            for cat in strategic_order:\n                if cat in categories_to_process_brief:\n                    ordered_categories.append(cat)\n            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫\n            for cat in categories_to_process_brief:\n                if cat not in ordered_categories:\n                    ordered_categories.append(cat)\n            categories_to_process_brief = ordered_categories\n            logger.info(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {' ‚Üí '.join(categories_to_process_brief)}\")\n        \n        categories_to_process_detailed = [category for category in CATEGORIES if category in messages_by_category]\n        if \"–¥—Ä—É–≥–æ–µ\" in messages_by_category:\n            categories_to_process_detailed.append(\"–¥—Ä—É–≥–æ–µ\")\n\n        elif digest_type == \"detailed\" and detailed_strategy and detailed_strategy.get(\"category_order\"):\n            strategic_order = detailed_strategy[\"category_order\"]\n            ordered_categories = []\n            for cat in strategic_order:\n                if cat in categories_to_process_detailed:\n                    ordered_categories.append(cat)\n            for cat in categories_to_process_detailed:\n                if cat not in ordered_categories:\n                    ordered_categories.append(cat)\n            categories_to_process_detailed = ordered_categories\n            logger.info(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {' ‚Üí '.join(categories_to_process_detailed)}\")\n\n        if digest_type in [\"brief\", \"both\"]:\n            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            brief_sections = self._process_categories_parallel(\n                categories_to_process_brief, messages_by_category, \"brief\"\n            )\n        \n        if digest_type in [\"detailed\", \"both\"]:\n            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            detailed_sections = self._process_categories_parallel(\n                categories_to_process_detailed, messages_by_category, \"detailed\"\n            )\n\n        results = {\n            \"status\": \"success\",\n            \"date\": end_date.strftime(\"%Y-%m-%d\"),\n            \"total_messages\": total_messages,\n            \"categories\": categories_count,\n        }\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ\n        if digest_type in [\"brief\", \"both\"]:\n            try:\n                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–≤–æ–¥–Ω—É—é —á–∞—Å—Ç—å\n                intro_text = self._generate_digest_intro(\n                    end_date, total_messages, categories_count, \n                    is_brief=True, days_back=days_back\n                )\n                \n                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n                brief_text = f\"{intro_text}\\n\\n\"\n                "
  },
  {
    "chunk_id": 53,
    "context_type": "business_logic",
    "size_tokens": 1497,
    "content": "                # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n                for category in CATEGORIES:\n                    if category in brief_sections:\n                        brief_text += f\"{brief_sections[category]}\\n\\n\"\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é \"–¥—Ä—É–≥–æ–µ\" –≤ –∫–æ–Ω–µ—Ü, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è\n                if \"–¥—Ä—É–≥–æ–µ\" in brief_sections:\n                    brief_text += f\"{brief_sections['–¥—Ä—É–≥–æ–µ']}\\n\\n\"\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç, –µ—Å–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –æ–±–∞\n                if digest_type == \"both\":\n                    brief_text += \"\\n\\n[–ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç](/digest/detailed)\\n\"\n                \n                results[\"brief_digest_text\"] = brief_text\n                \n                today = datetime.now().date() \n                is_today_digest = end_date.date() == today\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ –ë–î —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n                try:\n                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                    brief_digest_id = digest_id if digest_type == \"brief\" else None\n                    if digest_type == \"both\" and \"brief\" in digests_by_type:\n                        brief_digest_id = digests_by_type[\"brief\"][\"id\"]\n                    \n                    brief_result = self.db_manager.save_digest_with_parameters(\n                        end_date, \n                        brief_text, \n                        brief_sections,\n                        digest_type=\"brief\",\n                        date_range_start=start_date,\n                        date_range_end=end_date,\n                        focus_category=focus_category,\n                        channels_filter=channels,\n                        keywords_filter=keywords,\n                        digest_id=brief_digest_id,\n                        is_today=is_today_digest\n                    )\n                    results[\"brief_digest_id\"] = brief_result[\"id\"]\n                    logger.info(f\"–ö—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω (ID: {brief_result['id']})\")\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\")\n                    results[\"brief_error\"] = str(e)\n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫—Ä–∞—Ç–∫–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\")\n                results[\"brief_error\"] = str(e)\n        \n        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ\n        if digest_type in [\"detailed\", \"both\"]:\n            try:\n                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–≤–æ–¥–Ω—É—é —á–∞—Å—Ç—å\n                intro_text = self._generate_digest_intro(\n                    end_date, total_messages, categories_count, \n                    is_brief=False, days_back=days_back\n                )\n                \n                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n                detailed_text = f\"{intro_text}\\n\\n\"\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ –ø–æ—Ä—è–¥–∫–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏\n                for category in CATEGORIES:\n                    if category in detailed_sections:\n                        category_icon = self._add_category_icon(category)\n                        detailed_text += f\"## {category_icon} {category.upper()}\\n\\n{detailed_sections[category]}\\n\\n\"\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é \"–¥—Ä—É–≥–æ–µ\" –≤ –∫–æ–Ω–µ—Ü, –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è\n                if \"–¥—Ä—É–≥–æ–µ\" in detailed_sections:\n                    category_icon = self._add_category_icon(\"–¥—Ä—É–≥–æ–µ\")\n                    detailed_text += f\"## {category_icon} –î–†–£–ì–ò–ï –ù–û–í–û–°–¢–ò\\n\\n{detailed_sections['–¥—Ä—É–≥–æ–µ']}\\n\\n\"\n                \n                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç, –µ—Å–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –æ–±–∞\n                if digest_type == \"both\":\n                    detailed_text += \"\\n\\n[–ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç](/digest/brief)\\n\"\n                \n                results[\"detailed_digest_text\"] = detailed_text\n                \n                today = datetime.now().date() \n                is_today_digest = end_date.date() == today\n                \n                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –≤ –ë–î —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n                try:\n                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n                    detailed_digest_id = digest_id if digest_type == \"detailed\" else None\n                    if digest_type == \"both\" and \"detailed\" in digests_by_type:\n                        detailed_digest_id = digests_by_type[\"detailed\"][\"id\"]\n                    \n                    detailed_result = self.db_manager.save_digest_with_parameters(\n                        end_date, \n                        detailed_text, \n                        detailed_sections,\n                        digest_type=\"detailed\",\n                        date_range_start=start_date,\n                        date_range_end=end_date,\n                        focus_category=focus_category,\n                        channels_filter=channels,\n                        keywords_filter=keywords,\n                        digest_id=detailed_digest_id,\n                        is_today=is_today_digest\n                    )\n                    results[\"detailed_digest_id\"] = detailed_result[\"id\"]\n                    logger.info(f\"–ü–æ–¥—Ä–æ–±–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω (ID: {detailed_result['id']})\")\n                except Exception as e:\n                    logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\")\n                    results[\"detailed_error\"] = str(e)\n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {str(e)}\")\n                results[\"detailed_error\"] = str(e)\n        \n        return results\n    def get_digest_to_update(self, date, digest_type):\n        \"\"\"\n        –ù–∞—Ö–æ–¥–∏—Ç –¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É –∏ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞\n        \n        Args:\n            date (datetime): –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            digest_type (str): –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞"
  },
  {
    "chunk_id": 54,
    "context_type": "business_logic",
    "size_tokens": 1492,
    "content": "            \n        Returns:\n            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–π–¥–∂–µ—Å—Ç–µ –∏–ª–∏ None\n        \"\"\"\n        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –ª–∏ —ç—Ç–æ –¥–∞–π–¥–∂–µ—Å—Ç\n        today = datetime.now().date()\n        is_today = date.date() == today if hasattr(date, 'date') else date == today\n        \n        if is_today:\n            # –î–ª—è —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è –∏—â–µ–º —Å —Ñ–ª–∞–≥–æ–º is_today\n            digests = self.db_manager.find_digests_by_parameters(\n                is_today=True,\n                digest_type=digest_type,\n                limit=5\n            )\n        else:\n            # –î–ª—è –¥—Ä—É–≥–∏—Ö –¥–Ω–µ–π –∏—â–µ–º –ø–æ –¥–∞—Ç–µ\n            digests = self.db_manager.find_digests_by_parameters(\n                date=date,\n                digest_type=digest_type,\n                limit=5\n            )\n        \n        if not digests:\n            return None\n        \n        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π —Ä–∞–Ω–Ω–∏–π (—Å –Ω–∞–∏–º–µ–Ω—å—à–∏–º ID)\n        return min(digests, key=lambda x: x['id'])\n    def create_task(self):\n        \"\"\"\n        –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞\n        \n        Returns:\n            Task: –ó–∞–¥–∞—á–∞ CrewAI\n        \"\"\"\n        return Task(\n            description=\"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç –ø—Ä–∞–≤–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–µ–Ω—å\",\n            agent=self.agent,\n            expected_output=\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º\"\n        )\n    def update_digests_for_date(self, date):\n        \"\"\"\n        –û–±–Ω–æ–≤–ª—è–µ—Ç –≤—Å–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É\n        \n        Args:\n            date (datetime): –î–∞—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤\n                \n        Returns:\n            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n        \"\"\"\n        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞—Ç—É\n        if hasattr(date, 'date'):\n            # –≠—Ç–æ datetime –æ–±—ä–µ–∫—Ç\n            date_for_search = date\n            date_str = date.strftime('%Y-%m-%d')\n        else:\n            # –≠—Ç–æ —É–∂–µ date –æ–±—ä–µ–∫—Ç\n            date_for_search = datetime.combine(date, datetime.min.time())\n            date_str = date.strftime('%Y-%m-%d')\n            \n        logger.info(f\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –¥–∞—Ç—É {date_str}\")\n        \n        # –ù–∞–π—Ç–∏ –≤—Å–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∞–Ω–Ω—É—é –¥–∞—Ç—É\n        digests = self.db_manager.get_digests_containing_date(date_for_search)\n        \n        if not digests:\n            # –î–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç—ã —Å —Ñ–ª–∞–≥–æ–º is_today\n            today = datetime.now().date()\n            if date.date() == today:\n                today_digests = self.db_manager.find_digests_by_parameters(\n                    is_today=True,\n                    limit=10\n                )\n                if today_digests:\n                    digests = today_digests\n                    logger.info(f\"–ù–∞–π–¥–µ–Ω–æ {len(today_digests)} –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –∑–∞ —Å–µ–≥–æ–¥–Ω—è —Å —Ñ–ª–∞–≥–æ–º is_today=True\")\n        \n        if not digests:\n            logger.info(f\"–î–∞–π–¥–∂–µ—Å—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –¥–∞—Ç—É {date.strftime('%Y-%m-%d')}, –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n            return {\"status\": \"no_digests\", \"date\": date.strftime('%Y-%m-%d')}\n        \n        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç—ã –ø–æ —Ç–∏–ø—É –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Ä–∞–Ω–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞\n        # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–µ–π\n        unique_digests = {}\n        for digest in digests:\n            digest_type = digest[\"digest_type\"]\n            if digest_type not in unique_digests or digest[\"id\"] < unique_digests[digest_type][\"id\"]:\n                unique_digests[digest_type] = digest\n        \n        digests = list(unique_digests.values())\n        logger.info(f\"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {len(digests)}\")\n        \n        results = {\"updated_digests\": []}\n        \n        for digest in digests:\n            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            digest_date = digest[\"date\"]\n            digest_type = digest[\"digest_type\"]\n            focus_category = digest[\"focus_category\"]\n            channels = digest.get[\"channels_filter\"]\n            keywords = digest.get[\"keywords_filter\"]\n            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –ø–∞—Ä—Å–∏–º JSON, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ\n            if isinstance(channels, str):\n                try:\n                    channels = json.loads(channels) if channels else None\n                except (json.JSONDecodeError, TypeError):\n                    channels = None\n            \n            if isinstance(keywords, str):\n                try:\n                    keywords = json.loads(keywords) if keywords else None\n                except (json.JSONDecodeError, TypeError):\n                    keywords = None\n\n            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n            if digest[\"date_range_start\"] and digest[\"date_range_end\"]:\n                start_date = digest[\"date_range_start\"]\n                end_date = digest[\"date_range_end\"]\n                days_back = (end_date - start_date).days + 1\n            else:\n                # –ï—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω –Ω–µ —É–∫–∞–∑–∞–Ω, —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –æ–¥–∏–Ω –¥–µ–Ω—å\n                start_date = end_date = digest_date\n                days_back = 1\n            \n            try:\n                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n                result = self.create_digest(\n                    date=end_date,\n                    days_back=days_back,\n                    digest_type=digest_type,\n                    update_existing=True,\n                    focus_category=focus_category,\n                    channels=channels,\n                    keywords=keywords,\n                    digest_id=digest[\"id\"]\n                )\n                \n                results[\"updated_digests\"].append({\n                    \"digest_id\": digest[\"id\"],\n                    \"digest_type\": digest_type,\n                    \"date\": end_date.strftime('%Y-%m-%d'),\n                    \"status\": \"success\"\n                })\n                \n                logger.info(f\"–î–∞–π–¥–∂–µ—Å—Ç ID {digest['id']} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω\")\n            except Exception as e:\n                logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ ID {digest['id']}: {str(e)}\")\n                results[\"updated_digests\"].append({\n                    \"digest_id\": digest[\"id\"],\n                    \"digest_type\": digest_type,"
  },
  {
    "chunk_id": 55,
    "context_type": "business_logic",
    "size_tokens": 1498,
    "content": "                    \"date\": end_date.strftime('%Y-%m-%d'),\n                    \"status\": \"error\",\n                    \"error\": str(e)\n                })\n        \n        logger.info(f\"–û–±–Ω–æ–≤–ª–µ–Ω–æ {len(results['updated_digests'])} –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –¥–ª—è –¥–∞—Ç—ã {date.strftime('%Y-%m-%d')}\")\n        return results\n    def save_digest_with_parameters(self, date, text, sections, digest_type=\"brief\", \n                              date_range_start=None, date_range_end=None, \n                              focus_category=None, channels_filter=None, \n                              keywords_filter=None, digest_id=None):\n        \"\"\"\n        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n        \n        Args:\n            date (datetime): –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            text (str): –¢–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            sections (dict): –°–ª–æ–≤–∞—Ä—å —Å–µ–∫—Ü–∏–π\n            digest_type (str): –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            date_range_start (datetime): –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞\n            date_range_end (datetime): –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞\n            focus_category (str): –§–æ–∫—É—Å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n            channels_filter (list): –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n            keywords_filter (list): –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n            digest_id (int): ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n            \n        Returns:\n            dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ–∑–¥–∞–Ω–Ω–æ–º –¥–∞–π–¥–∂–µ—Å—Ç–µ\n        \"\"\"\n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞ —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å\n        today = datetime.now().date()\n        is_today_digest = date.date() == today\n        \n        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –≤ –ë–î\n        result = self.db_manager.save_digest_with_parameters(\n            date=date,\n            text=text,\n            sections=sections,\n            digest_type=digest_type,\n            date_range_start=date_range_start,\n            date_range_end=date_range_end,\n            focus_category=focus_category,\n            channels_filter=channels_filter,\n            keywords_filter=keywords_filter,\n            digest_id=digest_id,\n            is_today=is_today_digest,\n            last_updated=datetime.now()  # –í—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\n        )\n        \n        logger.info(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω –¥–∞–π–¥–∂–µ—Å—Ç —Ç–∏–ø–∞ '{digest_type}' –∑–∞ {date.strftime('%Y-%m-%d')}, ID: {result['id']}\")\n        return result\n    # –í agents/digester.py - –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–∏ –º–µ—Ç–æ–¥—ã –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è\n\n    def _plan_digest_strategy(self, messages_by_category, digest_type, date, days_back=1, \n                            focus_category=None, target_audience=\"general\"):\n        \"\"\"\n        –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        \n        Args:\n            messages_by_category (dict): –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n            digest_type (str): –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞ (brief/detailed)\n            date (datetime): –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n            days_back (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π\n            focus_category (str): –§–æ–∫—É—Å–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è\n            target_audience (str): –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è\n            \n        Returns:\n            dict: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        \"\"\"\n        logger.info(f\"üéØ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ò –î–ê–ô–î–ñ–ï–°–¢–ê:\")\n        logger.info(f\"   üìÖ –î–∞—Ç–∞: {date.strftime('%Y-%m-%d')}\")\n        logger.info(f\"   üìã –¢–∏–ø: {digest_type}\")\n        logger.info(f\"   üé™ –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(messages_by_category)}\")\n        logger.info(f\"   üìä –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {sum(len(msgs) for msgs in messages_by_category.values())}\")\n        \n        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–∞–≤ —Å–æ–æ–±—â–µ–Ω–∏–π\n        category_analysis = {}\n        total_messages = 0\n        \n        for category, messages in messages_by_category.items():\n            count = len(messages)\n            total_messages += count\n            \n            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n            importance_score = self._calculate_category_importance(category, messages, focus_category)\n            \n            category_analysis[category] = {\n                \"count\": count,\n                \"importance\": importance_score,\n                \"percentage\": 0,  # –ë—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ –Ω–∏–∂–µ\n                \"recommended_length\": \"short\"  # –ë—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∏–∂–µ\n            }\n        \n        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ\n        for category in category_analysis:\n            if total_messages > 0:\n                category_analysis[category][\"percentage\"] = (\n                    category_analysis[category][\"count\"] / total_messages * 100\n                )\n        \n        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –ø–ª–∞–Ω\n        strategy_prompt = f\"\"\"\n        –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –ö–û–ù–¢–ï–ù–¢–ù–û–ô –°–¢–†–ê–¢–ï–ì–ò–ò –î–ê–ô–î–ñ–ï–°–¢–ê:\n        \n        –¢—ã - —Å—Ç—Ä–∞—Ç–µ–≥ –∫–æ–Ω—Ç–µ–Ω—Ç-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –ø—Ä–∞–≤–æ–≤–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞.\n        \n        –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:\n        - –î–∞—Ç–∞: {date.strftime('%d.%m.%Y')}\n        - –ü–µ—Ä–∏–æ–¥: {days_back} {'–¥–µ–Ω—å' if days_back == 1 else '–¥–Ω–µ–π'}\n        - –¢–∏–ø –¥–∞–π–¥–∂–µ—Å—Ç–∞: {'–∫—Ä–∞—Ç–∫–∏–π' if digest_type == 'brief' else '–ø–æ–¥—Ä–æ–±–Ω—ã–π'}\n        - –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è: {target_audience}\n        - –§–æ–∫—É—Å –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {focus_category or '–Ω–µ—Ç'}\n        - –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {total_messages}\n        \n        –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:\n        {self._format_category_stats(category_analysis)}\n        \n        –ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞\n        \n        –£–ß–ò–¢–´–í–ê–ô:\n        1. –ü–†–ò–û–†–ò–¢–ò–ó–ê–¶–ò–Ø –ö–û–ù–¢–ï–ù–¢–ê:\n        - –ö–∞–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã –¥–ª—è —á–∏—Ç–∞—Ç–µ–ª–µ–π?\n        - –ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –Ω–∞—á–∞–ª–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞?\n        - –ö–∞–∫ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä–µ–º —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π?\n        \n        2. –°–¢–ò–õ–¨ –ò –ü–û–î–ê–ß–ê:\n        {\"- –ö—Ä–∞—Ç–∫–∏–π —Ñ–æ—Ä–º–∞—Ç: –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç—ã, –º–∏–Ω–∏–º—É–º –¥–µ—Ç–∞–ª–µ–π\" if digest_type == \"brief\" else \"- –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: –∞–Ω–∞–ª–∏–∑, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è\"}\n        - –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å + –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å\n        - –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ–¥–∞—á–∞\n        \n        3. –ß–ò–¢–ê–¢–ï–õ–¨–°–ö–ê–Ø –¶–ï–ù–ù–û–°–¢–¨:\n        - –ß—Ç–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –∞—É–¥–∏—Ç–æ—Ä–∏–∏?\n        - –ö–∞–∫–∏–µ –≤—ã–≤–æ–¥—ã –∏ —Å–≤—è–∑–∏ —Å—Ç–æ–∏—Ç –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å?\n        - –ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–µ–π—Å—Ç–≤–µ–Ω–Ω–æ–π?\n        \n        –î–ê–ô –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n        –°—Ç—Ä—É–∫—Ç—É—Ä–∞: [–ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏]\n        –ê–∫—Ü–µ–Ω—Ç—ã: [–Ω–∞ —á–µ–º —Å–¥–µ–ª–∞—Ç—å —É–ø–æ—Ä –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏]\n        –°—Ç–∏–ª—å: [—Ç–æ–Ω –∏ –ø–æ–¥—Ö–æ–¥ –∫ –∏–∑–ª–æ–∂–µ–Ω–∏—é]\n        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: [—á—Ç–æ –≤—ã–¥–µ–ª–∏—Ç—å –æ—Å–æ–±–æ]\n        \"\"\""
  },
  {
    "chunk_id": 56,
    "context_type": "business_logic",
    "size_tokens": 1498,
    "content": "        \n        try:\n            strategy_response = self.llm_model.generate(\n                strategy_prompt, \n                max_tokens=600, \n                temperature=0.3\n            )\n            \n            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n            strategy = self._parse_strategy_response(\n                strategy_response, category_analysis, digest_type\n            )\n            \n            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n            self._log_content_strategy(strategy, category_analysis)\n            \n            return strategy\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {str(e)}\")\n            # Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è\n            return self._create_fallback_strategy(category_analysis, digest_type)\n\n    def _calculate_category_importance(self, category, messages, focus_category=None):\n        \"\"\"–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞\"\"\"\n        \n        # –ë–∞–∑–æ–≤—ã–µ –≤–µ—Å–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n        base_weights = {\n            '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã': 5,  # –°–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ - –Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã\n            '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º': 4,  # –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–∫–æ–Ω–∞—Ö\n            '–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã': 3,  # –ë—É–¥—É—â–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\n            '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞': 4,  # –í–∞–∂–Ω—ã–µ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏—è\n            '–¥—Ä—É–≥–æ–µ': 1  # –ù–∞–∏–º–µ–Ω–µ–µ –≤–∞–∂–Ω–æ–µ\n        }\n        \n        base_score = base_weights.get(category, 2)\n        \n        # –ë–æ–Ω—É—Å –∑–∞ —Ñ–æ–∫—É—Å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n        if focus_category and category == focus_category:\n            base_score += 2\n        \n        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π (–ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å —Ç–µ–º—ã)\n        message_count = len(messages)\n        if message_count > 3:\n            base_score += 1\n        elif message_count > 1:\n            base_score += 0.5\n        \n        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏\n        important_keywords = [\n            '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–ø–æ–¥–ø–∏—Å–∞–ª', '–≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É', '—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω',\n            '–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã–π —Å—É–¥', '–≤–µ—Ä—Ö–æ–≤–Ω—ã–π —Å—É–¥', '–ø–ª–µ–Ω—É–º',\n            '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è –¥—É–º–∞', '—Å–æ–≤–µ—Ç —Ñ–µ–¥–µ—Ä–∞—Ü–∏–∏'\n        ]\n        \n        keyword_bonus = 0\n        for message in messages:\n            text_lower = message.text.lower()\n            for keyword in important_keywords:\n                if keyword in text_lower:\n                    keyword_bonus += 0.2\n                    break  # –û–¥–∏–Ω –±–æ–Ω—É—Å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ\n        \n        final_score = min(5, base_score + keyword_bonus)  # –ú–∞–∫—Å–∏–º—É–º 5\n        \n        return round(final_score, 1)\n\n    def _format_category_stats(self, category_analysis):\n        \"\"\"–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞\"\"\"\n        \n        stats_text = \"\"\n        sorted_categories = sorted(\n            category_analysis.items(), \n            key=lambda x: x[1]['importance'], \n            reverse=True\n        )\n        \n        for category, stats in sorted_categories:\n            stats_text += f\"- {category}: {stats['count']} —Å–æ–æ–±—â–µ–Ω–∏–π \"\n            stats_text += f\"({stats['percentage']:.1f}%), –≤–∞–∂–Ω–æ—Å—Ç—å: {stats['importance']}/5\\n\"\n        \n        return stats_text\n\n    def _parse_strategy_response(self, response, category_analysis, digest_type):\n        \"\"\"–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ —Å–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\"\"\"\n        \n        strategy = {\n            \"content_priorities\": [],\n            \"category_order\": [],\n            \"style_guidelines\": [],\n            \"emphasis_points\": [],\n            \"tone\": \"professional\",\n            \"approach\": digest_type,\n            \"raw_response\": response\n        }\n        \n        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏\n        lines = response.strip().split('\\n')\n        current_section = None\n        \n        # –õ–æ–≥–∏—Ä—É–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏\n        logger.debug(f\"–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ LLM: {response[:200]}...\")\n        \n        for line in lines:\n            line_clean = line.strip()\n            if not line_clean:\n                continue\n            \n            line_lower = line_clean.lower()\n            \n            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ü–∏–π —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏\n            if any(word in line_lower for word in ['—Å—Ç—Ä—É–∫—Ç—É—Ä–∞:', '–ø–æ—Ä—è–¥–æ–∫:', '–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:']):\n                current_section = 'structure'\n                content = self._extract_content_after_colon(line_clean)\n                if content:\n                    strategy[\"category_order\"] = self._extract_categories_from_text(content, category_analysis)\n                    logger.debug(f\"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {content}\")\n            \n            elif any(word in line_lower for word in ['–∞–∫—Ü–µ–Ω—Ç—ã:', '–∞–∫—Ü–µ–Ω—Ç:', '–≤—ã–¥–µ–ª–∏—Ç—å:', '–ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å:']):\n                current_section = 'emphasis'\n                content = self._extract_content_after_colon(line_clean)\n                if content:\n                    strategy[\"emphasis_points\"].append(content)\n                    logger.debug(f\"–ù–∞–π–¥–µ–Ω—ã –∞–∫—Ü–µ–Ω—Ç—ã: {content}\")\n            \n            elif any(word in line_lower for word in ['—Å—Ç–∏–ª—å:', '—Ç–æ–Ω:', '–ø–æ–¥–∞—á–∞:', '–∏–∑–ª–æ–∂–µ–Ω–∏–µ:']):\n                current_section = 'style'\n                content = self._extract_content_after_colon(line_clean)\n                if content:\n                    strategy[\"style_guidelines\"].append(content)\n                    logger.debug(f\"–ù–∞–π–¥–µ–Ω —Å—Ç–∏–ª—å: {content}\")\n            \n            elif any(word in line_lower for word in ['–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã:', '–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç:', '–≤–∞–∂–Ω–æ:', '–≥–ª–∞–≤–Ω–æ–µ:']):\n                current_section = 'priorities'\n                content = self._extract_content_after_colon(line_clean)\n                if content:\n                    strategy[\"content_priorities\"].append(content)\n                    logger.debug(f\"–ù–∞–π–¥–µ–Ω—ã –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã: {content}\")\n            \n            elif current_section and line_clean and not line_clean.startswith('-'):\n                # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å–µ–∫—Ü–∏–∏ (–µ—Å–ª–∏ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å -)\n                if current_section == 'emphasis':\n                    strategy[\"emphasis_points\"].append(line_clean)\n                elif current_section == 'style':\n                    strategy[\"style_guidelines\"].append(line_clean)"
  },
  {
    "chunk_id": 57,
    "context_type": "business_logic",
    "size_tokens": 1482,
    "content": "                elif current_section == 'priorities':\n                    strategy[\"content_priorities\"].append(line_clean)\n                elif current_section == 'structure':\n                    additional_cats = self._extract_categories_from_text(line_clean, category_analysis)\n                    for cat in additional_cats:\n                        if cat not in strategy[\"category_order\"]:\n                            strategy[\"category_order\"].append(cat)\n            \n            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± - –ø–æ–∏—Å–∫ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤\n            elif line_clean.startswith('-') or line_clean.startswith('‚Ä¢'):\n                bullet_content = line_clean[1:].strip()\n                if bullet_content:\n                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â—É—é —Å–µ–∫—Ü–∏—é –∏–ª–∏ –≤ –æ–±—â–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã\n                    if current_section == 'emphasis':\n                        strategy[\"emphasis_points\"].append(bullet_content)\n                    elif current_section == 'style':\n                        strategy[\"style_guidelines\"].append(bullet_content)\n                    elif current_section == 'priorities':\n                        strategy[\"content_priorities\"].append(bullet_content)\n                    else:\n                        # –ï—Å–ª–∏ —Å–µ–∫—Ü–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\n                        strategy[\"content_priorities\"].append(bullet_content)\n        \n        # Fallback: –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞\n        if not strategy[\"content_priorities\"]:\n            strategy[\"content_priorities\"] = self._extract_fallback_priorities(response)\n            logger.debug(\"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è fallback –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã\")\n        \n        if not strategy[\"style_guidelines\"]:\n            strategy[\"style_guidelines\"] = self._extract_fallback_style(response)\n            logger.debug(\"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è fallback —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\")\n        \n        if not strategy[\"emphasis_points\"]:\n            strategy[\"emphasis_points\"] = self._extract_fallback_emphasis(response)\n            logger.debug(\"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è fallback –∞–∫—Ü–µ–Ω—Ç—ã\")\n        \n        # –ï—Å–ª–∏ –ø–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä—è–¥–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\n        if not strategy[\"category_order\"]:\n            strategy[\"category_order\"] = sorted(\n                category_analysis.keys(),\n                key=lambda cat: category_analysis[cat]['importance'],\n                reverse=True\n            )\n            logger.debug(\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Ä—è–¥–æ–∫ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\")\n        \n        # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n        logger.debug(f\"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã={len(strategy['content_priorities'])}, \"\n                    f\"—Å—Ç–∏–ª—å={len(strategy['style_guidelines'])}, \"\n                    f\"–∞–∫—Ü–µ–Ω—Ç—ã={len(strategy['emphasis_points'])}\")\n        \n        return strategy\n\n    def _extract_categories_from_text(self, text, category_analysis):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ —Ç–µ–∫—Å—Ç–∞\"\"\"\n        \n        categories_found = []\n        text_lower = text.lower()\n        \n        for category in category_analysis.keys():\n            if category.lower() in text_lower:\n                categories_found.append(category)\n        \n        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ —É–ø–æ–º—è–Ω—É—Ç—ã\n        all_categories = list(category_analysis.keys())\n        for category in all_categories:\n            if category not in categories_found:\n                categories_found.append(category)\n        \n        return categories_found\n\n    def _create_fallback_strategy(self, category_analysis, digest_type):\n        \"\"\"–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏\"\"\"\n        \n        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏\n        ordered_categories = sorted(\n            category_analysis.keys(),\n            key=lambda cat: category_analysis[cat]['importance'],\n            reverse=True\n        )\n        \n        return {\n            \"content_priorities\": [\"–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å\", \"–ü—Ä–∞–≤–æ–≤–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å\", \"–í–ª–∏—è–Ω–∏–µ –Ω–∞ –≥—Ä–∞–∂–¥–∞–Ω\"],\n            \"category_order\": ordered_categories,\n            \"style_guidelines\": [\n                \"–Ø—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è\",\n                \"–ü—Ä–∞–≤–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å\", \n                \"–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å\"\n            ],\n            \"emphasis_points\": [\"–ù–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã\", \"–í–∞–∂–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\"],\n            \"tone\": \"professional\",\n            \"approach\": digest_type,\n            \"raw_response\": \"Fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è\"\n        }\n\n    def _log_content_strategy(self, strategy, category_analysis):\n        \"\"\"–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\"\"\"\n        \n        logger.info(\"üìã –ö–û–ù–¢–ï–ù–¢–ù–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø –î–ê–ô–î–ñ–ï–°–¢–ê:\")\n        logger.info(\"   \" + \"=\" * 50)\n        \n        # –ü–æ—Ä—è–¥–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π\n        logger.info(\"   üìä –ü–û–†–Ø–î–û–ö –ö–ê–¢–ï–ì–û–†–ò–ô:\")\n        for i, category in enumerate(strategy[\"category_order\"], 1):\n            importance = category_analysis.get(category, {}).get('importance', 0)\n            count = category_analysis.get(category, {}).get('count', 0)\n            logger.info(f\"     {i}. {category} (–≤–∞–∂–Ω–æ—Å—Ç—å: {importance}, —Å–æ–æ–±—â–µ–Ω–∏–π: {count})\")\n        \n        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞\n        if strategy[\"content_priorities\"]:\n            logger.info(\"   üéØ –ü–†–ò–û–†–ò–¢–ï–¢–´ –ö–û–ù–¢–ï–ù–¢–ê:\")\n            for priority in strategy[\"content_priorities\"]:\n                logger.info(f\"     ‚Ä¢ {priority}\")\n        \n        # –°—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n        if strategy[\"style_guidelines\"]:\n            logger.info(\"   ‚úçÔ∏è –°–¢–ò–õ–¨ –ò –ü–û–î–ê–ß–ê:\")\n            for guideline in strategy[\"style_guidelines\"]:\n                logger.info(f\"     ‚Ä¢ {guideline}\")\n        \n        # –ê–∫—Ü–µ–Ω—Ç—ã\n        if strategy[\"emphasis_points\"]:\n            logger.info(\"   ‚≠ê –ê–ö–¶–ï–ù–¢–´:\")\n            for emphasis in strategy[\"emphasis_points\"]:\n                logger.info(f\"     ‚Ä¢ {emphasis}\")\n        \n        logger.info(\"   \" + \"=\" * 50)\n\n    \n\n    def _generate_category_overview_with_strategy(self, category, messages, digest_type, strategy=None):\n        \"\"\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–∑–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\"\"\"\n        \n        if not strategy:\n            # Fallback –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥"
  },
  {
    "chunk_id": 58,
    "context_type": "business_logic",
    "size_tokens": 1318,
    "content": "            return self._generate_category_overview(category, messages, digest_type)\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\n        category_priority = 1\n        if category in strategy[\"category_order\"]:\n            category_priority = strategy[\"category_order\"].index(category) + 1\n        \n        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ü–µ–Ω—Ç—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        relevant_emphasis = [emp for emp in strategy[\"emphasis_points\"] \n                            if category.lower() in emp.lower()]\n        \n        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏\n        strategic_prompt = f\"\"\"\n        –°–û–ó–î–ê–ù–ò–ï {'–ö–†–ê–¢–ö–û–ì–û' if digest_type == 'brief' else '–ü–û–î–†–û–ë–ù–û–ì–û'} –û–ë–ó–û–†–ê –ö–ê–¢–ï–ì–û–†–ò–ò –° –£–ß–ï–¢–û–ú –°–¢–†–ê–¢–ï–ì–ò–ò:\n        \n        –°–¢–†–ê–¢–ï–ì–ò–ß–ï–°–ö–ò–ï –£–ö–ê–ó–ê–ù–ò–Ø:\n        - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_priority} –∏–∑ {len(strategy['category_order'])}\n        - –°—Ç–∏–ª—å: {', '.join(strategy['style_guidelines'][:3])}\n        - –ê–∫—Ü–µ–Ω—Ç—ã: {', '.join(relevant_emphasis) if relevant_emphasis else '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø–æ–¥–∞—á–∞'}\n        - –ü–æ–¥—Ö–æ–¥: {strategy['approach']}\n        \n        –ö–ê–¢–ï–ì–û–†–ò–Ø: {category}\n        –ö–û–õ–ò–ß–ï–°–¢–í–û –°–û–û–ë–©–ï–ù–ò–ô: {len(messages)}\n        \n        –°–û–û–ë–©–ï–ù–ò–Ø –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n        {self._format_messages_for_llm(messages, max_messages=10 if digest_type == 'detailed' else 5)}\n        \n        –ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞–π {digest_type} –æ–±–∑–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö —É–∫–∞–∑–∞–Ω–∏–π\n        \n        –¢–†–ï–ë–û–í–ê–ù–ò–Ø:\n        {\"- –ö—Ä–∞—Ç–∫–æ—Å—Ç—å: 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤–æ—Å—Ç—å\" if digest_type == \"brief\" else \"- –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç—å: –∞–Ω–∞–ª–∏–∑, –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è\"}\n        - –°–ª–µ–¥—É–π —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–º –∞–∫—Ü–µ–Ω—Ç–∞–º\n        - –ò—Å–ø–æ–ª—å–∑—É–π —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∏–ª—å\n        - –£—á–∏—Ç—ã–≤–∞–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \n        –†–ï–ó–£–õ–¨–¢–ê–¢: –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –æ–±–∑–æ—Ä–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\n        \"\"\"\n        \n        try:\n            max_tokens = 300 if digest_type == \"brief\" else 600\n            response = self.llm_model.generate(strategic_prompt, max_tokens=max_tokens, temperature=0.4)\n            \n            logger.debug(f\"–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –æ–±–∑–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' —Å–æ–∑–¥–∞–Ω (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {category_priority})\")\n            return response\n            \n        except Exception as e:\n            logger.error(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –æ–±–∑–æ—Ä–∞: {str(e)}\")\n            # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥\n            return self._generate_category_overview(category, messages, digest_type)\n    \n    def _extract_content_after_colon(self, line):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è\"\"\"\n        if ':' in line:\n            return line.split(':', 1)[1].strip()\n        return \"\"\n\n    def _extract_fallback_priorities(self, response):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\"\"\"\n        priorities = []\n        response_lower = response.lower()\n        \n        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤\n        priority_keywords = {\n            '–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å': '–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–æ–≤—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π',\n            '–≤–∞–∂–Ω–æ—Å—Ç—å': '–ü—Ä–∞–≤–æ–≤–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å',\n            '–≥—Ä–∞–∂–¥–∞–Ω': '–í–ª–∏—è–Ω–∏–µ –Ω–∞ –≥—Ä–∞–∂–¥–∞–Ω',\n            '–±–∏–∑–Ω–µ—Å': '–í–ª–∏—è–Ω–∏–µ –Ω–∞ –±–∏–∑–Ω–µ—Å',\n            '–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫': '–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å',\n            '—Å—Ä–æ—á–Ω': '–°—Ä–æ—á–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π'\n        }\n        \n        for keyword, priority in priority_keywords.items():\n            if keyword in response_lower:\n                priorities.append(priority)\n                if len(priorities) >= 3:  # –ú–∞–∫—Å–∏–º—É–º 3 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞\n                    break\n        \n        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ\n        if not priorities:\n            priorities = [\"–ü—Ä–∞–≤–æ–≤–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å\", \"–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å\", \"–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫—É\"]\n        \n        return priorities\n\n    def _extract_fallback_style(self, response):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\"\"\"\n        styles = []\n        response_lower = response.lower()\n        \n        style_keywords = {\n            '—è—Å–Ω': '–Ø—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è',\n            '—Ç–æ—á–Ω': '–ü—Ä–∞–≤–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å',\n            '—Å—Ç—Ä—É–∫—Ç—É—Ä': '–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å',\n            '–¥–æ—Å—Ç—É–ø–Ω': '–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏—è',\n            '–∫—Ä–∞—Ç–∫': '–ö—Ä–∞—Ç–∫–æ—Å—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫',\n            '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª': '–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω'\n        }\n        \n        for keyword, style in style_keywords.items():\n            if keyword in response_lower:\n                styles.append(style)\n                if len(styles) >= 3:\n                    break\n        \n        if not styles:\n            styles = [\"–ü—Ä–∞–≤–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å\", \"–Ø—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è\", \"–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å\"]\n        \n        return styles\n\n    def _extract_fallback_emphasis(self, response):\n        \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–∫—Ü–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤\"\"\"\n        emphasis = []\n        response_lower = response.lower()\n        \n        emphasis_keywords = {\n            '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã': '–ù–æ–≤—ã–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã',\n            '–ø–æ–ø—Ä–∞–≤–∫–∏': '–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–µ',\n            '—Å—É–¥': '–°—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞',\n            '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç': '–†–µ—à–µ–Ω–∏—è –Ω–∞ –≤—ã—Å—à–µ–º —É—Ä–æ–≤–Ω–µ',\n            '–≥–æ—Å–¥—É–º–∞': '–ó–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã',\n            '–≤–∞–∂–Ω': '–ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è'\n        }\n        \n        for keyword, emph in emphasis_keywords.items():\n            if keyword in response_lower:\n                emphasis.append(emph)\n                if len(emphasis) >= 3:\n                    break\n        \n        if not emphasis:\n            emphasis = [\"–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è\", \"–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫—É\"]\n        \n        return emphasis"
  },
  {
    "chunk_id": 59,
    "context_type": "configurations",
    "size_tokens": 1303,
    "content": "=== agent_config.json ===\n{\n  \"agent_name\": \"TestAgent\",\n  \"model\": \"gpt-4\",\n  \"temperature\": 0.1,\n  \"system_prompt\": \"–¢—ã - –±–∞–Ω–∫–æ–≤—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç\",\n  \"guardrails\": [\n    \"–ù–µ —Ä–∞–∑–≥–ª–∞—à–∞–π –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\",\n    \"–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞\"\n  ]\n}\n\n=== logging_config.py ===\n\"\"\"\n–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n\"\"\"\nimport os\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\n# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\nlogs_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'logs')\nif not os.path.exists(logs_dir):\n    os.makedirs(logs_dir)\n\n# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞\nlog_file_path = os.path.join(logs_dir, 'lawdigest.log')\n\n# –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞\ndef setup_logging():\n    # –°–æ–∑–¥–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S'\n    )\n    \n    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞\n    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ñ–∞–π–ª–∞ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏ UTF-8\n    file_handler = RotatingFileHandler(\n    log_file_path,\n    maxBytes=10*1024*1024,  # 10MB\n    backupCount=5,\n    encoding='utf-8'  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É\n    )\n    file_handler.setFormatter(formatter)\n    file_handler.setLevel(logging.INFO)\n    \n    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    console_handler.setLevel(logging.INFO)\n    \n    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.INFO)\n    root_logger.addHandler(file_handler)\n    root_logger.addHandler(console_handler)\n    \n    # –û—Ç–¥–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –±–∏–±–ª–∏–æ—Ç–µ–∫\n    logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)\n    logging.getLogger('telethon').setLevel(logging.WARNING)\n    \n    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –¥—Ä—É–≥–∏—Ö –ª–æ–≥–≥–µ—Ä–æ–≤ CrewAI\n    logging.getLogger('crewai').setLevel(logging.INFO)\n    \n    return root_logger\n\n\n=== settings.py ===\n\"\"\"\n–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–µ–∫—Ç–∞\n\"\"\"\nimport os\nfrom dotenv import load_dotenv\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞\nload_dotenv()\n\n# Telegram –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\nTELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\")\nTELEGRAM_API_ID = os.getenv(\"TELEGRAM_API_ID\")\nTELEGRAM_API_HASH = os.getenv(\"TELEGRAM_API_HASH\")\nBOT_USERNAME = os.getenv(\"BOT_USERNAME\", \"your_bot_username\")  # –ò–º—è –±–æ—Ç–∞ –¥–ª—è —Å—Å—ã–ª–æ–∫\n\n# –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\nTELEGRAM_CHANNELS = [\n    # –í—ã—Å—à–∏–µ –æ—Ä–≥–∞–Ω—ã –≤–ª–∞—Å—Ç–∏\n    \"@kremlininfo\",      # –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –†–§\n    \"@governmentru\",     # –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –†–§\n    \"@dumainfo\",         # –ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–∞—è –î—É–º–∞\n    \"@sovfedinfo\",       # –°–æ–≤–µ—Ç –§–µ–¥–µ—Ä–∞—Ü–∏–∏\n    \n    # –ú–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞\n    \"@minzdravru\",       # –ú–∏–Ω–∑–¥—Ä–∞–≤ –†–§\n    \"@rosmintrudru\",     # –ú–∏–Ω—Ç—Ä—É–¥ –†–§\n    \"@minprosvetrf\",     # –ú–∏–Ω–ø—Ä–æ—Å–≤–µ—â–µ–Ω–∏—è –†–§\n    \"@minpromtorgrf\",    # –ú–∏–Ω–ø—Ä–æ–º—Ç–æ—Ä–≥ –†–§\n    \"@MinEconomyrf\",     # –ú–∏–Ω—ç–∫–æ–Ω–æ–º—Ä–∞–∑–≤–∏—Ç–∏—è –†–§\n    \"@mincifry\",         # –ú–∏–Ω—Ü–∏—Ñ—Ä—ã –†–§\n    \"@mintransrussia\",   # –ú–∏–Ω—Ç—Ä–∞–Ω—Å –†–§\n    \"@minprirody\",       # –ú–∏–Ω–ø—Ä–∏—Ä–æ–¥—ã –†–§\n    \"@ruminfin\",         # –ú–∏–Ω—Ñ–∏–Ω –†–§\n    \"@minkultrf\",        # –ú–∏–Ω–∫—É–ª—å—Ç –†–§\n    \"@minselhozrf\",      # –ú–∏–Ω—Å–µ–ª—å—Ö–æ–∑ –†–§\n    \"@rumvd\",            # –ú–í–î –†–§\n    \"@minjustrf\",        # –ú–∏–Ω—é—Å—Ç –†–§\n    \"@minenergorf\",      # –ú–∏–Ω—ç–Ω–µ—Ä–≥–æ –†–§\n    \"@minobrnaukirf\",    # –ú–∏–Ω–æ–±—Ä–Ω–∞—É–∫–∏ –†–§\n    \"@minsportrf\",       # –ú–∏–Ω—Å–ø–æ—Ä—Ç –†–§\n    \n    # –§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ —Å–ª—É–∂–±—ã –∏ –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞\n    \"@rospotrebnadzorru\", # –†–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\n    \"@favtrf\",           # –†–æ—Å–∞–≤–∏–∞—Ü–∏—è\n    \"@fas_time\",         # –§–ê–° –†–æ—Å—Å–∏–∏\n    \"@rostrudgovru\",     # –†–æ—Å—Ç—Ä—É–¥\n    \"@obrnadzorru\",      # –†–æ—Å–æ–±—Ä–Ω–∞–¥–∑–æ—Ä\n    \"@roskomnadzorro\",   # –†–æ—Å–∫–æ–º–Ω–∞–¥–∑–æ—Ä\n    \"@rukazna\",          # –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–µ –∫–∞–∑–Ω–∞—á–µ–π—Å—Ç–≤–æ\n    \"@fnsru\",            # –§–ù–° –†–æ—Å—Å–∏–∏\n    \"@customsrf\",        # –§–¢–° –†–æ—Å—Å–∏–∏\n    \"@fedsfmru\",         # –†–æ—Å—Ñ–∏–Ω–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥\n    \"@fmbaros\",          # –§–ú–ë–ê –†–æ—Å—Å–∏–∏\n    \"@rosstatinfo\",      # –†–æ—Å–°—Ç–∞—Ç\n    \"@rosreestrinfo\",    # –†–æ—Å—Ä–µ–µ—Å—Ç—Ä\n    \"@rosstandart\",      # –†–æ—Å—Å—Ç–∞–Ω–¥–∞—Ä—Ç\n    \"@fsagovru\",         # –†–æ—Å–∞–∫–∫—Ä–µ–¥–∏—Ç–∞—Ü–∏—è\n    \"@rosavtodorru\",     # –†–æ—Å–∞–≤—Ç–æ–¥–æ—Ä\n    \"@rosgvardrf\",       # –†–æ—Å–≥–≤–∞—Ä–¥–∏—è\n    \"@fstecru\",          # –§–°–¢–≠–ö –†–æ—Å—Å–∏–∏\n    \"@rosalcohol\",       # –†–æ—Å–∞–ª–∫–æ–≥–æ–ª—å—Ç–∞–±–∞–∫–∫–æ–Ω—Ç—Ä–æ–ª—å\n    \"@roszeldor\",        # –†–æ—Å–∂–µ–ª–¥–æ—Ä\n    \"@morflotru\",        # –†–æ—Å–º–æ—Ä—Ä–µ—á—Ñ–ª–æ—Ç\n    \"@rpngovru\",         # –†–æ—Å–ø—Ä–∏—Ä–æ–¥–Ω–∞–¥–∑–æ—Ä\n    \"@rosleshozgovru\",   # –†–æ—Å–ª–µ—Å—Ö–æ–∑\n    \"@rosnedra\",         # –†–æ—Å–Ω–µ–¥—Ä–∞\n    \"@archivesru\",       # –†–æ—Å–∞—Ä—Ö–∏–≤\n    \n    # –ü—Ä–æ—á–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏\n    \"@socialfondrf\",     # –°–æ—Ü–∏–∞–ª—å–Ω—ã–π —Ñ–æ–Ω–¥ –†–§\n    \"@cbrrf\",            # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –±–∞–Ω–∫ –†–§\n    \"@vsrf_ru\",          # –í–µ—Ä—Ö–æ–≤–Ω—ã–π —Å—É–¥ –†–§\n    \"@ksrf_ru\",          # –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω—ã–π –°—É–¥ –†–§\n    \"@rusledcom\",        # –°–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–æ–º–∏—Ç–µ—Ç –†–§\n    \"@genprocru\",        # –ì–µ–Ω–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞ –†–§\n    \"@auditgovru\"        # –°—á–µ—Ç–Ω–∞—è –ø–∞–ª–∞—Ç–∞ –†–§\n]\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ë–î\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///lawdigest.db\")\n\n# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ LLM\nLLM_STUDIO_URL = os.getenv(\"LLM_STUDIO_URL\", \"http://127.0.0.1:1234\")\nQWEN_API_KEY = os.getenv(\"QWEN_API_KEY\")\nQWEN_MODEL = \"qwen2.5-14b\"\n\nGEMMA_API_KEY = os.getenv(\"GEMMA_API_KEY\")\nGEMMA_MODEL = \"gemma-3-12b\"\n\n# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\nCATEGORIES = [\n    '–∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã',\n    '–Ω–æ–≤–∞—è —Å—É–¥–µ–±–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞',\n    '–Ω–æ–≤—ã–µ –∑–∞–∫–æ–Ω—ã',\n    '–ø–æ–ø—Ä–∞–≤–∫–∏ –∫ –∑–∞–∫–æ–Ω–∞–º'\n]\n\n# –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á\nCOLLECT_INTERVAL_MINUTES = 30\nANALYZE_INTERVAL_MINUTES = 30\nDIGEST_TIME_HOUR = 18\nDIGEST_TIME_MINUTE = 0"
  },
  {
    "chunk_id": 60,
    "context_type": "supporting_docs",
    "size_tokens": 256,
    "content": "=== test_agent.txt ===\n–ê–≥–µ–Ω—Ç: TestAgent\n\n–û–ø–∏—Å–∞–Ω–∏–µ:\n–¢–µ—Å—Ç–æ–≤—ã–π –ò–ò-–∞–≥–µ–Ω—Ç –¥–ª—è –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π.\n\n–§—É–Ω–∫—Ü–∏–∏:\n- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤\n- –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤\n- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n\n–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:\n- –ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è\n- –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\n\n\n=== test_agent_spec.docx ===\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è TestAgent\n–û–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è\nTestAgent - —ç—Ç–æ –ò–ò-–∞–≥–µ–Ω—Ç –¥–ª—è –±–∞–Ω–∫–æ–≤—Å–∫–æ–π —Å—Ñ–µ—Ä—ã.\n–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n–ú–æ–¥–µ–ª—å: Qwen3/GEmma\n–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: 0.1\n–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤: 4096\n–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏\n1. –ù–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ —Å–æ–≥–ª–∞—Å–∏—è\n2. –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å–≤—ã—à–µ 100,000 —Ä—É–±.\n\n=== agent_params.xlsx ===\n=== –õ–∏—Å—Ç: –ê–≥–µ–Ω—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ===\n–ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ\n–ò–º—è –∞–≥–µ–Ω—Ç–∞ | TestAgent | –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –∞–≥–µ–Ω—Ç–∞\n–ú–æ–¥–µ–ª—å | GPT-4 | –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å\n–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ | 0.1 | –ü–∞—Ä–∞–º–µ—Ç—Ä –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏\n–ú–∞–∫—Å —Ç–æ–∫–µ–Ω—ã | 4096 | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞\n–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ä–∏—Å–∫–∞ | –°—Ä–µ–¥–Ω–∏–π | –û—Ü–µ–Ω–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä–∏—Å–∫–∞\n\n=== I AM AGENT.xlsx ===\n=== –õ–∏—Å—Ç: –õ–∏—Å—Ç1 ===\n"
  }
]